{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import os \n",
    "import timeit\n",
    "from scipy.stats import uniform\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../tests/Xaccelerometer_geometric/models')\n",
    "\n",
    "# Import the function coarse_model\n",
    "from coarse_model import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define help function to compute the total stiffness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stiffness(w, th , E , l1 , l2 , oe): \n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    w - Beam width\n",
    "    th - Beam thickness \n",
    "    E - Young's modulus of the beam material\n",
    "    l1 - Length of the longer beams\n",
    "    l2 - Length of the shorter beams\n",
    "    oe - Overetch affecting the effective width of the beam\n",
    "\n",
    "     Output:\n",
    "     kTotal - Total stiffness of the folded beam structure\n",
    "    \"\"\"\n",
    "    effectiveWidth = w - 2*oe\n",
    "    J = (1/12) * th * effectiveWidth**3\n",
    "    #Stiffness of individual beams based on their length\n",
    "    k1 = 12 * E * J / (l1**3 * 4)\n",
    "    k2 = 12 * E * J / (l2**3 * 2)\n",
    "    kTotal = 2 / (1/k1 + 1/k2)\n",
    "    \n",
    "    return kTotal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fringing_coeff( G, W ,L):\n",
    "    return (1+ G/np.pi/W + G/np.pi/W*np.log(2*np.pi*W/G))*(1+ G/np.pi/L + G/np.pi/L*np.log(2*np.pi*L/G))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "w0 = np.array([\n",
    "       -5.46838380e-02, -5.48967794e-02, -5.55854514e-02, -5.69293946e-02,\n",
    "       -6.15979917e-02, -6.96645826e-02, -8.53587836e-02, -1.13584198e-01,\n",
    "       -1.55779019e-01, -2.17224211e-01, -2.89895594e-01, -3.72584194e-01,\n",
    "       -4.60936368e-01, -5.41136026e-01, -6.05785012e-01, -6.33480668e-01,\n",
    "       -6.19262516e-01, -5.53423703e-01, -4.28976476e-01, -2.45728046e-01,\n",
    "       -1.18095540e-02,  2.58471608e-01,  5.44585645e-01,  8.23014259e-01,\n",
    "        1.06804001e+00,  1.25755286e+00,  1.38050044e+00,  1.42790329e+00,\n",
    "        1.40554321e+00,  1.32398021e+00,  1.20541465e+00,  1.05884898e+00,\n",
    "        8.86592448e-01,  6.83821023e-01,  4.60522562e-01,  2.31037945e-01,\n",
    "       -5.70054632e-04, -2.24628627e-01, -4.35439378e-01, -6.25737846e-01,\n",
    "       -7.88053155e-01, -9.16048288e-01, -1.00675571e+00, -1.06351376e+00,\n",
    "       -1.08169496e+00, -1.07077491e+00, -1.03711855e+00, -9.94023323e-01,\n",
    "       -9.51916993e-01, -9.19640779e-01, -8.97413194e-01, -8.88098419e-01,\n",
    "       -8.84706736e-01, -8.82587194e-01, -8.70208561e-01, -8.37450683e-01,\n",
    "       -7.73694575e-01, -6.70147836e-01, -5.18874586e-01, -3.20481181e-01,\n",
    "       -7.85847083e-02,  1.94332868e-01,  4.81066912e-01,  7.56015182e-01,\n",
    "        9.96855795e-01,  1.18446314e+00,  1.30417430e+00,  1.34975564e+00,\n",
    "        1.32360113e+00,  1.24206936e+00,  1.11802256e+00,  9.73114133e-01,\n",
    "        7.96541691e-01,  6.01413965e-01,  3.87530953e-01,  1.66534051e-01,\n",
    "       -5.83987348e-02, -2.76883483e-01, -4.82963532e-01, -6.68263495e-01,\n",
    "       -8.27728570e-01, -9.52925146e-01, -1.04211688e+00, -1.09318089e+00,\n",
    "       -1.10869455e+00, -1.08746517e+00, -1.03708637e+00, -9.64633644e-01,\n",
    "       -8.79197538e-01, -7.87804663e-01, -6.94566667e-01, -6.03279769e-01,\n",
    "       -5.14187515e-01, -4.30457652e-01, -3.52577776e-01, -2.81432003e-01,\n",
    "       -0.21902496, -0.16362718, -0.11842529, -0.0839361 , -0.05877977,\n",
    "       -0.04311477, -0.0356038 , -0.0343717 , -0.04091887, -0.0441989 ,\n",
    "       -0.05398948, -0.06047267, -0.070446  , -0.07894647, -0.08656528,\n",
    "       -0.09359398, -0.09992059, -0.10565532, -0.10747549, -0.10939648,\n",
    "       -0.11117665, -0.10993127, -0.10891264, -0.10737673, -0.10464664,\n",
    "       -0.10177431, -0.09841612, -0.09430341, -0.09072948, -0.08698898,\n",
    "       -0.08338045, -0.08009314, -0.07784703, -0.07413474, -0.07164513,\n",
    "       -0.07049834, -0.06917841, -0.06577135, -0.06452557, -0.06314325,\n",
    "       -0.06243589, -0.06056603, -0.06046208, -0.05954407, -0.05914033,\n",
    "       -0.05995621, -0.05923726, -0.05893051, -0.05853039, -0.05816014,\n",
    "       -0.0574123 , -0.05714226, -0.0570005 , -0.0569686 ]\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = np.array([7.70296335e-01, 7.70759165e-01, 7.70844460e-01, 7.70721376e-01,\n",
    "       7.69156337e-01, 7.68131554e-01, 7.65174866e-01, 7.58141637e-01,\n",
    "       7.48862624e-01, 7.31319487e-01, 7.16895878e-01, 7.02043295e-01,\n",
    "       6.83882356e-01, 6.70020282e-01, 6.55230105e-01, 6.53583586e-01,\n",
    "       6.57113135e-01, 6.67445719e-01, 6.87399030e-01, 7.19669342e-01,\n",
    "       7.64909625e-01, 8.24381292e-01, 9.00411844e-01, 9.93627608e-01,\n",
    "       1.10344493e+00, 1.22517502e+00, 1.35730124e+00, 1.48168850e+00,\n",
    "       1.58601487e+00, 1.64787626e+00, 1.65860808e+00, 1.61445642e+00,\n",
    "       1.51164794e+00, 1.34585547e+00, 1.13929117e+00, 9.23234344e-01,\n",
    "       7.15993524e-01, 5.33042789e-01, 3.77927899e-01, 2.51210898e-01,\n",
    "       1.53314725e-01, 8.36797208e-02, 4.10641879e-02, 1.99973490e-02,\n",
    "       2.84919366e-02, 6.01814389e-02, 1.13957725e-01, 1.79770574e-01,\n",
    "       2.49763817e-01, 3.16651165e-01, 3.82201552e-01, 4.40317333e-01,\n",
    "       4.95554537e-01, 5.43817461e-01, 5.88401258e-01, 6.28514171e-01,\n",
    "       6.67115569e-01, 7.04657853e-01, 7.44365156e-01, 7.86359251e-01,\n",
    "       8.37098360e-01, 8.99342299e-01, 9.76662040e-01, 1.06663561e+00,\n",
    "       1.17103696e+00, 1.28906727e+00, 1.41228676e+00, 1.52738297e+00,\n",
    "       1.61504674e+00, 1.66400385e+00, 1.65247071e+00, 1.59717786e+00,\n",
    "       1.47445822e+00, 1.30778909e+00, 1.10509360e+00, 8.93734276e-01,\n",
    "       6.88796461e-01, 5.06941855e-01, 3.52603257e-01, 2.27826789e-01,\n",
    "       1.29971921e-01, 6.07080124e-02, 1.76058263e-02, 1.00801419e-03,\n",
    "       7.81397615e-03, 4.33648415e-02, 1.00349553e-01, 1.72105774e-01,\n",
    "       2.48899922e-01, 3.25683475e-01, 3.99538845e-01, 4.67896134e-01,\n",
    "       5.32739997e-01, 5.91235638e-01, 6.44264936e-01, 6.91527247e-01,\n",
    "       0.7317261 , 0.76765615, 0.79366785, 0.8101723 , 0.81885713,\n",
    "       0.8198994 , 0.8143184 , 0.80478585, 0.7882982 , 0.7812978 ,\n",
    "       0.76776284, 0.76209384, 0.7528379 , 0.7469036 , 0.7426898 ,\n",
    "       0.7392677 , 0.7364249 , 0.73363554, 0.7358924 , 0.73676556,\n",
    "       0.7365562 , 0.73988754, 0.74173874, 0.74344456, 0.74608564,\n",
    "       0.7482979 , 0.75070864, 0.7539025 , 0.7560142 , 0.75822383,\n",
    "       0.76025784, 0.7617975 , 0.76185554, 0.7644145 , 0.76531583,\n",
    "       0.76434743, 0.7639876 , 0.76720524, 0.7672523 , 0.7678288 ,\n",
    "       0.7675803 , 0.76938194, 0.7685974 , 0.769236  , 0.7692172 ,\n",
    "       0.7673927 , 0.76808155, 0.7681907 , 0.7685097 , 0.7688019 ,\n",
    "       0.7697169 , 0.76991284, 0.7699335 , 0.76977706]\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2 = np.array(\n",
    "    [ 1.1795405e-03,  1.1840451e-03,  1.1959869e-03,  1.2207277e-03,\n",
    "        1.2990178e-03,  1.4365296e-03,  1.7058086e-03,  2.1724852e-03,\n",
    "        2.8809647e-03,  3.9416105e-03,  5.2604810e-03,  6.8700342e-03,\n",
    "        8.7222764e-03,  1.0628401e-02,  1.2483117e-02,  1.3960212e-02,\n",
    "        1.4952241e-02,  1.5281168e-02,  1.4801122e-02,  1.3477816e-02,\n",
    "        1.1376112e-02,  8.6813606e-03,  5.6756926e-03,  2.6986429e-03,\n",
    "        1.2146129e-04, -1.7559405e-03, -2.8362253e-03, -3.0895281e-03,\n",
    "       -2.7415555e-03, -2.0914837e-03, -1.5538209e-03, -1.2771582e-03,\n",
    "       -1.2379606e-03, -1.2190365e-03, -1.1613212e-03, -1.0383708e-03,\n",
    "       -6.7628775e-04, -4.5896399e-05,  8.8538841e-04,  2.0719501e-03,\n",
    "        3.4131925e-03,  4.7814972e-03,  6.0838331e-03,  7.2897766e-03,\n",
    "        8.2584750e-03,  9.0717841e-03,  9.7897043e-03,  1.0531691e-02,\n",
    "        1.1325627e-02,  1.2263296e-02,  1.3308296e-02,  1.4508674e-02,\n",
    "        1.5769836e-02,  1.7029645e-02,  1.8130491e-02,  1.8930821e-02,\n",
    "        1.9268043e-02,  1.9004608e-02,  1.8005772e-02,  1.6263932e-02,\n",
    "        1.3815512e-02,  1.0835455e-02,  7.5779622e-03,  4.4179284e-03,\n",
    "        1.6845005e-03, -3.6425062e-04, -1.5768342e-03, -1.9620121e-03,\n",
    "       -1.7005323e-03, -1.1641773e-03, -6.2782411e-04, -4.3140151e-04,\n",
    "       -3.6799020e-04, -4.8707327e-04, -5.7336641e-04, -5.6046143e-04,\n",
    "       -2.7708180e-04,  2.9348352e-04,  1.1843614e-03,  2.3299623e-03,\n",
    "        3.6599853e-03,  5.0171125e-03,  6.3271364e-03,  7.4718776e-03,\n",
    "        8.4157949e-03,  9.0739280e-03,  9.5237447e-03,  9.7771920e-03,\n",
    "        9.8182894e-03,  9.6886335e-03,  9.3794167e-03,  8.9296196e-03,\n",
    "        8.3289687e-03,  7.6236730e-03,  6.8304148e-03,  5.9782993e-03,\n",
    "       0.00511369, 0.00423774, 0.00342795, 0.00269901, 0.00207221,\n",
    "       0.00156748, 0.00118178, 0.00089505, 0.00075626, 0.00059919,\n",
    "       0.00057483, 0.00054736, 0.00061048, 0.00068231, 0.00077182,\n",
    "       0.00088519, 0.00100494, 0.00113517, 0.00122551, 0.00132268,\n",
    "       0.00141375, 0.00146179, 0.00151491, 0.0015564 , 0.00157324,\n",
    "       0.00158186, 0.00157688, 0.0015539 , 0.0015331 , 0.00150503,\n",
    "       0.00147514, 0.00144507, 0.00142254, 0.00138213, 0.00134833,\n",
    "       0.00133906, 0.00132623, 0.00127886, 0.00126368, 0.00124628,\n",
    "       0.00123883, 0.00121707, 0.00121424, 0.00120479, 0.00120179,\n",
    "       0.00121585, 0.00120763, 0.00120626, 0.00120406, 0.00120137,\n",
    "       0.00119406, 0.00119282, 0.00119344, 0.00119479]\n",
    "\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coarse_model_adj(params):\n",
    "    \"\"\"\n",
    "    - Inputs:\n",
    "    - parameters[0] : Overetch \n",
    "    - parameters[1] : Offset\n",
    "    - parameters[2] : Thickness\n",
    "\n",
    "    - Output:\n",
    "    - C : An array containing the computed difference of capacitance \n",
    "    \"\"\"\n",
    "    # Time parameters\n",
    "    t0 = 0                    # Initial time.\n",
    "    tf = 0.0015-1e-5          # Final time.\n",
    "    dt =1e-5                  # Time step size.\n",
    "\n",
    "    # Stiffness parameters\n",
    "    l1 = 221.4*1e-6              # Lenght of the longer beam \n",
    "    l2 = 110*1e-6            # Length of the shorted beam\n",
    "    E  = 160*1e9               # Young Modulus \n",
    "    w  = 2.8*1e-6              # Width \n",
    "\n",
    "    # Force parameters \n",
    "    phi = lambda t: 0.9*(1-np.cos(2*np.pi*2500*t)) if t < 2/2500 else 0 # Voltage in the right electrodes\n",
    "    s   = 101*1e-6             # param for the surface \n",
    "    dp  =1.2*1e-6                # Distance from the plates with Overetch and Offset = 0 \n",
    "\n",
    "    # Mass parameters\n",
    "    rho = 2320                 # Density of the mass.\n",
    "    A   = 84*1e-9              # Area of the component\n",
    "\n",
    "    # Damping parameters \n",
    "    alpha = 31440            # Damping coefficient alpha. 31400\n",
    "    beta  =  0               # Damping coeff beta \n",
    "\n",
    "    # Input Parameters \n",
    "    oe = params[0]*1e-6\n",
    "    of = params[1]*1e-6\n",
    "    th = params[2]*1e-6 # ricorda di rimettere 6\n",
    "   \n",
    "    eps0 = 8.854*1e-12       # Dielectric permittivity constant\n",
    "    eps1 = 1.000             # Relative dielectric permittivity of air.\n",
    "\n",
    "    # Compute the distance between the faces of electrodes and the sensor\n",
    "    dl = dp+2*oe+of\n",
    "    dr = dp+2*oe-of\n",
    "    # Compute the surface of the electrode \n",
    "    S = th * (s - 2*oe) * 10  # multiply by ten since we have 10 condensators\n",
    "    \n",
    "    # Initial conditions\n",
    "    u0 = 0  # Initial displacement\n",
    "    v0 = 0  # Initial velocity\n",
    "    N = int((tf - t0) / dt)\n",
    "\n",
    "    # Initialization\n",
    "    u = np.zeros((N+1))  # displacement\n",
    "    v = np.zeros((N+1))  # velocity\n",
    "    C = np.zeros((N+1))  # capacitance\n",
    "    u[0] = u0\n",
    "    v[0] = v0\n",
    "    C[0] = eps1*eps0*S*(1/(dr)*fringing_coeff( dr, s-2*oe ,th) - 1/(dl)*fringing_coeff( dl, s-2*oe ,th))\n",
    "\n",
    "    # Compute the stiffness\n",
    "    k = compute_stiffness(w, th , E , l1 , l2 , oe) \n",
    "   \n",
    "    # Compute mass\n",
    "    m = rho * A * th\n",
    "    # Compute Damping \n",
    "    damp = alpha* m + beta* k\n",
    "\n",
    "    # Precompute phi values to avoid redundant computation\n",
    "    k1 =  0.5 * eps0 * eps1 * S\n",
    "    k2 = eps1*eps0*S\n",
    "    F_values = np.array([phi(n * dt) for n in range(N)])**2 * k1\n",
    "\n",
    "    # Time-stepping loop using Forward Euler scheme\n",
    "    for n in range(N) :\n",
    "        u_n = u[n]\n",
    "        v_n = v[n]\n",
    "        u_new = u_n + dt * v_n\n",
    "        # Compute the value of the input voltage at time t = n*dt \n",
    "        F = F_values[n]/((dr-u_n)**2)\n",
    "        v[n+1] = v_n + dt * ( F - damp*v_n - k*u_n )/m\n",
    "        # Compute the difference of capacitance\n",
    "        C[n+1] = k2*(1/(dr-u_new)*fringing_coeff( dr-u_new, s-2*oe ,th) - 1/(dl+u_new)*fringing_coeff( dl+u_new, s-2*oe ,th))\n",
    "        u[n+1] = u_new\n",
    "    \n",
    "    # Adjusting phase \n",
    "    C = C*1.02*1e15 + w0*params[0] + w1*params[1] + w2*params[2]\n",
    "\n",
    "    return C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare the model with the exact solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the true samples on which we want to test the corse model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Overetch,   Offset,   Thickness\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 2.3053600e-01, -6.8871000e-02,  3.0351452e+01],\n",
       "       [ 4.5057900e-01, -4.4200000e-04,  2.9471304e+01],\n",
       "       [ 1.5078200e-01, -6.1468000e-02,  3.0962383e+01],\n",
       "       [ 2.6249600e-01, -2.7814000e-02,  2.9626475e+01],\n",
       "       [ 4.8182800e-01, -4.7104400e-01,  2.9200776e+01]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standard library imports\n",
    "import sys\n",
    "# Local module imports\n",
    "sys.path.append('../../src/SurrogateModeling')\n",
    "sys.path.append('../../src/InverseProblems')\n",
    "sys.path.append('../../src/utils')\n",
    "from utils import * \n",
    "\n",
    "# Surrogate Model Configurations\n",
    "CONFIGURATION_I = './config_I.json'\n",
    "data_processor_I = preprocessing(CONFIGURATION_I)\n",
    "\n",
    "# Extract test data \n",
    "X_values, y_values = data_processor_I.X_test, data_processor_I.y_test\n",
    "\n",
    "# Which sample of the training set do wou want to take as experimental input?\n",
    "sample = [5,11, 22, 38, 154]\n",
    "\n",
    "# Select a true sample for testing\n",
    "x_true, y_true = X_values[sample], y_values[sample]\n",
    "print('        Overetch,   Offset,   Thickness')\n",
    "x_true\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform comparisons with different types of inputs of parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The parameters used are: [ 0.230536 -0.068871 30.351452]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-14.089086995520503\n",
      "The parameters used are: [ 4.5057900e-01 -4.4200000e-04  2.9471304e+01]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.04493199632158809\n",
      "The parameters used are: [ 0.150782 -0.061468 30.962383]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-15.675761065008224\n",
      "The parameters used are: [ 2.6249600e-01 -2.7814000e-02  2.9626475e+01]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-5.134908421770849\n",
      "The parameters used are: [ 0.481828 -0.471044 29.200776]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-57.52011571100089\n",
      "Mean absolute percentage error for the simulations are:\n",
      " [0.01041476 0.04580999 0.01416338 0.02856778 0.00344433]\n"
     ]
    }
   ],
   "source": [
    "ratio = []\n",
    "for index, x in enumerate(x_true):\n",
    "    print('The parameters used are:' , x)\n",
    "    res = coarse_model_adj(x) \n",
    "    \n",
    "    plt.plot(res)\n",
    "    plt.plot(y_true[index])\n",
    "    plt.legend(['Coarse Model', 'Fine Model'])\n",
    "    plt.show()\n",
    "    print(res[0])\n",
    "    #print(res/y_true[0])\n",
    "    ratio.append(  np.linalg.norm((res - y_true[index]), ord=1)  / np.linalg.norm(( y_true[index]), ord=1) )\n",
    "\n",
    "#plt.plot(y_true[-1]-res)\n",
    "#plt.show()\n",
    "print('Mean absolute percentage error for the simulations are:\\n', np.array(ratio) ) \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the adjusting coefficients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collecting traing and Testing Data\n",
    "X_train = data_processor_I.X_train\n",
    "X_test = data_processor_I.X_test\n",
    "y_train = data_processor_I.y_train\n",
    "y_test = data_processor_I.y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "coarse_y_train = []\n",
    "coarse_y_test = []\n",
    "for x in X_train:  \n",
    "    coarse_y_train.append(coarse_model(x))\n",
    "for x in X_test:\n",
    "    coarse_y_test.append(coarse_model(x))\n",
    "\n",
    "# Concatenate input parameters and coarse solutions\n",
    "X_train_combined = np.concatenate((X_train, coarse_y_train), axis=1)\n",
    "X_test_combined = np.concatenate((X_test, coarse_y_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucacaroselli/miniconda3/envs/bima/lib/python3.11/site-packages/keras/src/layers/core/dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2807 - val_loss: 0.1082 - learning_rate: 1.0000e-04\n",
      "Epoch 2/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0610 - val_loss: 0.0363 - learning_rate: 1.0000e-04\n",
      "Epoch 3/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0251 - val_loss: 0.0194 - learning_rate: 1.0000e-04\n",
      "Epoch 4/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0157 - val_loss: 0.0161 - learning_rate: 1.0000e-04\n",
      "Epoch 5/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0128 - val_loss: 0.0138 - learning_rate: 1.0000e-04\n",
      "Epoch 6/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0110 - val_loss: 0.0164 - learning_rate: 1.0000e-04\n",
      "Epoch 7/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0125 - val_loss: 0.0160 - learning_rate: 1.0000e-04\n",
      "Epoch 8/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0123 - val_loss: 0.0126 - learning_rate: 1.0000e-04\n",
      "Epoch 9/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0115 - val_loss: 0.0127 - learning_rate: 1.0000e-04\n",
      "Epoch 10/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0108 - val_loss: 0.0124 - learning_rate: 1.0000e-04\n",
      "Epoch 11/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0114 - val_loss: 0.0120 - learning_rate: 1.0000e-04\n",
      "Epoch 12/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0107 - val_loss: 0.0133 - learning_rate: 1.0000e-04\n",
      "Epoch 13/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0104 - val_loss: 0.0119 - learning_rate: 1.0000e-04\n",
      "Epoch 14/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0112 - val_loss: 0.0118 - learning_rate: 1.0000e-04\n",
      "Epoch 15/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0091 - val_loss: 0.0114 - learning_rate: 1.0000e-04\n",
      "Epoch 16/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0105 - val_loss: 0.0121 - learning_rate: 1.0000e-04\n",
      "Epoch 17/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0109 - val_loss: 0.0112 - learning_rate: 1.0000e-04\n",
      "Epoch 18/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0100 - val_loss: 0.0107 - learning_rate: 1.0000e-04\n",
      "Epoch 19/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0092 - val_loss: 0.0137 - learning_rate: 1.0000e-04\n",
      "Epoch 20/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0097 - val_loss: 0.0096 - learning_rate: 1.0000e-04\n",
      "Epoch 21/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0092 - val_loss: 0.0097 - learning_rate: 1.0000e-04\n",
      "Epoch 22/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0088 - val_loss: 0.0107 - learning_rate: 1.0000e-04\n",
      "Epoch 23/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0127 - val_loss: 0.0162 - learning_rate: 1.0000e-04\n",
      "Epoch 24/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0115 - val_loss: 0.0117 - learning_rate: 1.0000e-04\n",
      "Epoch 25/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0115 - val_loss: 0.0148 - learning_rate: 1.0000e-04\n",
      "Epoch 26/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0121 - val_loss: 0.0121 - learning_rate: 1.0000e-04\n",
      "Epoch 27/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0108 - val_loss: 0.0115 - learning_rate: 1.0000e-04\n",
      "Epoch 28/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0152 - val_loss: 0.0198 - learning_rate: 1.0000e-04\n",
      "Epoch 29/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0119 - val_loss: 0.0123 - learning_rate: 1.0000e-04\n",
      "Epoch 30/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0103 - val_loss: 0.0126 - learning_rate: 1.0000e-04\n",
      "Epoch 31/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0107 - val_loss: 0.0098 - learning_rate: 1.0000e-04\n",
      "Epoch 32/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0094 - val_loss: 0.0110 - learning_rate: 1.0000e-04\n",
      "Epoch 33/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0095 - val_loss: 0.0119 - learning_rate: 1.0000e-04\n",
      "Epoch 34/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0108 - val_loss: 0.0130 - learning_rate: 1.0000e-04\n",
      "Epoch 35/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0095 - val_loss: 0.0112 - learning_rate: 1.0000e-04\n",
      "Epoch 36/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0111 - val_loss: 0.0101 - learning_rate: 1.0000e-04\n",
      "Epoch 37/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0086 - val_loss: 0.0109 - learning_rate: 1.0000e-04\n",
      "Epoch 38/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0108 - val_loss: 0.0114 - learning_rate: 1.0000e-04\n",
      "Epoch 39/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0096 - val_loss: 0.0096 - learning_rate: 1.0000e-04\n",
      "Epoch 40/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0086 - val_loss: 0.0129 - learning_rate: 1.0000e-04\n",
      "Epoch 41/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0110 - val_loss: 0.0103 - learning_rate: 1.0000e-04\n",
      "Epoch 42/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0095 - val_loss: 0.0108 - learning_rate: 1.0000e-04\n",
      "Epoch 43/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0092 - val_loss: 0.0226 - learning_rate: 1.0000e-04\n",
      "Epoch 44/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0121 - val_loss: 0.0118 - learning_rate: 1.0000e-04\n",
      "Epoch 45/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0116 - val_loss: 0.0133 - learning_rate: 1.0000e-04\n",
      "Epoch 46/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0132 - val_loss: 0.0114 - learning_rate: 1.0000e-04\n",
      "Epoch 47/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0103 - val_loss: 0.0105 - learning_rate: 1.0000e-04\n",
      "Epoch 48/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0094 - val_loss: 0.0109 - learning_rate: 1.0000e-04\n",
      "Epoch 49/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0110 - val_loss: 0.0123 - learning_rate: 1.0000e-04\n",
      "Epoch 50/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0099 - val_loss: 0.0141 - learning_rate: 1.0000e-04\n",
      "Epoch 51/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0118 - val_loss: 0.0134 - learning_rate: 1.0000e-04\n",
      "Epoch 52/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0118 - val_loss: 0.0192 - learning_rate: 1.0000e-04\n",
      "Epoch 53/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0122 - val_loss: 0.0123 - learning_rate: 1.0000e-04\n",
      "Epoch 54/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0098 - val_loss: 0.0118 - learning_rate: 1.0000e-04\n",
      "Epoch 55/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0093 - val_loss: 0.0164 - learning_rate: 1.0000e-04\n",
      "Epoch 56/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0134 - val_loss: 0.0112 - learning_rate: 1.0000e-04\n",
      "Epoch 57/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0112 - val_loss: 0.0140 - learning_rate: 1.0000e-04\n",
      "Epoch 58/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0099 - val_loss: 0.0089 - learning_rate: 1.0000e-04\n",
      "Epoch 59/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0097 - val_loss: 0.0144 - learning_rate: 1.0000e-04\n",
      "Epoch 60/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0125 - val_loss: 0.0125 - learning_rate: 1.0000e-04\n",
      "Epoch 61/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0102 - val_loss: 0.0103 - learning_rate: 1.0000e-04\n",
      "Epoch 62/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0092 - val_loss: 0.0129 - learning_rate: 1.0000e-04\n",
      "Epoch 63/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0146 - val_loss: 0.0281 - learning_rate: 1.0000e-04\n",
      "Epoch 64/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0145 - val_loss: 0.0153 - learning_rate: 1.0000e-04\n",
      "Epoch 65/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0131 - val_loss: 0.0139 - learning_rate: 1.0000e-04\n",
      "Epoch 66/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0139 - val_loss: 0.0186 - learning_rate: 1.0000e-04\n",
      "Epoch 67/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0122 - val_loss: 0.0133 - learning_rate: 1.0000e-04\n",
      "Epoch 68/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0099 - val_loss: 0.0103 - learning_rate: 1.0000e-04\n",
      "Epoch 69/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0093 - val_loss: 0.0091 - learning_rate: 1.0000e-04\n",
      "Epoch 70/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0105 - val_loss: 0.0113 - learning_rate: 1.0000e-04\n",
      "Epoch 71/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0091 - val_loss: 0.0094 - learning_rate: 1.0000e-04\n",
      "Epoch 72/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0087 - val_loss: 0.0153 - learning_rate: 1.0000e-04\n",
      "Epoch 73/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0131 - val_loss: 0.0136 - learning_rate: 1.0000e-04\n",
      "Epoch 74/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0121 - val_loss: 0.0123 - learning_rate: 1.0000e-04\n",
      "Epoch 75/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0114 - val_loss: 0.0125 - learning_rate: 1.0000e-04\n",
      "Epoch 76/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0123 - val_loss: 0.0128 - learning_rate: 1.0000e-04\n",
      "Epoch 77/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0122 - val_loss: 0.0155 - learning_rate: 1.0000e-04\n",
      "Epoch 78/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0128 - val_loss: 0.0115 - learning_rate: 1.0000e-04\n",
      "Epoch 79/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0153 - val_loss: 0.0127 - learning_rate: 1.0000e-04\n",
      "Epoch 80/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0139 - val_loss: 0.0143 - learning_rate: 1.0000e-04\n",
      "Epoch 81/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0104 - val_loss: 0.0103 - learning_rate: 1.0000e-04\n",
      "Epoch 82/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0098 - val_loss: 0.0176 - learning_rate: 1.0000e-04\n",
      "Epoch 83/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0105 - val_loss: 0.0208 - learning_rate: 1.0000e-04\n",
      "Epoch 84/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0253 - val_loss: 0.0458 - learning_rate: 1.0000e-04\n",
      "Epoch 85/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0265 - val_loss: 0.0282 - learning_rate: 1.0000e-04\n",
      "Epoch 86/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0144 - val_loss: 0.0136 - learning_rate: 1.0000e-04\n",
      "Epoch 87/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0108 - val_loss: 0.0131 - learning_rate: 1.0000e-04\n",
      "Epoch 88/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0144 - val_loss: 0.0159 - learning_rate: 1.0000e-04\n",
      "Epoch 89/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0118 - val_loss: 0.0113 - learning_rate: 1.0000e-04\n",
      "Epoch 90/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0096 - val_loss: 0.0117 - learning_rate: 1.0000e-04\n",
      "Epoch 91/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0108 - val_loss: 0.0118 - learning_rate: 1.0000e-04\n",
      "Epoch 92/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0098 - val_loss: 0.0115 - learning_rate: 1.0000e-04\n",
      "Epoch 93/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0110 - val_loss: 0.0103 - learning_rate: 1.0000e-04\n",
      "Epoch 94/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0099 - val_loss: 0.0115 - learning_rate: 1.0000e-04\n",
      "Epoch 95/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0096 - val_loss: 0.0159 - learning_rate: 1.0000e-04\n",
      "Epoch 96/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0115 - val_loss: 0.0120 - learning_rate: 1.0000e-04\n",
      "Epoch 97/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0101 - val_loss: 0.0167 - learning_rate: 1.0000e-04\n",
      "Epoch 98/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0130 - val_loss: 0.0137 - learning_rate: 1.0000e-04\n",
      "Epoch 99/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0152 - val_loss: 0.0182 - learning_rate: 1.0000e-04\n",
      "Epoch 100/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0156 - val_loss: 0.0109 - learning_rate: 1.0000e-04\n",
      "Epoch 101/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0123 - val_loss: 0.0120 - learning_rate: 1.0000e-04\n",
      "Epoch 102/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0093 - val_loss: 0.0104 - learning_rate: 1.0000e-04\n",
      "Epoch 103/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0099 - val_loss: 0.0132 - learning_rate: 1.0000e-04\n",
      "Epoch 104/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0109 - val_loss: 0.0121 - learning_rate: 1.0000e-04\n",
      "Epoch 105/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0118 - val_loss: 0.0121 - learning_rate: 1.0000e-04\n",
      "Epoch 106/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0107 - val_loss: 0.0109 - learning_rate: 1.0000e-04\n",
      "Epoch 107/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0116 - val_loss: 0.0168 - learning_rate: 1.0000e-04\n",
      "Epoch 108/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0137 - val_loss: 0.0106 - learning_rate: 1.0000e-04\n",
      "Epoch 109/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0109 - val_loss: 0.0130 - learning_rate: 1.0000e-04\n",
      "Epoch 110/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0095 - val_loss: 0.0118 - learning_rate: 1.0000e-04\n",
      "Epoch 111/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0094 - val_loss: 0.0109 - learning_rate: 1.0000e-04\n",
      "Epoch 112/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0105 - val_loss: 0.0113 - learning_rate: 1.0000e-04\n",
      "Epoch 113/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0117 - val_loss: 0.0164 - learning_rate: 1.0000e-04\n",
      "Epoch 114/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0122 - val_loss: 0.0125 - learning_rate: 1.0000e-04\n",
      "Epoch 115/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0099 - val_loss: 0.0089 - learning_rate: 1.0000e-04\n",
      "Epoch 116/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0095 - val_loss: 0.0107 - learning_rate: 1.0000e-04\n",
      "Epoch 117/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0086 - val_loss: 0.0101 - learning_rate: 1.0000e-04\n",
      "Epoch 118/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0101 - val_loss: 0.0120 - learning_rate: 1.0000e-04\n",
      "Epoch 119/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0114 - val_loss: 0.0145 - learning_rate: 1.0000e-04\n",
      "Epoch 120/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0109 - val_loss: 0.0106 - learning_rate: 1.0000e-04\n",
      "Epoch 121/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0085 - val_loss: 0.0165 - learning_rate: 1.0000e-04\n",
      "Epoch 122/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0129 - val_loss: 0.0155 - learning_rate: 1.0000e-04\n",
      "Epoch 123/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0171 - val_loss: 0.0158 - learning_rate: 1.0000e-04\n",
      "Epoch 124/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0110 - val_loss: 0.0098 - learning_rate: 1.0000e-04\n",
      "Epoch 125/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0088 - val_loss: 0.0095 - learning_rate: 1.0000e-04\n",
      "Epoch 126/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0102 - val_loss: 0.0129 - learning_rate: 1.0000e-04\n",
      "Epoch 127/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0118 - val_loss: 0.0138 - learning_rate: 1.0000e-04\n",
      "Epoch 128/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0109 - val_loss: 0.0093 - learning_rate: 1.0000e-04\n",
      "Epoch 129/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0093 - val_loss: 0.0092 - learning_rate: 1.0000e-04\n",
      "Epoch 130/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0097 - val_loss: 0.0110 - learning_rate: 1.0000e-04\n",
      "Epoch 131/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0099 - val_loss: 0.0138 - learning_rate: 1.0000e-04\n",
      "Epoch 132/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0108 - val_loss: 0.0105 - learning_rate: 1.0000e-04\n",
      "Epoch 133/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0083 - val_loss: 0.0104 - learning_rate: 1.0000e-04\n",
      "Epoch 134/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0101 - val_loss: 0.0118 - learning_rate: 1.0000e-04\n",
      "Epoch 135/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0088 - val_loss: 0.0112 - learning_rate: 1.0000e-04\n",
      "Epoch 136/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0092 - val_loss: 0.0111 - learning_rate: 1.0000e-04\n",
      "Epoch 137/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0107 - val_loss: 0.0103 - learning_rate: 1.0000e-04\n",
      "Epoch 138/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0111 - val_loss: 0.0126 - learning_rate: 1.0000e-04\n",
      "Epoch 139/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0123 - val_loss: 0.0167 - learning_rate: 1.0000e-04\n",
      "Epoch 140/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0162 - val_loss: 0.0184 - learning_rate: 1.0000e-04\n",
      "Epoch 141/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0160 - val_loss: 0.0251 - learning_rate: 1.0000e-04\n",
      "Epoch 142/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0286 - val_loss: 0.0255 - learning_rate: 1.0000e-04\n",
      "Epoch 143/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0168 - val_loss: 0.0140 - learning_rate: 1.0000e-04\n",
      "Epoch 144/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0103 - val_loss: 0.0113 - learning_rate: 1.0000e-04\n",
      "Epoch 145/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0104 - val_loss: 0.0121 - learning_rate: 1.0000e-04\n",
      "Epoch 146/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0133 - val_loss: 0.0135 - learning_rate: 1.0000e-04\n",
      "Epoch 147/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0099 - val_loss: 0.0115 - learning_rate: 1.0000e-04\n",
      "Epoch 148/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0111 - val_loss: 0.0143 - learning_rate: 1.0000e-04\n",
      "Epoch 149/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0127 - val_loss: 0.0110 - learning_rate: 1.0000e-04\n",
      "Epoch 150/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0108 - val_loss: 0.0160 - learning_rate: 1.0000e-04\n",
      "Epoch 151/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0105 - val_loss: 0.0110 - learning_rate: 1.0000e-04\n",
      "Epoch 152/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0089 - val_loss: 0.0095 - learning_rate: 1.0000e-04\n",
      "Epoch 153/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0085 - val_loss: 0.0123 - learning_rate: 1.0000e-04\n",
      "Epoch 154/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0104 - val_loss: 0.0128 - learning_rate: 1.0000e-04\n",
      "Epoch 155/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0105 - val_loss: 0.0094 - learning_rate: 1.0000e-04\n",
      "Epoch 156/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0087 - val_loss: 0.0141 - learning_rate: 1.0000e-04\n",
      "Epoch 157/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0105 - val_loss: 0.0167 - learning_rate: 1.0000e-04\n",
      "Epoch 158/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0131 - val_loss: 0.0200 - learning_rate: 1.0000e-04\n",
      "Epoch 159/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0134 - val_loss: 0.0133 - learning_rate: 1.0000e-04\n",
      "Epoch 160/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0166 - val_loss: 0.0108 - learning_rate: 1.0000e-04\n",
      "Epoch 161/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0112 - val_loss: 0.0152 - learning_rate: 1.0000e-04\n",
      "Epoch 162/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0113 - val_loss: 0.0130 - learning_rate: 1.0000e-04\n",
      "Epoch 163/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0100 - val_loss: 0.0111 - learning_rate: 1.0000e-04\n",
      "Epoch 164/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0120 - val_loss: 0.0267 - learning_rate: 1.0000e-04\n",
      "Epoch 165/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0163 - val_loss: 0.0117 - learning_rate: 1.0000e-04\n",
      "Epoch 166/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0110 - val_loss: 0.0138 - learning_rate: 1.0000e-04\n",
      "Epoch 167/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0103 - val_loss: 0.0093 - learning_rate: 1.0000e-04\n",
      "Epoch 168/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0105 - val_loss: 0.0107 - learning_rate: 1.0000e-04\n",
      "Epoch 169/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0100 - val_loss: 0.0137 - learning_rate: 1.0000e-04\n",
      "Epoch 170/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0100 - val_loss: 0.0097 - learning_rate: 1.0000e-04\n",
      "Epoch 171/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0089 - val_loss: 0.0115 - learning_rate: 1.0000e-04\n",
      "Epoch 172/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0096 - val_loss: 0.0109 - learning_rate: 1.0000e-04\n",
      "Epoch 173/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0103 - val_loss: 0.0110 - learning_rate: 1.0000e-04\n",
      "Epoch 174/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0108 - val_loss: 0.0102 - learning_rate: 1.0000e-04\n",
      "Epoch 175/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0093 - val_loss: 0.0099 - learning_rate: 1.0000e-04\n",
      "Epoch 176/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0086 - val_loss: 0.0097 - learning_rate: 1.0000e-04\n",
      "Epoch 177/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0098 - val_loss: 0.0107 - learning_rate: 1.0000e-04\n",
      "Epoch 178/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0103 - val_loss: 0.0140 - learning_rate: 1.0000e-04\n",
      "Epoch 179/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0107 - val_loss: 0.0181 - learning_rate: 1.0000e-04\n",
      "Epoch 180/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0180 - val_loss: 0.0218 - learning_rate: 1.0000e-04\n",
      "Epoch 181/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0174 - val_loss: 0.0167 - learning_rate: 1.0000e-04\n",
      "Epoch 182/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0124 - val_loss: 0.0151 - learning_rate: 1.0000e-04\n",
      "Epoch 183/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0098 - val_loss: 0.0114 - learning_rate: 1.0000e-04\n",
      "Epoch 184/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0137 - val_loss: 0.0113 - learning_rate: 1.0000e-04\n",
      "Epoch 185/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0107 - val_loss: 0.0123 - learning_rate: 1.0000e-04\n",
      "Epoch 186/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0105 - val_loss: 0.0151 - learning_rate: 1.0000e-04\n",
      "Epoch 187/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0115 - val_loss: 0.0155 - learning_rate: 1.0000e-04\n",
      "Epoch 188/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0137 - val_loss: 0.0150 - learning_rate: 1.0000e-04\n",
      "Epoch 189/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0108 - val_loss: 0.0120 - learning_rate: 1.0000e-04\n",
      "Epoch 190/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0106 - val_loss: 0.0098 - learning_rate: 1.0000e-04\n",
      "Epoch 191/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0098 - val_loss: 0.0107 - learning_rate: 1.0000e-04\n",
      "Epoch 192/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0093 - val_loss: 0.0204 - learning_rate: 1.0000e-04\n",
      "Epoch 193/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0126 - val_loss: 0.0103 - learning_rate: 1.0000e-04\n",
      "Epoch 194/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0092 - val_loss: 0.0092 - learning_rate: 1.0000e-04\n",
      "Epoch 195/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0090 - val_loss: 0.0104 - learning_rate: 1.0000e-04\n",
      "Epoch 196/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0105 - val_loss: 0.0118 - learning_rate: 1.0000e-04\n",
      "Epoch 197/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0140 - val_loss: 0.0116 - learning_rate: 1.0000e-04\n",
      "Epoch 198/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0103 - val_loss: 0.0093 - learning_rate: 1.0000e-04\n",
      "Epoch 199/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0149 - val_loss: 0.0135 - learning_rate: 1.0000e-04\n",
      "Epoch 200/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0131 - val_loss: 0.0146 - learning_rate: 1.0000e-04\n",
      "Epoch 201/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0128 - val_loss: 0.0096 - learning_rate: 1.0000e-04\n",
      "Epoch 202/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0100 - val_loss: 0.0122 - learning_rate: 1.0000e-04\n",
      "Epoch 203/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0099 - val_loss: 0.0125 - learning_rate: 1.0000e-04\n",
      "Epoch 204/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0095 - val_loss: 0.0150 - learning_rate: 1.0000e-04\n",
      "Epoch 205/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0119 - val_loss: 0.0100 - learning_rate: 1.0000e-04\n",
      "Epoch 206/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0093 - val_loss: 0.0092 - learning_rate: 1.0000e-04\n",
      "Epoch 207/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 - val_loss: 0.0109 - learning_rate: 1.0000e-04\n",
      "Epoch 208/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0102 - val_loss: 0.0090 - learning_rate: 1.0000e-04\n",
      "Epoch 209/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 - val_loss: 0.0097 - learning_rate: 1.0000e-04\n",
      "Epoch 210/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0116 - val_loss: 0.0099 - learning_rate: 1.0000e-04\n",
      "Epoch 211/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0092 - val_loss: 0.0101 - learning_rate: 1.0000e-04\n",
      "Epoch 212/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0097 - val_loss: 0.0101 - learning_rate: 1.0000e-04\n",
      "Epoch 213/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0091 - val_loss: 0.0185 - learning_rate: 1.0000e-04\n",
      "Epoch 214/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0110 - val_loss: 0.0137 - learning_rate: 1.0000e-04\n",
      "Epoch 215/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0103 - val_loss: 0.0086 - learning_rate: 1.0000e-04\n",
      "Epoch 216/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0101 - val_loss: 0.0114 - learning_rate: 1.0000e-04\n",
      "Epoch 217/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0106 - val_loss: 0.0148 - learning_rate: 1.0000e-04\n",
      "Epoch 218/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0150 - val_loss: 0.0231 - learning_rate: 1.0000e-04\n",
      "Epoch 219/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0143 - val_loss: 0.0121 - learning_rate: 1.0000e-04\n",
      "Epoch 220/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0141 - val_loss: 0.0422 - learning_rate: 1.0000e-04\n",
      "Epoch 221/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0237 - val_loss: 0.0138 - learning_rate: 1.0000e-04\n",
      "Epoch 222/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0108 - val_loss: 0.0092 - learning_rate: 1.0000e-04\n",
      "Epoch 223/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0088 - val_loss: 0.0093 - learning_rate: 1.0000e-04\n",
      "Epoch 224/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0083 - val_loss: 0.0118 - learning_rate: 1.0000e-04\n",
      "Epoch 225/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0116 - val_loss: 0.0108 - learning_rate: 1.0000e-04\n",
      "Epoch 226/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0105 - val_loss: 0.0117 - learning_rate: 1.0000e-04\n",
      "Epoch 227/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0105 - val_loss: 0.0132 - learning_rate: 1.0000e-04\n",
      "Epoch 228/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0094 - val_loss: 0.0092 - learning_rate: 1.0000e-04\n",
      "Epoch 229/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0098 - val_loss: 0.0114 - learning_rate: 1.0000e-04\n",
      "Epoch 230/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0101 - val_loss: 0.0135 - learning_rate: 1.0000e-04\n",
      "Epoch 231/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0108 - val_loss: 0.0122 - learning_rate: 1.0000e-04\n",
      "Epoch 232/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0103 - val_loss: 0.0158 - learning_rate: 1.0000e-04\n",
      "Epoch 233/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0102 - val_loss: 0.0093 - learning_rate: 1.0000e-04\n",
      "Epoch 234/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0089 - val_loss: 0.0137 - learning_rate: 1.0000e-04\n",
      "Epoch 235/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0149 - val_loss: 0.0272 - learning_rate: 1.0000e-04\n",
      "Epoch 236/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0213 - val_loss: 0.0150 - learning_rate: 1.0000e-04\n",
      "Epoch 237/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0125 - val_loss: 0.0186 - learning_rate: 1.0000e-04\n",
      "Epoch 238/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0137 - val_loss: 0.0098 - learning_rate: 1.0000e-04\n",
      "Epoch 239/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0105 - val_loss: 0.0107 - learning_rate: 1.0000e-04\n",
      "Epoch 240/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0091 - val_loss: 0.0089 - learning_rate: 1.0000e-04\n",
      "Epoch 241/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0085 - val_loss: 0.0129 - learning_rate: 1.0000e-04\n",
      "Epoch 242/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0102 - val_loss: 0.0167 - learning_rate: 1.0000e-04\n",
      "Epoch 243/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0109 - val_loss: 0.0119 - learning_rate: 1.0000e-04\n",
      "Epoch 244/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0093 - val_loss: 0.0152 - learning_rate: 1.0000e-04\n",
      "Epoch 245/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0140 - val_loss: 0.0209 - learning_rate: 1.0000e-04\n",
      "Epoch 246/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0145 - val_loss: 0.0125 - learning_rate: 1.0000e-04\n",
      "Epoch 247/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0101 - val_loss: 0.0144 - learning_rate: 1.0000e-04\n",
      "Epoch 248/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0132 - val_loss: 0.0118 - learning_rate: 1.0000e-04\n",
      "Epoch 249/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0096 - val_loss: 0.0090 - learning_rate: 1.0000e-04\n",
      "Epoch 250/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0084 - val_loss: 0.0118 - learning_rate: 1.0000e-04\n",
      "Epoch 251/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0102 - val_loss: 0.0171 - learning_rate: 1.0000e-04\n",
      "Epoch 252/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0108 - val_loss: 0.0113 - learning_rate: 1.0000e-04\n",
      "Epoch 253/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0104 - val_loss: 0.0100 - learning_rate: 1.0000e-04\n",
      "Epoch 254/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0102 - val_loss: 0.0124 - learning_rate: 1.0000e-04\n",
      "Epoch 255/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0107 - val_loss: 0.0139 - learning_rate: 1.0000e-04\n",
      "Epoch 256/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0114 - val_loss: 0.0110 - learning_rate: 1.0000e-04\n",
      "Epoch 257/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0109 - val_loss: 0.0117 - learning_rate: 1.0000e-04\n",
      "Epoch 258/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0086 - val_loss: 0.0168 - learning_rate: 1.0000e-04\n",
      "Epoch 259/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0096 - val_loss: 0.0106 - learning_rate: 1.0000e-04\n",
      "Epoch 260/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0120 - val_loss: 0.0148 - learning_rate: 1.0000e-04\n",
      "Epoch 261/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0112 - val_loss: 0.0145 - learning_rate: 1.0000e-04\n",
      "Epoch 262/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0137 - val_loss: 0.0152 - learning_rate: 1.0000e-04\n",
      "Epoch 263/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0139 - val_loss: 0.0337 - learning_rate: 1.0000e-04\n",
      "Epoch 264/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0218 - val_loss: 0.0204 - learning_rate: 1.0000e-04\n",
      "Epoch 265/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0129 - val_loss: 0.0171 - learning_rate: 1.0000e-04\n",
      "Epoch 266/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0102 - val_loss: 0.0108 - learning_rate: 1.0000e-04\n",
      "Epoch 267/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0103 - val_loss: 0.0138 - learning_rate: 1.0000e-04\n",
      "Epoch 268/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0102 - val_loss: 0.0103 - learning_rate: 1.0000e-04\n",
      "Epoch 269/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0092 - val_loss: 0.0110 - learning_rate: 1.0000e-04\n",
      "Epoch 270/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0123 - val_loss: 0.0113 - learning_rate: 1.0000e-04\n",
      "Epoch 271/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0143 - val_loss: 0.0116 - learning_rate: 1.0000e-04\n",
      "Epoch 272/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0104 - val_loss: 0.0136 - learning_rate: 1.0000e-04\n",
      "Epoch 273/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0108 - val_loss: 0.0126 - learning_rate: 1.0000e-04\n",
      "Epoch 274/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0102 - val_loss: 0.0127 - learning_rate: 1.0000e-04\n",
      "Epoch 275/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0138 - val_loss: 0.0155 - learning_rate: 1.0000e-04\n",
      "Epoch 276/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0136 - val_loss: 0.0112 - learning_rate: 1.0000e-04\n",
      "Epoch 277/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0102 - val_loss: 0.0103 - learning_rate: 1.0000e-04\n",
      "Epoch 278/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0109 - val_loss: 0.0128 - learning_rate: 1.0000e-04\n",
      "Epoch 279/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0091 - val_loss: 0.0089 - learning_rate: 1.0000e-04\n",
      "Epoch 280/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0300 - learning_rate: 1.0000e-04\n",
      "Epoch 281/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0172 - val_loss: 0.0090 - learning_rate: 1.0000e-04\n",
      "Epoch 282/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0093 - val_loss: 0.0092 - learning_rate: 1.0000e-04\n",
      "Epoch 283/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0101 - val_loss: 0.0124 - learning_rate: 1.0000e-04\n",
      "Epoch 284/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0095 - val_loss: 0.0098 - learning_rate: 1.0000e-04\n",
      "Epoch 285/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0112 - val_loss: 0.0099 - learning_rate: 1.0000e-04\n",
      "Epoch 286/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0092 - val_loss: 0.0118 - learning_rate: 1.0000e-04\n",
      "Epoch 287/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0105 - learning_rate: 1.0000e-04\n",
      "Epoch 288/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0090 - val_loss: 0.0102 - learning_rate: 1.0000e-04\n",
      "Epoch 289/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0115 - val_loss: 0.0109 - learning_rate: 1.0000e-04\n",
      "Epoch 290/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0098 - val_loss: 0.0137 - learning_rate: 1.0000e-04\n",
      "Epoch 291/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0098 - val_loss: 0.0125 - learning_rate: 1.0000e-04\n",
      "Epoch 292/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0106 - val_loss: 0.0094 - learning_rate: 1.0000e-04\n",
      "Epoch 293/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0128 - val_loss: 0.0131 - learning_rate: 1.0000e-04\n",
      "Epoch 294/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0094 - val_loss: 0.0109 - learning_rate: 1.0000e-04\n",
      "Epoch 295/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0122 - val_loss: 0.0155 - learning_rate: 1.0000e-04\n",
      "Epoch 296/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0130 - val_loss: 0.0123 - learning_rate: 1.0000e-04\n",
      "Epoch 297/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0116 - val_loss: 0.0108 - learning_rate: 1.0000e-04\n",
      "Epoch 298/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0100 - val_loss: 0.0094 - learning_rate: 1.0000e-04\n",
      "Epoch 299/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0086 - val_loss: 0.0116 - learning_rate: 1.0000e-04\n",
      "Epoch 300/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0089 - val_loss: 0.0114 - learning_rate: 1.0000e-04\n",
      "Epoch 301/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0094 - val_loss: 0.0129 - learning_rate: 1.0000e-04\n",
      "Epoch 302/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0106 - val_loss: 0.0090 - learning_rate: 1.0000e-04\n",
      "Epoch 303/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0098 - val_loss: 0.0101 - learning_rate: 1.0000e-04\n",
      "Epoch 304/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0107 - val_loss: 0.0093 - learning_rate: 1.0000e-04\n",
      "Epoch 305/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0098 - val_loss: 0.0103 - learning_rate: 1.0000e-04\n",
      "Epoch 306/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0101 - val_loss: 0.0100 - learning_rate: 1.0000e-04\n",
      "Epoch 307/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0110 - val_loss: 0.0100 - learning_rate: 1.0000e-04\n",
      "Epoch 308/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0103 - val_loss: 0.0164 - learning_rate: 1.0000e-04\n",
      "Epoch 309/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0132 - val_loss: 0.0109 - learning_rate: 1.0000e-04\n",
      "Epoch 310/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0120 - val_loss: 0.0131 - learning_rate: 1.0000e-04\n",
      "Epoch 311/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0110 - val_loss: 0.0124 - learning_rate: 1.0000e-04\n",
      "Epoch 312/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0097 - val_loss: 0.0123 - learning_rate: 1.0000e-04\n",
      "Epoch 313/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0114 - val_loss: 0.0198 - learning_rate: 1.0000e-04\n",
      "Epoch 314/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0172 - val_loss: 0.0153 - learning_rate: 1.0000e-04\n",
      "Epoch 315/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0194 - val_loss: 0.0122 - learning_rate: 1.0000e-04\n",
      "Epoch 316/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0143 - val_loss: 0.0138 - learning_rate: 1.0000e-04\n",
      "Epoch 317/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0138 - val_loss: 0.0132 - learning_rate: 1.0000e-04\n",
      "Epoch 318/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0107 - val_loss: 0.0176 - learning_rate: 1.0000e-04\n",
      "Epoch 319/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0140 - val_loss: 0.0121 - learning_rate: 1.0000e-04\n",
      "Epoch 320/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0101 - val_loss: 0.0093 - learning_rate: 1.0000e-04\n",
      "Epoch 321/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0091 - val_loss: 0.0098 - learning_rate: 1.0000e-04\n",
      "Epoch 322/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0091 - val_loss: 0.0117 - learning_rate: 1.0000e-04\n",
      "Epoch 323/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0119 - val_loss: 0.0118 - learning_rate: 1.0000e-04\n",
      "Epoch 324/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0108 - val_loss: 0.0096 - learning_rate: 1.0000e-04\n",
      "Epoch 325/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0118 - val_loss: 0.0127 - learning_rate: 1.0000e-04\n",
      "Epoch 326/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0107 - val_loss: 0.0101 - learning_rate: 1.0000e-04\n",
      "Epoch 327/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0096 - val_loss: 0.0130 - learning_rate: 1.0000e-04\n",
      "Epoch 328/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0114 - val_loss: 0.0110 - learning_rate: 1.0000e-04\n",
      "Epoch 329/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0108 - val_loss: 0.0123 - learning_rate: 1.0000e-04\n",
      "Epoch 330/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0140 - val_loss: 0.0099 - learning_rate: 1.0000e-04\n",
      "Epoch 331/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0099 - val_loss: 0.0119 - learning_rate: 1.0000e-04\n",
      "Epoch 332/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0107 - val_loss: 0.0125 - learning_rate: 1.0000e-04\n",
      "Epoch 333/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0101 - val_loss: 0.0115 - learning_rate: 1.0000e-04\n",
      "Epoch 334/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0125 - val_loss: 0.0209 - learning_rate: 1.0000e-04\n",
      "Epoch 335/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0131 - val_loss: 0.0134 - learning_rate: 1.0000e-04\n",
      "Epoch 336/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0111 - val_loss: 0.0122 - learning_rate: 1.0000e-04\n",
      "Epoch 337/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0113 - val_loss: 0.0213 - learning_rate: 1.0000e-04\n",
      "Epoch 338/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0159 - val_loss: 0.0139 - learning_rate: 1.0000e-04\n",
      "Epoch 339/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0118 - val_loss: 0.0103 - learning_rate: 1.0000e-04\n",
      "Epoch 340/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0114 - val_loss: 0.0127 - learning_rate: 1.0000e-04\n",
      "Epoch 341/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0119 - val_loss: 0.0138 - learning_rate: 1.0000e-04\n",
      "Epoch 342/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0105 - val_loss: 0.0091 - learning_rate: 1.0000e-04\n",
      "Epoch 343/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 - val_loss: 0.0114 - learning_rate: 1.0000e-04\n",
      "Epoch 344/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0091 - val_loss: 0.0103 - learning_rate: 1.0000e-04\n",
      "Epoch 345/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0094 - val_loss: 0.0109 - learning_rate: 1.0000e-04\n",
      "Epoch 346/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0098 - val_loss: 0.0109 - learning_rate: 1.0000e-04\n",
      "Epoch 347/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0082 - val_loss: 0.0106 - learning_rate: 1.0000e-04\n",
      "Epoch 348/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0123 - val_loss: 0.0111 - learning_rate: 1.0000e-04\n",
      "Epoch 349/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0089 - val_loss: 0.0146 - learning_rate: 1.0000e-04\n",
      "Epoch 350/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0113 - val_loss: 0.0114 - learning_rate: 1.0000e-04\n",
      "Epoch 351/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0118 - val_loss: 0.0104 - learning_rate: 1.0000e-04\n",
      "Epoch 352/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0093 - val_loss: 0.0175 - learning_rate: 1.0000e-04\n",
      "Epoch 353/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0151 - val_loss: 0.0130 - learning_rate: 1.0000e-04\n",
      "Epoch 354/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0126 - val_loss: 0.0099 - learning_rate: 1.0000e-04\n",
      "Epoch 355/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0127 - val_loss: 0.0197 - learning_rate: 1.0000e-04\n",
      "Epoch 356/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0182 - val_loss: 0.0217 - learning_rate: 1.0000e-04\n",
      "Epoch 357/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0176 - val_loss: 0.0117 - learning_rate: 1.0000e-04\n",
      "Epoch 358/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0107 - val_loss: 0.0129 - learning_rate: 1.0000e-04\n",
      "Epoch 359/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0102 - val_loss: 0.0112 - learning_rate: 1.0000e-04\n",
      "Epoch 360/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0106 - val_loss: 0.0272 - learning_rate: 1.0000e-04\n",
      "Epoch 361/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0134 - val_loss: 0.0158 - learning_rate: 1.0000e-04\n",
      "Epoch 362/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0127 - val_loss: 0.0167 - learning_rate: 1.0000e-04\n",
      "Epoch 363/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0112 - val_loss: 0.0206 - learning_rate: 1.0000e-04\n",
      "Epoch 364/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0182 - val_loss: 0.0255 - learning_rate: 1.0000e-04\n",
      "Epoch 365/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0169 - val_loss: 0.0112 - learning_rate: 1.0000e-04\n",
      "Epoch 366/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0122 - val_loss: 0.0328 - learning_rate: 1.0000e-04\n",
      "Epoch 367/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0164 - val_loss: 0.0091 - learning_rate: 1.0000e-04\n",
      "Epoch 368/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0101 - val_loss: 0.0097 - learning_rate: 1.0000e-04\n",
      "Epoch 369/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0085 - val_loss: 0.0101 - learning_rate: 1.0000e-04\n",
      "Epoch 370/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0090 - val_loss: 0.0097 - learning_rate: 1.0000e-04\n",
      "Epoch 371/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0089 - val_loss: 0.0150 - learning_rate: 1.0000e-04\n",
      "Epoch 372/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0107 - val_loss: 0.0115 - learning_rate: 1.0000e-04\n",
      "Epoch 373/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0105 - val_loss: 0.0124 - learning_rate: 1.0000e-04\n",
      "Epoch 374/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0096 - val_loss: 0.0130 - learning_rate: 1.0000e-04\n",
      "Epoch 375/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0120 - val_loss: 0.0098 - learning_rate: 1.0000e-04\n",
      "Epoch 376/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0093 - val_loss: 0.0113 - learning_rate: 1.0000e-04\n",
      "Epoch 377/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0096 - val_loss: 0.0105 - learning_rate: 1.0000e-04\n",
      "Epoch 378/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0101 - val_loss: 0.0115 - learning_rate: 1.0000e-04\n",
      "Epoch 379/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0093 - val_loss: 0.0128 - learning_rate: 1.0000e-04\n",
      "Epoch 380/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0127 - val_loss: 0.0126 - learning_rate: 1.0000e-04\n",
      "Epoch 381/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0130 - val_loss: 0.0126 - learning_rate: 1.0000e-04\n",
      "Epoch 382/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0124 - val_loss: 0.0165 - learning_rate: 1.0000e-04\n",
      "Epoch 383/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0136 - val_loss: 0.0111 - learning_rate: 1.0000e-04\n",
      "Epoch 384/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0133 - val_loss: 0.0169 - learning_rate: 1.0000e-04\n",
      "Epoch 385/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0125 - val_loss: 0.0127 - learning_rate: 1.0000e-04\n",
      "Epoch 386/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0114 - val_loss: 0.0104 - learning_rate: 1.0000e-04\n",
      "Epoch 387/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0095 - val_loss: 0.0099 - learning_rate: 1.0000e-04\n",
      "Epoch 388/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0104 - val_loss: 0.0098 - learning_rate: 1.0000e-04\n",
      "Epoch 389/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0090 - val_loss: 0.0104 - learning_rate: 1.0000e-04\n",
      "Epoch 390/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0112 - val_loss: 0.0109 - learning_rate: 1.0000e-04\n",
      "Epoch 391/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0091 - val_loss: 0.0097 - learning_rate: 1.0000e-04\n",
      "Epoch 392/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0094 - val_loss: 0.0144 - learning_rate: 1.0000e-04\n",
      "Epoch 393/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0144 - val_loss: 0.0174 - learning_rate: 1.0000e-04\n",
      "Epoch 394/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0119 - val_loss: 0.0200 - learning_rate: 1.0000e-04\n",
      "Epoch 395/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0146 - val_loss: 0.0158 - learning_rate: 1.0000e-04\n",
      "Epoch 396/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0103 - val_loss: 0.0107 - learning_rate: 1.0000e-04\n",
      "Epoch 397/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0087 - val_loss: 0.0134 - learning_rate: 1.0000e-04\n",
      "Epoch 398/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0139 - val_loss: 0.0219 - learning_rate: 1.0000e-04\n",
      "Epoch 399/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0166 - val_loss: 0.0300 - learning_rate: 1.0000e-04\n",
      "Epoch 400/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0180 - val_loss: 0.0402 - learning_rate: 1.0000e-04\n",
      "Epoch 401/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0189 - val_loss: 0.0118 - learning_rate: 1.0000e-04\n",
      "Epoch 402/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0106 - val_loss: 0.0199 - learning_rate: 1.0000e-04\n",
      "Epoch 403/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0140 - val_loss: 0.0158 - learning_rate: 1.0000e-04\n",
      "Epoch 404/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0105 - val_loss: 0.0095 - learning_rate: 1.0000e-04\n",
      "Epoch 405/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0091 - val_loss: 0.0156 - learning_rate: 1.0000e-04\n",
      "Epoch 406/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0127 - val_loss: 0.0175 - learning_rate: 1.0000e-04\n",
      "Epoch 407/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0172 - val_loss: 0.0158 - learning_rate: 1.0000e-04\n",
      "Epoch 408/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0147 - val_loss: 0.0137 - learning_rate: 1.0000e-04\n",
      "Epoch 409/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0138 - val_loss: 0.0106 - learning_rate: 1.0000e-04\n",
      "Epoch 410/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0113 - val_loss: 0.0119 - learning_rate: 1.0000e-04\n",
      "Epoch 411/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0111 - val_loss: 0.0145 - learning_rate: 1.0000e-04\n",
      "Epoch 412/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0102 - val_loss: 0.0160 - learning_rate: 1.0000e-04\n",
      "Epoch 413/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0133 - val_loss: 0.0142 - learning_rate: 1.0000e-04\n",
      "Epoch 414/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0092 - val_loss: 0.0093 - learning_rate: 1.0000e-04\n",
      "Epoch 415/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 - val_loss: 0.0102 - learning_rate: 1.0000e-04\n",
      "Epoch 416/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0085 - val_loss: 0.0135 - learning_rate: 1.0000e-04\n",
      "Epoch 417/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0110 - val_loss: 0.0097 - learning_rate: 1.0000e-04\n",
      "Epoch 418/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0091 - val_loss: 0.0126 - learning_rate: 1.0000e-04\n",
      "Epoch 419/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0104 - val_loss: 0.0149 - learning_rate: 1.0000e-04\n",
      "Epoch 420/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0103 - val_loss: 0.0130 - learning_rate: 1.0000e-04\n",
      "Epoch 421/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0099 - val_loss: 0.0127 - learning_rate: 1.0000e-04\n",
      "Epoch 422/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0099 - val_loss: 0.0190 - learning_rate: 1.0000e-04\n",
      "Epoch 423/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0130 - val_loss: 0.0210 - learning_rate: 1.0000e-04\n",
      "Epoch 424/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0147 - val_loss: 0.0115 - learning_rate: 1.0000e-04\n",
      "Epoch 425/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0094 - val_loss: 0.0155 - learning_rate: 1.0000e-04\n",
      "Epoch 426/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0113 - val_loss: 0.0094 - learning_rate: 1.0000e-04\n",
      "Epoch 427/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0103 - val_loss: 0.0165 - learning_rate: 1.0000e-04\n",
      "Epoch 428/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0144 - val_loss: 0.0144 - learning_rate: 1.0000e-04\n",
      "Epoch 429/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0114 - val_loss: 0.0118 - learning_rate: 1.0000e-04\n",
      "Epoch 430/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0112 - val_loss: 0.0101 - learning_rate: 1.0000e-04\n",
      "Epoch 431/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0095 - val_loss: 0.0166 - learning_rate: 1.0000e-04\n",
      "Epoch 432/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0127 - val_loss: 0.0117 - learning_rate: 1.0000e-04\n",
      "Epoch 433/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0110 - val_loss: 0.0111 - learning_rate: 1.0000e-04\n",
      "Epoch 434/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0103 - val_loss: 0.0153 - learning_rate: 1.0000e-04\n",
      "Epoch 435/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0101 - val_loss: 0.0122 - learning_rate: 1.0000e-04\n",
      "Epoch 436/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0103 - val_loss: 0.0135 - learning_rate: 1.0000e-04\n",
      "Epoch 437/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0100 - val_loss: 0.0113 - learning_rate: 1.0000e-04\n",
      "Epoch 438/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0097 - val_loss: 0.0144 - learning_rate: 1.0000e-04\n",
      "Epoch 439/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0112 - val_loss: 0.0128 - learning_rate: 1.0000e-04\n",
      "Epoch 440/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0124 - val_loss: 0.0109 - learning_rate: 1.0000e-04\n",
      "Epoch 441/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0090 - val_loss: 0.0111 - learning_rate: 1.0000e-04\n",
      "Epoch 442/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0112 - val_loss: 0.0176 - learning_rate: 1.0000e-04\n",
      "Epoch 443/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0129 - val_loss: 0.0140 - learning_rate: 1.0000e-04\n",
      "Epoch 444/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0119 - val_loss: 0.0215 - learning_rate: 1.0000e-04\n",
      "Epoch 445/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0136 - val_loss: 0.0106 - learning_rate: 1.0000e-04\n",
      "Epoch 446/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0100 - val_loss: 0.0092 - learning_rate: 1.0000e-04\n",
      "Epoch 447/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0095 - val_loss: 0.0155 - learning_rate: 1.0000e-04\n",
      "Epoch 448/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0152 - val_loss: 0.0258 - learning_rate: 1.0000e-04\n",
      "Epoch 449/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0163 - val_loss: 0.0105 - learning_rate: 1.0000e-04\n",
      "Epoch 450/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0088 - val_loss: 0.0099 - learning_rate: 1.0000e-04\n",
      "Epoch 451/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0089 - val_loss: 0.0116 - learning_rate: 1.0000e-04\n",
      "Epoch 452/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 - val_loss: 0.0153 - learning_rate: 1.0000e-04\n",
      "Epoch 453/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0103 - val_loss: 0.0168 - learning_rate: 1.0000e-04\n",
      "Epoch 454/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0118 - val_loss: 0.0121 - learning_rate: 1.0000e-04\n",
      "Epoch 455/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0099 - val_loss: 0.0162 - learning_rate: 1.0000e-04\n",
      "Epoch 456/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0123 - val_loss: 0.0105 - learning_rate: 1.0000e-04\n",
      "Epoch 457/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0118 - val_loss: 0.0179 - learning_rate: 1.0000e-04\n",
      "Epoch 458/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0117 - val_loss: 0.0113 - learning_rate: 1.0000e-04\n",
      "Epoch 459/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0107 - val_loss: 0.0100 - learning_rate: 1.0000e-04\n",
      "Epoch 460/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0090 - val_loss: 0.0273 - learning_rate: 1.0000e-04\n",
      "Epoch 461/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0162 - val_loss: 0.0152 - learning_rate: 1.0000e-04\n",
      "Epoch 462/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0115 - val_loss: 0.0109 - learning_rate: 1.0000e-04\n",
      "Epoch 463/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0132 - val_loss: 0.0095 - learning_rate: 1.0000e-04\n",
      "Epoch 464/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0131 - val_loss: 0.0156 - learning_rate: 1.0000e-04\n",
      "Epoch 465/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0141 - val_loss: 0.0115 - learning_rate: 1.0000e-04\n",
      "Epoch 466/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0104 - val_loss: 0.0121 - learning_rate: 1.0000e-04\n",
      "Epoch 467/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0109 - val_loss: 0.0141 - learning_rate: 1.0000e-04\n",
      "Epoch 468/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0122 - val_loss: 0.0111 - learning_rate: 1.0000e-04\n",
      "Epoch 469/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0110 - val_loss: 0.0093 - learning_rate: 1.0000e-04\n",
      "Epoch 470/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0085 - val_loss: 0.0094 - learning_rate: 1.0000e-04\n",
      "Epoch 471/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0103 - val_loss: 0.0127 - learning_rate: 1.0000e-04\n",
      "Epoch 472/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0108 - val_loss: 0.0127 - learning_rate: 1.0000e-04\n",
      "Epoch 473/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0114 - val_loss: 0.0114 - learning_rate: 1.0000e-04\n",
      "Epoch 474/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0098 - val_loss: 0.0145 - learning_rate: 1.0000e-04\n",
      "Epoch 475/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0111 - val_loss: 0.0124 - learning_rate: 1.0000e-04\n",
      "Epoch 476/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0113 - val_loss: 0.0095 - learning_rate: 1.0000e-04\n",
      "Epoch 477/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0102 - val_loss: 0.0106 - learning_rate: 1.0000e-04\n",
      "Epoch 478/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0159 - learning_rate: 1.0000e-04\n",
      "Epoch 479/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0117 - val_loss: 0.0101 - learning_rate: 1.0000e-04\n",
      "Epoch 480/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0085 - val_loss: 0.0139 - learning_rate: 1.0000e-04\n",
      "Epoch 481/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0107 - val_loss: 0.0115 - learning_rate: 1.0000e-04\n",
      "Epoch 482/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0113 - val_loss: 0.0115 - learning_rate: 1.0000e-04\n",
      "Epoch 483/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0125 - val_loss: 0.0155 - learning_rate: 1.0000e-04\n",
      "Epoch 484/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0129 - val_loss: 0.0119 - learning_rate: 1.0000e-04\n",
      "Epoch 485/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0104 - val_loss: 0.0095 - learning_rate: 1.0000e-04\n",
      "Epoch 486/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0093 - val_loss: 0.0118 - learning_rate: 1.0000e-04\n",
      "Epoch 487/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0104 - val_loss: 0.0108 - learning_rate: 1.0000e-04\n",
      "Epoch 488/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0100 - val_loss: 0.0146 - learning_rate: 1.0000e-04\n",
      "Epoch 489/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0108 - val_loss: 0.0154 - learning_rate: 1.0000e-04\n",
      "Epoch 490/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0123 - val_loss: 0.0210 - learning_rate: 1.0000e-04\n",
      "Epoch 491/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0201 - val_loss: 0.0192 - learning_rate: 1.0000e-04\n",
      "Epoch 492/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0139 - val_loss: 0.0116 - learning_rate: 1.0000e-04\n",
      "Epoch 493/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0114 - val_loss: 0.0103 - learning_rate: 1.0000e-04\n",
      "Epoch 494/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0104 - val_loss: 0.0103 - learning_rate: 1.0000e-04\n",
      "Epoch 495/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0095 - val_loss: 0.0089 - learning_rate: 1.0000e-04\n",
      "Epoch 496/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0095 - val_loss: 0.0115 - learning_rate: 1.0000e-04\n",
      "Epoch 497/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0117 - val_loss: 0.0174 - learning_rate: 1.0000e-04\n",
      "Epoch 498/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0143 - val_loss: 0.0466 - learning_rate: 1.0000e-04\n",
      "Epoch 499/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0284 - val_loss: 0.0188 - learning_rate: 1.0000e-04\n",
      "Epoch 500/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0169 - val_loss: 0.0149 - learning_rate: 1.0000e-04\n",
      "Epoch 501/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0100 - val_loss: 0.0148 - learning_rate: 1.0000e-04\n",
      "Epoch 502/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0151 - val_loss: 0.0133 - learning_rate: 1.0000e-04\n",
      "Epoch 503/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0122 - val_loss: 0.0141 - learning_rate: 1.0000e-04\n",
      "Epoch 504/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0103 - val_loss: 0.0106 - learning_rate: 1.0000e-04\n",
      "Epoch 505/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0119 - val_loss: 0.0121 - learning_rate: 1.0000e-04\n",
      "Epoch 506/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0096 - val_loss: 0.0100 - learning_rate: 1.0000e-04\n",
      "Epoch 507/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 - val_loss: 0.0102 - learning_rate: 1.0000e-04\n",
      "Epoch 508/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0098 - val_loss: 0.0113 - learning_rate: 1.0000e-04\n",
      "Epoch 509/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0095 - val_loss: 0.0113 - learning_rate: 1.0000e-04\n",
      "Epoch 510/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0119 - val_loss: 0.0114 - learning_rate: 1.0000e-04\n",
      "Epoch 511/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0093 - val_loss: 0.0151 - learning_rate: 1.0000e-04\n",
      "Epoch 512/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0114 - val_loss: 0.0196 - learning_rate: 1.0000e-04\n",
      "Epoch 513/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0144 - val_loss: 0.0139 - learning_rate: 1.0000e-04\n",
      "Epoch 514/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0127 - val_loss: 0.0110 - learning_rate: 1.0000e-04\n",
      "Epoch 515/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0126 - val_loss: 0.0199 - learning_rate: 1.0000e-04\n",
      "Epoch 516/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0151 - val_loss: 0.0136 - learning_rate: 1.0000e-04\n",
      "Epoch 517/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0126 - val_loss: 0.0151 - learning_rate: 1.0000e-04\n",
      "Epoch 518/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0153 - val_loss: 0.0102 - learning_rate: 1.0000e-04\n",
      "Epoch 519/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0109 - val_loss: 0.0150 - learning_rate: 1.0000e-04\n",
      "Epoch 520/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0114 - val_loss: 0.0133 - learning_rate: 1.0000e-04\n",
      "Epoch 521/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0116 - val_loss: 0.0169 - learning_rate: 1.0000e-04\n",
      "Epoch 522/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0097 - val_loss: 0.0105 - learning_rate: 1.0000e-04\n",
      "Epoch 523/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0103 - val_loss: 0.0102 - learning_rate: 1.0000e-04\n",
      "Epoch 524/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0097 - val_loss: 0.0088 - learning_rate: 1.0000e-04\n",
      "Epoch 525/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0088 - val_loss: 0.0105 - learning_rate: 1.0000e-04\n",
      "Epoch 526/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0095 - val_loss: 0.0115 - learning_rate: 1.0000e-04\n",
      "Epoch 527/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0089 - val_loss: 0.0097 - learning_rate: 1.0000e-04\n",
      "Epoch 528/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0082 - val_loss: 0.0095 - learning_rate: 1.0000e-04\n",
      "Epoch 529/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0092 - val_loss: 0.0115 - learning_rate: 1.0000e-04\n",
      "Epoch 530/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0116 - val_loss: 0.0119 - learning_rate: 1.0000e-04\n",
      "Epoch 531/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0180 - val_loss: 0.0179 - learning_rate: 1.0000e-04\n",
      "Epoch 532/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0133 - val_loss: 0.0114 - learning_rate: 1.0000e-04\n",
      "Epoch 533/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0082 - val_loss: 0.0102 - learning_rate: 1.0000e-04\n",
      "Epoch 534/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0098 - val_loss: 0.0239 - learning_rate: 1.0000e-04\n",
      "Epoch 535/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0199 - val_loss: 0.0116 - learning_rate: 1.0000e-04\n",
      "Epoch 536/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0124 - val_loss: 0.0137 - learning_rate: 1.0000e-04\n",
      "Epoch 537/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0114 - val_loss: 0.0128 - learning_rate: 1.0000e-04\n",
      "Epoch 538/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0108 - val_loss: 0.0140 - learning_rate: 1.0000e-04\n",
      "Epoch 539/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0099 - val_loss: 0.0089 - learning_rate: 1.0000e-04\n",
      "Epoch 540/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0081 - val_loss: 0.0114 - learning_rate: 1.0000e-04\n",
      "Epoch 541/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0101 - val_loss: 0.0177 - learning_rate: 1.0000e-04\n",
      "Epoch 542/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0111 - val_loss: 0.0099 - learning_rate: 1.0000e-04\n",
      "Epoch 543/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0082 - val_loss: 0.0132 - learning_rate: 1.0000e-04\n",
      "Epoch 544/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0097 - val_loss: 0.0117 - learning_rate: 1.0000e-04\n",
      "Epoch 545/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0113 - val_loss: 0.0123 - learning_rate: 1.0000e-04\n",
      "Epoch 546/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0115 - val_loss: 0.0102 - learning_rate: 1.0000e-04\n",
      "Epoch 547/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0096 - val_loss: 0.0120 - learning_rate: 1.0000e-04\n",
      "Epoch 548/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0099 - val_loss: 0.0195 - learning_rate: 1.0000e-04\n",
      "Epoch 549/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0111 - val_loss: 0.0121 - learning_rate: 1.0000e-04\n",
      "Epoch 550/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0100 - val_loss: 0.0103 - learning_rate: 1.0000e-04\n",
      "Epoch 551/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0110 - val_loss: 0.0110 - learning_rate: 1.0000e-04\n",
      "Epoch 552/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0097 - val_loss: 0.0096 - learning_rate: 1.0000e-04\n",
      "Epoch 553/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0109 - val_loss: 0.0122 - learning_rate: 1.0000e-04\n",
      "Epoch 554/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0096 - val_loss: 0.0101 - learning_rate: 1.0000e-04\n",
      "Epoch 555/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0097 - val_loss: 0.0171 - learning_rate: 1.0000e-04\n",
      "Epoch 556/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0122 - val_loss: 0.0095 - learning_rate: 1.0000e-04\n",
      "Epoch 557/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0104 - val_loss: 0.0102 - learning_rate: 1.0000e-04\n",
      "Epoch 558/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0092 - val_loss: 0.0135 - learning_rate: 1.0000e-04\n",
      "Epoch 559/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0107 - val_loss: 0.0157 - learning_rate: 1.0000e-04\n",
      "Epoch 560/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0127 - val_loss: 0.0333 - learning_rate: 1.0000e-04\n",
      "Epoch 561/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0186 - val_loss: 0.0121 - learning_rate: 1.0000e-04\n",
      "Epoch 562/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0117 - val_loss: 0.0170 - learning_rate: 1.0000e-04\n",
      "Epoch 563/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0153 - val_loss: 0.0304 - learning_rate: 1.0000e-04\n",
      "Epoch 564/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0188 - val_loss: 0.0142 - learning_rate: 1.0000e-04\n",
      "Epoch 565/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0105 - val_loss: 0.0092 - learning_rate: 1.0000e-04\n",
      "Epoch 566/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0106 - val_loss: 0.0110 - learning_rate: 1.0000e-04\n",
      "Epoch 567/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0105 - val_loss: 0.0090 - learning_rate: 1.0000e-04\n",
      "Epoch 568/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0108 - val_loss: 0.0275 - learning_rate: 1.0000e-04\n",
      "Epoch 569/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0158 - val_loss: 0.0112 - learning_rate: 1.0000e-04\n",
      "Epoch 570/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0103 - val_loss: 0.0113 - learning_rate: 1.0000e-04\n",
      "Epoch 571/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0095 - val_loss: 0.0147 - learning_rate: 1.0000e-04\n",
      "Epoch 572/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0131 - val_loss: 0.0093 - learning_rate: 1.0000e-04\n",
      "Epoch 573/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0098 - val_loss: 0.0155 - learning_rate: 1.0000e-04\n",
      "Epoch 574/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0108 - val_loss: 0.0090 - learning_rate: 1.0000e-04\n",
      "Epoch 575/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0102 - val_loss: 0.0175 - learning_rate: 1.0000e-04\n",
      "Epoch 576/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0180 - val_loss: 0.0182 - learning_rate: 1.0000e-04\n",
      "Epoch 577/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0120 - val_loss: 0.0117 - learning_rate: 1.0000e-04\n",
      "Epoch 578/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0098 - val_loss: 0.0127 - learning_rate: 1.0000e-04\n",
      "Epoch 579/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0112 - val_loss: 0.0152 - learning_rate: 1.0000e-04\n",
      "Epoch 580/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0109 - val_loss: 0.0095 - learning_rate: 1.0000e-04\n",
      "Epoch 581/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0103 - val_loss: 0.0160 - learning_rate: 1.0000e-04\n",
      "Epoch 582/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0135 - val_loss: 0.0099 - learning_rate: 1.0000e-04\n",
      "Epoch 583/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0092 - val_loss: 0.0099 - learning_rate: 1.0000e-04\n",
      "Epoch 584/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0095 - val_loss: 0.0208 - learning_rate: 1.0000e-04\n",
      "Epoch 585/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0143 - val_loss: 0.0135 - learning_rate: 1.0000e-04\n",
      "Epoch 586/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0125 - val_loss: 0.0096 - learning_rate: 1.0000e-04\n",
      "Epoch 587/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0093 - val_loss: 0.0091 - learning_rate: 1.0000e-04\n",
      "Epoch 588/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0095 - val_loss: 0.0175 - learning_rate: 1.0000e-04\n",
      "Epoch 589/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0123 - val_loss: 0.0083 - learning_rate: 1.0000e-04\n",
      "Epoch 590/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0105 - val_loss: 0.0099 - learning_rate: 1.0000e-04\n",
      "Epoch 591/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0099 - val_loss: 0.0159 - learning_rate: 1.0000e-04\n",
      "Epoch 592/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0149 - val_loss: 0.0109 - learning_rate: 1.0000e-04\n",
      "Epoch 593/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0141 - val_loss: 0.0234 - learning_rate: 1.0000e-04\n",
      "Epoch 594/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0163 - val_loss: 0.0163 - learning_rate: 1.0000e-04\n",
      "Epoch 595/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0114 - val_loss: 0.0102 - learning_rate: 1.0000e-04\n",
      "Epoch 596/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0113 - val_loss: 0.0150 - learning_rate: 1.0000e-04\n",
      "Epoch 597/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0129 - val_loss: 0.0144 - learning_rate: 1.0000e-04\n",
      "Epoch 598/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0110 - val_loss: 0.0103 - learning_rate: 1.0000e-04\n",
      "Epoch 599/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0084 - val_loss: 0.0093 - learning_rate: 1.0000e-04\n",
      "Epoch 600/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0097 - val_loss: 0.0130 - learning_rate: 1.0000e-04\n",
      "Epoch 601/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0096 - val_loss: 0.0102 - learning_rate: 1.0000e-04\n",
      "Epoch 602/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0104 - val_loss: 0.0153 - learning_rate: 1.0000e-04\n",
      "Epoch 603/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0121 - val_loss: 0.0287 - learning_rate: 1.0000e-04\n",
      "Epoch 604/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0215 - val_loss: 0.0204 - learning_rate: 1.0000e-04\n",
      "Epoch 605/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0124 - val_loss: 0.0130 - learning_rate: 1.0000e-04\n",
      "Epoch 606/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0089 - val_loss: 0.0117 - learning_rate: 1.0000e-04\n",
      "Epoch 607/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0098 - val_loss: 0.0102 - learning_rate: 1.0000e-04\n",
      "Epoch 608/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0093 - val_loss: 0.0134 - learning_rate: 1.0000e-04\n",
      "Epoch 609/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0098 - val_loss: 0.0138 - learning_rate: 1.0000e-04\n",
      "Epoch 610/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0106 - val_loss: 0.0100 - learning_rate: 1.0000e-04\n",
      "Epoch 611/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0097 - val_loss: 0.0152 - learning_rate: 1.0000e-04\n",
      "Epoch 612/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0163 - val_loss: 0.0166 - learning_rate: 1.0000e-04\n",
      "Epoch 613/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0163 - val_loss: 0.0148 - learning_rate: 1.0000e-04\n",
      "Epoch 614/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0107 - val_loss: 0.0128 - learning_rate: 1.0000e-04\n",
      "Epoch 615/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0109 - val_loss: 0.0129 - learning_rate: 1.0000e-04\n",
      "Epoch 616/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0106 - val_loss: 0.0120 - learning_rate: 1.0000e-04\n",
      "Epoch 617/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0134 - val_loss: 0.0102 - learning_rate: 1.0000e-04\n",
      "Epoch 618/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0104 - val_loss: 0.0128 - learning_rate: 1.0000e-04\n",
      "Epoch 619/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0122 - val_loss: 0.0256 - learning_rate: 1.0000e-04\n",
      "Epoch 620/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0141 - val_loss: 0.0101 - learning_rate: 1.0000e-04\n",
      "Epoch 621/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0109 - val_loss: 0.0117 - learning_rate: 1.0000e-04\n",
      "Epoch 622/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0091 - val_loss: 0.0119 - learning_rate: 1.0000e-04\n",
      "Epoch 623/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0089 - val_loss: 0.0089 - learning_rate: 1.0000e-04\n",
      "Epoch 624/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0086 - val_loss: 0.0117 - learning_rate: 1.0000e-04\n",
      "Epoch 625/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0095 - val_loss: 0.0154 - learning_rate: 1.0000e-04\n",
      "Epoch 626/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0109 - val_loss: 0.0111 - learning_rate: 1.0000e-04\n",
      "Epoch 627/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0098 - val_loss: 0.0105 - learning_rate: 1.0000e-04\n",
      "Epoch 628/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0112 - val_loss: 0.0187 - learning_rate: 1.0000e-04\n",
      "Epoch 629/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0142 - val_loss: 0.0124 - learning_rate: 1.0000e-04\n",
      "Epoch 630/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0106 - val_loss: 0.0118 - learning_rate: 1.0000e-04\n",
      "Epoch 631/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0102 - val_loss: 0.0109 - learning_rate: 1.0000e-04\n",
      "Epoch 632/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0110 - val_loss: 0.0195 - learning_rate: 1.0000e-04\n",
      "Epoch 633/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0138 - val_loss: 0.0132 - learning_rate: 1.0000e-04\n",
      "Epoch 634/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0097 - val_loss: 0.0118 - learning_rate: 1.0000e-04\n",
      "Epoch 635/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0109 - val_loss: 0.0104 - learning_rate: 1.0000e-04\n",
      "Epoch 636/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0097 - val_loss: 0.0145 - learning_rate: 1.0000e-04\n",
      "Epoch 637/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0090 - val_loss: 0.0108 - learning_rate: 1.0000e-04\n",
      "Epoch 638/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0089 - val_loss: 0.0119 - learning_rate: 1.0000e-04\n",
      "Epoch 639/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0107 - val_loss: 0.0123 - learning_rate: 1.0000e-04\n",
      "Epoch 640/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0129 - val_loss: 0.0114 - learning_rate: 1.0000e-04\n",
      "Epoch 641/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0100 - val_loss: 0.0087 - learning_rate: 1.0000e-04\n",
      "Epoch 642/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0091 - val_loss: 0.0107 - learning_rate: 1.0000e-04\n",
      "Epoch 643/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0097 - val_loss: 0.0104 - learning_rate: 1.0000e-04\n",
      "Epoch 644/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0115 - val_loss: 0.0140 - learning_rate: 1.0000e-04\n",
      "Epoch 645/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0247 - val_loss: 0.0439 - learning_rate: 1.0000e-04\n",
      "Epoch 646/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0268 - val_loss: 0.0206 - learning_rate: 1.0000e-04\n",
      "Epoch 647/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0141 - val_loss: 0.0155 - learning_rate: 1.0000e-04\n",
      "Epoch 648/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0127 - val_loss: 0.0099 - learning_rate: 1.0000e-04\n",
      "Epoch 649/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0084 - val_loss: 0.0124 - learning_rate: 1.0000e-04\n",
      "Epoch 650/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0111 - val_loss: 0.0113 - learning_rate: 1.0000e-04\n",
      "Epoch 651/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0093 - val_loss: 0.0098 - learning_rate: 1.0000e-04\n",
      "Epoch 652/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0093 - val_loss: 0.0089 - learning_rate: 1.0000e-04\n",
      "Epoch 653/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0105 - learning_rate: 1.0000e-04\n",
      "Epoch 654/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0106 - val_loss: 0.0110 - learning_rate: 1.0000e-04\n",
      "Epoch 655/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0114 - val_loss: 0.0098 - learning_rate: 1.0000e-04\n",
      "Epoch 656/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0094 - val_loss: 0.0130 - learning_rate: 1.0000e-04\n",
      "Epoch 657/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0119 - val_loss: 0.0105 - learning_rate: 1.0000e-04\n",
      "Epoch 658/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0108 - val_loss: 0.0122 - learning_rate: 1.0000e-04\n",
      "Epoch 659/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0100 - val_loss: 0.0102 - learning_rate: 1.0000e-04\n",
      "Epoch 660/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0091 - val_loss: 0.0100 - learning_rate: 1.0000e-04\n",
      "Epoch 661/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0097 - val_loss: 0.0112 - learning_rate: 1.0000e-04\n",
      "Epoch 662/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0117 - val_loss: 0.0172 - learning_rate: 1.0000e-04\n",
      "Epoch 663/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0128 - val_loss: 0.0208 - learning_rate: 1.0000e-04\n",
      "Epoch 664/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0154 - val_loss: 0.0113 - learning_rate: 1.0000e-04\n",
      "Epoch 665/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0113 - val_loss: 0.0092 - learning_rate: 1.0000e-04\n",
      "Epoch 666/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0109 - val_loss: 0.0107 - learning_rate: 1.0000e-04\n",
      "Epoch 667/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0092 - val_loss: 0.0101 - learning_rate: 1.0000e-04\n",
      "Epoch 668/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0095 - val_loss: 0.0097 - learning_rate: 1.0000e-04\n",
      "Epoch 669/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0112 - val_loss: 0.0121 - learning_rate: 1.0000e-04\n",
      "Epoch 670/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0109 - val_loss: 0.0095 - learning_rate: 1.0000e-04\n",
      "Epoch 671/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0088 - val_loss: 0.0095 - learning_rate: 1.0000e-04\n",
      "Epoch 672/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0089 - val_loss: 0.0090 - learning_rate: 1.0000e-04\n",
      "Epoch 673/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0088 - val_loss: 0.0101 - learning_rate: 1.0000e-04\n",
      "Epoch 674/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0130 - val_loss: 0.0142 - learning_rate: 1.0000e-04\n",
      "Epoch 675/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0129 - val_loss: 0.0162 - learning_rate: 1.0000e-04\n",
      "Epoch 676/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0118 - val_loss: 0.0130 - learning_rate: 1.0000e-04\n",
      "Epoch 677/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0101 - val_loss: 0.0141 - learning_rate: 1.0000e-04\n",
      "Epoch 678/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0123 - val_loss: 0.0166 - learning_rate: 1.0000e-04\n",
      "Epoch 679/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0141 - val_loss: 0.0131 - learning_rate: 1.0000e-04\n",
      "Epoch 680/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0145 - val_loss: 0.0215 - learning_rate: 1.0000e-04\n",
      "Epoch 681/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0123 - val_loss: 0.0108 - learning_rate: 1.0000e-04\n",
      "Epoch 682/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0094 - val_loss: 0.0102 - learning_rate: 1.0000e-04\n",
      "Epoch 683/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0094 - val_loss: 0.0105 - learning_rate: 1.0000e-04\n",
      "Epoch 684/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0111 - val_loss: 0.0122 - learning_rate: 1.0000e-04\n",
      "Epoch 685/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0108 - val_loss: 0.0119 - learning_rate: 1.0000e-04\n",
      "Epoch 686/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0107 - val_loss: 0.0155 - learning_rate: 1.0000e-04\n",
      "Epoch 687/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0113 - val_loss: 0.0173 - learning_rate: 1.0000e-04\n",
      "Epoch 688/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0150 - val_loss: 0.0114 - learning_rate: 1.0000e-04\n",
      "Epoch 689/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0095 - val_loss: 0.0093 - learning_rate: 1.0000e-04\n",
      "Epoch 690/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0103 - val_loss: 0.0125 - learning_rate: 1.0000e-04\n",
      "Epoch 691/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0095 - val_loss: 0.0099 - learning_rate: 1.0000e-04\n",
      "Epoch 692/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0106 - val_loss: 0.0144 - learning_rate: 1.0000e-04\n",
      "Epoch 693/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0111 - val_loss: 0.0112 - learning_rate: 1.0000e-04\n",
      "Epoch 694/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0099 - val_loss: 0.0096 - learning_rate: 1.0000e-04\n",
      "Epoch 695/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0090 - val_loss: 0.0103 - learning_rate: 1.0000e-04\n",
      "Epoch 696/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0109 - val_loss: 0.0107 - learning_rate: 1.0000e-04\n",
      "Epoch 697/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0103 - val_loss: 0.0115 - learning_rate: 1.0000e-04\n",
      "Epoch 698/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0090 - val_loss: 0.0100 - learning_rate: 1.0000e-04\n",
      "Epoch 699/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0099 - val_loss: 0.0095 - learning_rate: 1.0000e-04\n",
      "Epoch 700/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0094 - val_loss: 0.0124 - learning_rate: 1.0000e-04\n",
      "Epoch 701/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0105 - val_loss: 0.0106 - learning_rate: 1.0000e-04\n",
      "Epoch 702/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0102 - val_loss: 0.0184 - learning_rate: 1.0000e-04\n",
      "Epoch 703/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0139 - val_loss: 0.0133 - learning_rate: 1.0000e-04\n",
      "Epoch 704/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0107 - val_loss: 0.0146 - learning_rate: 1.0000e-04\n",
      "Epoch 705/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0179 - val_loss: 0.0177 - learning_rate: 1.0000e-04\n",
      "Epoch 706/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0136 - val_loss: 0.0108 - learning_rate: 1.0000e-04\n",
      "Epoch 707/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0105 - val_loss: 0.0148 - learning_rate: 1.0000e-04\n",
      "Epoch 708/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0103 - val_loss: 0.0137 - learning_rate: 1.0000e-04\n",
      "Epoch 709/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0146 - val_loss: 0.0119 - learning_rate: 1.0000e-04\n",
      "Epoch 710/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0141 - val_loss: 0.0159 - learning_rate: 1.0000e-04\n",
      "Epoch 711/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0147 - val_loss: 0.0119 - learning_rate: 1.0000e-04\n",
      "Epoch 712/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0191 - val_loss: 0.0149 - learning_rate: 1.0000e-04\n",
      "Epoch 713/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0131 - val_loss: 0.0140 - learning_rate: 1.0000e-04\n",
      "Epoch 714/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0116 - val_loss: 0.0099 - learning_rate: 1.0000e-04\n",
      "Epoch 715/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0089 - val_loss: 0.0122 - learning_rate: 1.0000e-04\n",
      "Epoch 716/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0085 - val_loss: 0.0091 - learning_rate: 1.0000e-04\n",
      "Epoch 717/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0096 - val_loss: 0.0156 - learning_rate: 1.0000e-04\n",
      "Epoch 718/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0108 - val_loss: 0.0113 - learning_rate: 1.0000e-04\n",
      "Epoch 719/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0109 - val_loss: 0.0124 - learning_rate: 1.0000e-04\n",
      "Epoch 720/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0100 - val_loss: 0.0093 - learning_rate: 1.0000e-04\n",
      "Epoch 721/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0097 - val_loss: 0.0108 - learning_rate: 1.0000e-04\n",
      "Epoch 722/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0099 - val_loss: 0.0147 - learning_rate: 1.0000e-04\n",
      "Epoch 723/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0104 - val_loss: 0.0123 - learning_rate: 1.0000e-04\n",
      "Epoch 724/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0102 - val_loss: 0.0119 - learning_rate: 1.0000e-04\n",
      "Epoch 725/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0101 - val_loss: 0.0176 - learning_rate: 1.0000e-04\n",
      "Epoch 726/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0145 - val_loss: 0.0114 - learning_rate: 1.0000e-04\n",
      "Epoch 727/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0139 - val_loss: 0.0196 - learning_rate: 1.0000e-04\n",
      "Epoch 728/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0163 - val_loss: 0.0202 - learning_rate: 1.0000e-04\n",
      "Epoch 729/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0161 - val_loss: 0.0103 - learning_rate: 1.0000e-04\n",
      "Epoch 730/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0095 - val_loss: 0.0118 - learning_rate: 1.0000e-04\n",
      "Epoch 731/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0116 - val_loss: 0.0145 - learning_rate: 1.0000e-04\n",
      "Epoch 732/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0096 - val_loss: 0.0102 - learning_rate: 1.0000e-04\n",
      "Epoch 733/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0106 - val_loss: 0.0108 - learning_rate: 1.0000e-04\n",
      "Epoch 734/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0091 - val_loss: 0.0103 - learning_rate: 1.0000e-04\n",
      "Epoch 735/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0095 - val_loss: 0.0205 - learning_rate: 1.0000e-04\n",
      "Epoch 736/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0139 - val_loss: 0.0104 - learning_rate: 1.0000e-04\n",
      "Epoch 737/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0102 - val_loss: 0.0204 - learning_rate: 1.0000e-04\n",
      "Epoch 738/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0125 - val_loss: 0.0145 - learning_rate: 1.0000e-04\n",
      "Epoch 739/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0115 - val_loss: 0.0135 - learning_rate: 1.0000e-04\n",
      "Epoch 740/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0135 - val_loss: 0.0110 - learning_rate: 1.0000e-04\n",
      "Epoch 741/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0106 - val_loss: 0.0159 - learning_rate: 1.0000e-04\n",
      "Epoch 742/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0126 - val_loss: 0.0209 - learning_rate: 1.0000e-04\n",
      "Epoch 743/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0177 - val_loss: 0.0184 - learning_rate: 1.0000e-04\n",
      "Epoch 744/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0131 - val_loss: 0.0114 - learning_rate: 1.0000e-04\n",
      "Epoch 745/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0117 - val_loss: 0.0142 - learning_rate: 1.0000e-04\n",
      "Epoch 746/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0102 - val_loss: 0.0104 - learning_rate: 1.0000e-04\n",
      "Epoch 747/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0099 - val_loss: 0.0094 - learning_rate: 1.0000e-04\n",
      "Epoch 748/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0096 - val_loss: 0.0132 - learning_rate: 1.0000e-04\n",
      "Epoch 749/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0101 - val_loss: 0.0145 - learning_rate: 1.0000e-04\n",
      "Epoch 750/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0122 - val_loss: 0.0126 - learning_rate: 1.0000e-04\n",
      "Epoch 751/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0096 - val_loss: 0.0162 - learning_rate: 1.0000e-04\n",
      "Epoch 752/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0111 - val_loss: 0.0110 - learning_rate: 1.0000e-04\n",
      "Epoch 753/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0118 - val_loss: 0.0137 - learning_rate: 1.0000e-04\n",
      "Epoch 754/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0120 - val_loss: 0.0207 - learning_rate: 1.0000e-04\n",
      "Epoch 755/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0148 - val_loss: 0.0110 - learning_rate: 1.0000e-04\n",
      "Epoch 756/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0089 - val_loss: 0.0103 - learning_rate: 1.0000e-04\n",
      "Epoch 757/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0124 - val_loss: 0.0124 - learning_rate: 1.0000e-04\n",
      "Epoch 758/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0101 - val_loss: 0.0096 - learning_rate: 1.0000e-04\n",
      "Epoch 759/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0090 - val_loss: 0.0099 - learning_rate: 1.0000e-04\n",
      "Epoch 760/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0101 - val_loss: 0.0130 - learning_rate: 1.0000e-04\n",
      "Epoch 761/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0109 - val_loss: 0.0152 - learning_rate: 1.0000e-04\n",
      "Epoch 762/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0123 - val_loss: 0.0129 - learning_rate: 1.0000e-04\n",
      "Epoch 763/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0135 - val_loss: 0.0143 - learning_rate: 1.0000e-04\n",
      "Epoch 764/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0099 - val_loss: 0.0111 - learning_rate: 1.0000e-04\n",
      "Epoch 765/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0100 - val_loss: 0.0135 - learning_rate: 1.0000e-04\n",
      "Epoch 766/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0146 - val_loss: 0.0106 - learning_rate: 1.0000e-04\n",
      "Epoch 767/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0092 - val_loss: 0.0100 - learning_rate: 1.0000e-04\n",
      "Epoch 768/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0088 - val_loss: 0.0114 - learning_rate: 1.0000e-04\n",
      "Epoch 769/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0096 - val_loss: 0.0105 - learning_rate: 1.0000e-04\n",
      "Epoch 770/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0086 - val_loss: 0.0116 - learning_rate: 1.0000e-04\n",
      "Epoch 771/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0097 - val_loss: 0.0127 - learning_rate: 1.0000e-04\n",
      "Epoch 772/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0099 - val_loss: 0.0150 - learning_rate: 1.0000e-04\n",
      "Epoch 773/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0107 - val_loss: 0.0118 - learning_rate: 1.0000e-04\n",
      "Epoch 774/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0109 - val_loss: 0.0105 - learning_rate: 1.0000e-04\n",
      "Epoch 775/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0106 - val_loss: 0.0105 - learning_rate: 1.0000e-04\n",
      "Epoch 776/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0138 - val_loss: 0.0158 - learning_rate: 1.0000e-04\n",
      "Epoch 777/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0137 - val_loss: 0.0178 - learning_rate: 1.0000e-04\n",
      "Epoch 778/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0161 - val_loss: 0.0131 - learning_rate: 1.0000e-04\n",
      "Epoch 779/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0123 - val_loss: 0.0124 - learning_rate: 1.0000e-04\n",
      "Epoch 780/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0108 - val_loss: 0.0105 - learning_rate: 1.0000e-04\n",
      "Epoch 781/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0093 - val_loss: 0.0135 - learning_rate: 1.0000e-04\n",
      "Epoch 782/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0135 - val_loss: 0.0137 - learning_rate: 1.0000e-04\n",
      "Epoch 783/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0113 - val_loss: 0.0109 - learning_rate: 1.0000e-04\n",
      "Epoch 784/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0097 - val_loss: 0.0139 - learning_rate: 1.0000e-04\n",
      "Epoch 785/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0110 - val_loss: 0.0142 - learning_rate: 1.0000e-04\n",
      "Epoch 786/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0111 - val_loss: 0.0117 - learning_rate: 1.0000e-04\n",
      "Epoch 787/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0098 - val_loss: 0.0093 - learning_rate: 1.0000e-04\n",
      "Epoch 788/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0105 - val_loss: 0.0238 - learning_rate: 1.0000e-04\n",
      "Epoch 789/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0207 - val_loss: 0.0159 - learning_rate: 1.0000e-04\n",
      "Epoch 790/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0128 - val_loss: 0.0126 - learning_rate: 1.0000e-04\n",
      "Epoch 791/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0126 - val_loss: 0.0118 - learning_rate: 1.0000e-04\n",
      "Epoch 792/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0122 - val_loss: 0.0213 - learning_rate: 1.0000e-04\n",
      "Epoch 793/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0114 - val_loss: 0.0150 - learning_rate: 1.0000e-04\n",
      "Epoch 794/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0136 - val_loss: 0.0106 - learning_rate: 1.0000e-04\n",
      "Epoch 795/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0106 - val_loss: 0.0107 - learning_rate: 1.0000e-04\n",
      "Epoch 796/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0099 - val_loss: 0.0113 - learning_rate: 1.0000e-04\n",
      "Epoch 797/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0093 - val_loss: 0.0143 - learning_rate: 1.0000e-04\n",
      "Epoch 798/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0105 - val_loss: 0.0120 - learning_rate: 1.0000e-04\n",
      "Epoch 799/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0108 - val_loss: 0.0159 - learning_rate: 1.0000e-04\n",
      "Epoch 800/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0107 - val_loss: 0.0115 - learning_rate: 1.0000e-04\n",
      "Epoch 801/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0099 - val_loss: 0.0109 - learning_rate: 1.0000e-04\n",
      "Epoch 802/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0120 - val_loss: 0.0132 - learning_rate: 1.0000e-04\n",
      "Epoch 803/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0124 - val_loss: 0.0111 - learning_rate: 1.0000e-04\n",
      "Epoch 804/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0107 - val_loss: 0.0102 - learning_rate: 1.0000e-04\n",
      "Epoch 805/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0116 - val_loss: 0.0111 - learning_rate: 1.0000e-04\n",
      "Epoch 806/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0100 - val_loss: 0.0107 - learning_rate: 1.0000e-04\n",
      "Epoch 807/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0094 - val_loss: 0.0093 - learning_rate: 1.0000e-04\n",
      "Epoch 808/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0100 - val_loss: 0.0118 - learning_rate: 1.0000e-04\n",
      "Epoch 809/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0123 - val_loss: 0.0140 - learning_rate: 1.0000e-04\n",
      "Epoch 810/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0091 - val_loss: 0.0128 - learning_rate: 1.0000e-04\n",
      "Epoch 811/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0113 - val_loss: 0.0124 - learning_rate: 1.0000e-04\n",
      "Epoch 812/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0103 - val_loss: 0.0133 - learning_rate: 1.0000e-04\n",
      "Epoch 813/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0117 - val_loss: 0.0122 - learning_rate: 1.0000e-04\n",
      "Epoch 814/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0131 - val_loss: 0.0124 - learning_rate: 1.0000e-04\n",
      "Epoch 815/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0111 - val_loss: 0.0140 - learning_rate: 1.0000e-04\n",
      "Epoch 816/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0119 - val_loss: 0.0145 - learning_rate: 1.0000e-04\n",
      "Epoch 817/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0146 - val_loss: 0.0190 - learning_rate: 1.0000e-04\n",
      "Epoch 818/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0150 - val_loss: 0.0170 - learning_rate: 1.0000e-04\n",
      "Epoch 819/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0126 - val_loss: 0.0099 - learning_rate: 1.0000e-04\n",
      "Epoch 820/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0095 - val_loss: 0.0096 - learning_rate: 1.0000e-04\n",
      "Epoch 821/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0086 - val_loss: 0.0095 - learning_rate: 1.0000e-04\n",
      "Epoch 822/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0096 - val_loss: 0.0132 - learning_rate: 1.0000e-04\n",
      "Epoch 823/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0100 - val_loss: 0.0196 - learning_rate: 1.0000e-04\n",
      "Epoch 824/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0106 - val_loss: 0.0217 - learning_rate: 1.0000e-04\n",
      "Epoch 825/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0119 - val_loss: 0.0146 - learning_rate: 1.0000e-04\n",
      "Epoch 826/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0116 - val_loss: 0.0122 - learning_rate: 1.0000e-04\n",
      "Epoch 827/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0101 - val_loss: 0.0146 - learning_rate: 1.0000e-04\n",
      "Epoch 828/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0112 - val_loss: 0.0124 - learning_rate: 1.0000e-04\n",
      "Epoch 829/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0108 - val_loss: 0.0116 - learning_rate: 1.0000e-04\n",
      "Epoch 830/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0101 - val_loss: 0.0173 - learning_rate: 1.0000e-04\n",
      "Epoch 831/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0117 - val_loss: 0.0116 - learning_rate: 1.0000e-04\n",
      "Epoch 832/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0094 - val_loss: 0.0086 - learning_rate: 1.0000e-04\n",
      "Epoch 833/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0094 - val_loss: 0.0112 - learning_rate: 1.0000e-04\n",
      "Epoch 834/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0102 - val_loss: 0.0154 - learning_rate: 1.0000e-04\n",
      "Epoch 835/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0103 - val_loss: 0.0087 - learning_rate: 1.0000e-04\n",
      "Epoch 836/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 - val_loss: 0.0104 - learning_rate: 1.0000e-04\n",
      "Epoch 837/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0103 - val_loss: 0.0115 - learning_rate: 1.0000e-04\n",
      "Epoch 838/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0112 - val_loss: 0.0099 - learning_rate: 1.0000e-04\n",
      "Epoch 839/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0088 - val_loss: 0.0102 - learning_rate: 1.0000e-04\n",
      "Epoch 840/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0154 - val_loss: 0.0115 - learning_rate: 1.0000e-04\n",
      "Epoch 841/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0097 - val_loss: 0.0101 - learning_rate: 1.0000e-04\n",
      "Epoch 842/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0091 - val_loss: 0.0087 - learning_rate: 1.0000e-04\n",
      "Epoch 843/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0088 - val_loss: 0.0105 - learning_rate: 1.0000e-04\n",
      "Epoch 844/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0109 - val_loss: 0.0283 - learning_rate: 1.0000e-04\n",
      "Epoch 845/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0149 - val_loss: 0.0107 - learning_rate: 1.0000e-04\n",
      "Epoch 846/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0106 - val_loss: 0.0104 - learning_rate: 1.0000e-04\n",
      "Epoch 847/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0105 - val_loss: 0.0101 - learning_rate: 1.0000e-04\n",
      "Epoch 848/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0115 - val_loss: 0.0114 - learning_rate: 1.0000e-04\n",
      "Epoch 849/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0125 - val_loss: 0.0103 - learning_rate: 1.0000e-04\n",
      "Epoch 850/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0113 - val_loss: 0.0114 - learning_rate: 1.0000e-04\n",
      "Epoch 851/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0116 - val_loss: 0.0127 - learning_rate: 1.0000e-04\n",
      "Epoch 852/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0103 - val_loss: 0.0094 - learning_rate: 1.0000e-04\n",
      "Epoch 853/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0097 - val_loss: 0.0186 - learning_rate: 1.0000e-04\n",
      "Epoch 854/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0210 - val_loss: 0.0138 - learning_rate: 1.0000e-04\n",
      "Epoch 855/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0103 - val_loss: 0.0091 - learning_rate: 1.0000e-04\n",
      "Epoch 856/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0089 - val_loss: 0.0131 - learning_rate: 1.0000e-04\n",
      "Epoch 857/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0125 - val_loss: 0.0131 - learning_rate: 1.0000e-04\n",
      "Epoch 858/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0118 - val_loss: 0.0180 - learning_rate: 1.0000e-04\n",
      "Epoch 859/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0125 - val_loss: 0.0170 - learning_rate: 1.0000e-04\n",
      "Epoch 860/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0114 - val_loss: 0.0144 - learning_rate: 1.0000e-04\n",
      "Epoch 861/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0134 - val_loss: 0.0125 - learning_rate: 1.0000e-04\n",
      "Epoch 862/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0101 - val_loss: 0.0096 - learning_rate: 1.0000e-04\n",
      "Epoch 863/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0126 - val_loss: 0.0153 - learning_rate: 1.0000e-04\n",
      "Epoch 864/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0119 - val_loss: 0.0101 - learning_rate: 1.0000e-04\n",
      "Epoch 865/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0106 - val_loss: 0.0112 - learning_rate: 1.0000e-04\n",
      "Epoch 866/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0092 - val_loss: 0.0093 - learning_rate: 1.0000e-04\n",
      "Epoch 867/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0108 - learning_rate: 1.0000e-04\n",
      "Epoch 868/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0134 - val_loss: 0.0171 - learning_rate: 1.0000e-04\n",
      "Epoch 869/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0158 - val_loss: 0.0104 - learning_rate: 1.0000e-04\n",
      "Epoch 870/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0119 - val_loss: 0.0194 - learning_rate: 1.0000e-04\n",
      "Epoch 871/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0147 - val_loss: 0.0117 - learning_rate: 1.0000e-04\n",
      "Epoch 872/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0101 - val_loss: 0.0115 - learning_rate: 1.0000e-04\n",
      "Epoch 873/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 - val_loss: 0.0118 - learning_rate: 1.0000e-04\n",
      "Epoch 874/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0131 - val_loss: 0.0100 - learning_rate: 1.0000e-04\n",
      "Epoch 875/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0120 - val_loss: 0.0130 - learning_rate: 1.0000e-04\n",
      "Epoch 876/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0123 - val_loss: 0.0099 - learning_rate: 1.0000e-04\n",
      "Epoch 877/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 - val_loss: 0.0126 - learning_rate: 1.0000e-04\n",
      "Epoch 878/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0098 - val_loss: 0.0172 - learning_rate: 1.0000e-04\n",
      "Epoch 879/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0114 - val_loss: 0.0124 - learning_rate: 1.0000e-04\n",
      "Epoch 880/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0097 - val_loss: 0.0128 - learning_rate: 1.0000e-04\n",
      "Epoch 881/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0113 - val_loss: 0.0108 - learning_rate: 1.0000e-04\n",
      "Epoch 882/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0114 - val_loss: 0.0102 - learning_rate: 1.0000e-04\n",
      "Epoch 883/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0113 - val_loss: 0.0272 - learning_rate: 1.0000e-04\n",
      "Epoch 884/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0160 - val_loss: 0.0109 - learning_rate: 1.0000e-04\n",
      "Epoch 885/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0104 - val_loss: 0.0124 - learning_rate: 1.0000e-04\n",
      "Epoch 886/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0091 - val_loss: 0.0102 - learning_rate: 1.0000e-04\n",
      "Epoch 887/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0110 - learning_rate: 1.0000e-04\n",
      "Epoch 888/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0103 - val_loss: 0.0125 - learning_rate: 1.0000e-04\n",
      "Epoch 889/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0098 - val_loss: 0.0120 - learning_rate: 1.0000e-04\n",
      "Epoch 890/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0121 - val_loss: 0.0166 - learning_rate: 1.0000e-04\n",
      "Epoch 891/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0118 - val_loss: 0.0104 - learning_rate: 1.0000e-04\n",
      "Epoch 892/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0084 - val_loss: 0.0106 - learning_rate: 1.0000e-04\n",
      "Epoch 893/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0099 - val_loss: 0.0194 - learning_rate: 1.0000e-04\n",
      "Epoch 894/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0142 - val_loss: 0.0137 - learning_rate: 1.0000e-04\n",
      "Epoch 895/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0129 - val_loss: 0.0109 - learning_rate: 1.0000e-04\n",
      "Epoch 896/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0097 - val_loss: 0.0116 - learning_rate: 1.0000e-04\n",
      "Epoch 897/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0098 - val_loss: 0.0127 - learning_rate: 1.0000e-04\n",
      "Epoch 898/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0090 - val_loss: 0.0162 - learning_rate: 1.0000e-04\n",
      "Epoch 899/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0127 - val_loss: 0.0114 - learning_rate: 1.0000e-04\n",
      "Epoch 900/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0105 - val_loss: 0.0110 - learning_rate: 1.0000e-04\n",
      "Epoch 901/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 - val_loss: 0.0091 - learning_rate: 1.0000e-04\n",
      "Epoch 902/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0095 - val_loss: 0.0109 - learning_rate: 1.0000e-04\n",
      "Epoch 903/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0134 - val_loss: 0.0115 - learning_rate: 1.0000e-04\n",
      "Epoch 904/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0136 - val_loss: 0.0102 - learning_rate: 1.0000e-04\n",
      "Epoch 905/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0104 - val_loss: 0.0150 - learning_rate: 1.0000e-04\n",
      "Epoch 906/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0117 - val_loss: 0.0103 - learning_rate: 1.0000e-04\n",
      "Epoch 907/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0090 - val_loss: 0.0124 - learning_rate: 1.0000e-04\n",
      "Epoch 908/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0115 - val_loss: 0.0104 - learning_rate: 1.0000e-04\n",
      "Epoch 909/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0113 - val_loss: 0.0095 - learning_rate: 1.0000e-04\n",
      "Epoch 910/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0088 - val_loss: 0.0105 - learning_rate: 1.0000e-04\n",
      "Epoch 911/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0091 - val_loss: 0.0109 - learning_rate: 1.0000e-04\n",
      "Epoch 912/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0115 - val_loss: 0.0098 - learning_rate: 1.0000e-04\n",
      "Epoch 913/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0111 - val_loss: 0.0214 - learning_rate: 1.0000e-04\n",
      "Epoch 914/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0122 - val_loss: 0.0107 - learning_rate: 1.0000e-04\n",
      "Epoch 915/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0106 - val_loss: 0.0115 - learning_rate: 1.0000e-04\n",
      "Epoch 916/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0110 - val_loss: 0.0148 - learning_rate: 1.0000e-04\n",
      "Epoch 917/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0132 - val_loss: 0.0180 - learning_rate: 1.0000e-04\n",
      "Epoch 918/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0130 - val_loss: 0.0122 - learning_rate: 1.0000e-04\n",
      "Epoch 919/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0121 - val_loss: 0.0191 - learning_rate: 1.0000e-04\n",
      "Epoch 920/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0133 - val_loss: 0.0134 - learning_rate: 1.0000e-04\n",
      "Epoch 921/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0098 - val_loss: 0.0104 - learning_rate: 1.0000e-04\n",
      "Epoch 922/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 - val_loss: 0.0085 - learning_rate: 1.0000e-04\n",
      "Epoch 923/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0109 - learning_rate: 1.0000e-04\n",
      "Epoch 924/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0104 - val_loss: 0.0128 - learning_rate: 1.0000e-04\n",
      "Epoch 925/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0094 - val_loss: 0.0112 - learning_rate: 1.0000e-04\n",
      "Epoch 926/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0111 - val_loss: 0.0110 - learning_rate: 1.0000e-04\n",
      "Epoch 927/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0098 - val_loss: 0.0096 - learning_rate: 1.0000e-04\n",
      "Epoch 928/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0147 - val_loss: 0.0200 - learning_rate: 1.0000e-04\n",
      "Epoch 929/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0118 - val_loss: 0.0100 - learning_rate: 1.0000e-04\n",
      "Epoch 930/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0098 - learning_rate: 1.0000e-04\n",
      "Epoch 931/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0105 - learning_rate: 1.0000e-04\n",
      "Epoch 932/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0103 - val_loss: 0.0103 - learning_rate: 1.0000e-04\n",
      "Epoch 933/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0103 - val_loss: 0.0212 - learning_rate: 1.0000e-04\n",
      "Epoch 934/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0121 - val_loss: 0.0101 - learning_rate: 1.0000e-04\n",
      "Epoch 935/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0100 - val_loss: 0.0095 - learning_rate: 1.0000e-04\n",
      "Epoch 936/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0101 - val_loss: 0.0119 - learning_rate: 1.0000e-04\n",
      "Epoch 937/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0114 - val_loss: 0.0097 - learning_rate: 1.0000e-04\n",
      "Epoch 938/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0086 - val_loss: 0.0109 - learning_rate: 1.0000e-04\n",
      "Epoch 939/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0096 - val_loss: 0.0108 - learning_rate: 1.0000e-04\n",
      "Epoch 940/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0091 - val_loss: 0.0108 - learning_rate: 1.0000e-04\n",
      "Epoch 941/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0102 - val_loss: 0.0145 - learning_rate: 1.0000e-04\n",
      "Epoch 942/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0153 - val_loss: 0.0160 - learning_rate: 1.0000e-04\n",
      "Epoch 943/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0158 - val_loss: 0.0233 - learning_rate: 1.0000e-04\n",
      "Epoch 944/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0151 - val_loss: 0.0170 - learning_rate: 1.0000e-04\n",
      "Epoch 945/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0133 - val_loss: 0.0121 - learning_rate: 1.0000e-04\n",
      "Epoch 946/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0197 - val_loss: 0.0211 - learning_rate: 1.0000e-04\n",
      "Epoch 947/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0157 - val_loss: 0.0120 - learning_rate: 1.0000e-04\n",
      "Epoch 948/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0099 - val_loss: 0.0117 - learning_rate: 1.0000e-04\n",
      "Epoch 949/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0094 - val_loss: 0.0094 - learning_rate: 1.0000e-04\n",
      "Epoch 950/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0094 - val_loss: 0.0099 - learning_rate: 1.0000e-04\n",
      "Epoch 951/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0109 - val_loss: 0.0148 - learning_rate: 1.0000e-04\n",
      "Epoch 952/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0157 - val_loss: 0.0140 - learning_rate: 1.0000e-04\n",
      "Epoch 953/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0116 - val_loss: 0.0109 - learning_rate: 1.0000e-04\n",
      "Epoch 954/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0099 - val_loss: 0.0104 - learning_rate: 1.0000e-04\n",
      "Epoch 955/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0113 - val_loss: 0.0170 - learning_rate: 1.0000e-04\n",
      "Epoch 956/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0131 - val_loss: 0.0126 - learning_rate: 1.0000e-04\n",
      "Epoch 957/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0113 - val_loss: 0.0115 - learning_rate: 1.0000e-04\n",
      "Epoch 958/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0096 - val_loss: 0.0103 - learning_rate: 1.0000e-04\n",
      "Epoch 959/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0091 - val_loss: 0.0097 - learning_rate: 1.0000e-04\n",
      "Epoch 960/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0094 - val_loss: 0.0100 - learning_rate: 1.0000e-04\n",
      "Epoch 961/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0094 - val_loss: 0.0124 - learning_rate: 1.0000e-04\n",
      "Epoch 962/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0121 - val_loss: 0.0152 - learning_rate: 1.0000e-04\n",
      "Epoch 963/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0139 - val_loss: 0.0113 - learning_rate: 1.0000e-04\n",
      "Epoch 964/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0137 - val_loss: 0.0159 - learning_rate: 1.0000e-04\n",
      "Epoch 965/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0146 - val_loss: 0.0158 - learning_rate: 1.0000e-04\n",
      "Epoch 966/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0139 - val_loss: 0.0287 - learning_rate: 1.0000e-04\n",
      "Epoch 967/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0232 - val_loss: 0.0209 - learning_rate: 1.0000e-04\n",
      "Epoch 968/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0153 - val_loss: 0.0178 - learning_rate: 1.0000e-04\n",
      "Epoch 969/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0126 - val_loss: 0.0128 - learning_rate: 1.0000e-04\n",
      "Epoch 970/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0108 - val_loss: 0.0091 - learning_rate: 1.0000e-04\n",
      "Epoch 971/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0106 - val_loss: 0.0134 - learning_rate: 1.0000e-04\n",
      "Epoch 972/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0108 - val_loss: 0.0102 - learning_rate: 1.0000e-04\n",
      "Epoch 973/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0086 - val_loss: 0.0102 - learning_rate: 1.0000e-04\n",
      "Epoch 974/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0086 - val_loss: 0.0096 - learning_rate: 1.0000e-04\n",
      "Epoch 975/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0086 - val_loss: 0.0113 - learning_rate: 1.0000e-04\n",
      "Epoch 976/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 - val_loss: 0.0100 - learning_rate: 1.0000e-04\n",
      "Epoch 977/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0087 - val_loss: 0.0119 - learning_rate: 1.0000e-04\n",
      "Epoch 978/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0110 - val_loss: 0.0128 - learning_rate: 1.0000e-04\n",
      "Epoch 979/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0108 - val_loss: 0.0131 - learning_rate: 1.0000e-04\n",
      "Epoch 980/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0120 - val_loss: 0.0133 - learning_rate: 1.0000e-04\n",
      "Epoch 981/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0164 - val_loss: 0.0163 - learning_rate: 1.0000e-04\n",
      "Epoch 982/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0137 - val_loss: 0.0146 - learning_rate: 1.0000e-04\n",
      "Epoch 983/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0126 - val_loss: 0.0128 - learning_rate: 1.0000e-04\n",
      "Epoch 984/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0106 - val_loss: 0.0123 - learning_rate: 1.0000e-04\n",
      "Epoch 985/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0112 - val_loss: 0.0091 - learning_rate: 1.0000e-04\n",
      "Epoch 986/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 - val_loss: 0.0099 - learning_rate: 1.0000e-04\n",
      "Epoch 987/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0108 - val_loss: 0.0214 - learning_rate: 1.0000e-04\n",
      "Epoch 988/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0137 - val_loss: 0.0129 - learning_rate: 1.0000e-04\n",
      "Epoch 989/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0113 - val_loss: 0.0112 - learning_rate: 1.0000e-04\n",
      "Epoch 990/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0107 - val_loss: 0.0095 - learning_rate: 1.0000e-04\n",
      "Epoch 991/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0100 - val_loss: 0.0155 - learning_rate: 1.0000e-04\n",
      "Epoch 992/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0169 - val_loss: 0.0336 - learning_rate: 1.0000e-04\n",
      "Epoch 993/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0190 - val_loss: 0.0154 - learning_rate: 1.0000e-04\n",
      "Epoch 994/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0129 - val_loss: 0.0147 - learning_rate: 1.0000e-04\n",
      "Epoch 995/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0129 - val_loss: 0.0092 - learning_rate: 1.0000e-04\n",
      "Epoch 996/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0084 - val_loss: 0.0084 - learning_rate: 1.0000e-04\n",
      "Epoch 997/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0097 - learning_rate: 1.0000e-04\n",
      "Epoch 998/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0100 - val_loss: 0.0114 - learning_rate: 1.0000e-04\n",
      "Epoch 999/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0100 - val_loss: 0.0107 - learning_rate: 1.0000e-04\n",
      "Epoch 1000/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0107 - val_loss: 0.0116 - learning_rate: 1.0000e-04\n",
      "Epoch 1001/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0107 - val_loss: 0.0124 - learning_rate: 1.0000e-04\n",
      "Epoch 1002/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0100 - val_loss: 0.0135 - learning_rate: 1.0000e-04\n",
      "Epoch 1003/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0112 - val_loss: 0.0187 - learning_rate: 1.0000e-04\n",
      "Epoch 1004/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0121 - val_loss: 0.0135 - learning_rate: 1.0000e-04\n",
      "Epoch 1005/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0112 - val_loss: 0.0166 - learning_rate: 1.0000e-04\n",
      "Epoch 1006/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0120 - val_loss: 0.0120 - learning_rate: 1.0000e-04\n",
      "Epoch 1007/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0091 - val_loss: 0.0100 - learning_rate: 1.0000e-04\n",
      "Epoch 1008/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0092 - val_loss: 0.0090 - learning_rate: 1.0000e-04\n",
      "Epoch 1009/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0091 - val_loss: 0.0131 - learning_rate: 1.0000e-04\n",
      "Epoch 1010/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0100 - val_loss: 0.0105 - learning_rate: 1.0000e-04\n",
      "Epoch 1011/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0094 - val_loss: 0.0110 - learning_rate: 1.0000e-04\n",
      "Epoch 1012/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0094 - val_loss: 0.0101 - learning_rate: 1.0000e-04\n",
      "Epoch 1013/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0111 - val_loss: 0.0116 - learning_rate: 1.0000e-04\n",
      "Epoch 1014/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0103 - val_loss: 0.0097 - learning_rate: 1.0000e-04\n",
      "Epoch 1015/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0091 - val_loss: 0.0100 - learning_rate: 1.0000e-04\n",
      "Epoch 1016/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0108 - val_loss: 0.0137 - learning_rate: 1.0000e-04\n",
      "Epoch 1017/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0118 - val_loss: 0.0107 - learning_rate: 1.0000e-04\n",
      "Epoch 1018/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0098 - val_loss: 0.0093 - learning_rate: 1.0000e-04\n",
      "Epoch 1019/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0106 - val_loss: 0.0112 - learning_rate: 1.0000e-04\n",
      "Epoch 1020/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0113 - val_loss: 0.0122 - learning_rate: 1.0000e-04\n",
      "Epoch 1021/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0102 - val_loss: 0.0110 - learning_rate: 1.0000e-04\n",
      "Epoch 1022/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0110 - val_loss: 0.0120 - learning_rate: 1.0000e-04\n",
      "Epoch 1023/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0099 - val_loss: 0.0146 - learning_rate: 1.0000e-04\n",
      "Epoch 1024/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0121 - val_loss: 0.0119 - learning_rate: 1.0000e-04\n",
      "Epoch 1025/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0107 - val_loss: 0.0118 - learning_rate: 1.0000e-04\n",
      "Epoch 1026/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0100 - val_loss: 0.0125 - learning_rate: 1.0000e-04\n",
      "Epoch 1027/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0104 - val_loss: 0.0095 - learning_rate: 1.0000e-04\n",
      "Epoch 1028/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0092 - val_loss: 0.0145 - learning_rate: 1.0000e-04\n",
      "Epoch 1029/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0125 - val_loss: 0.0180 - learning_rate: 1.0000e-04\n",
      "Epoch 1030/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0133 - val_loss: 0.0129 - learning_rate: 1.0000e-04\n",
      "Epoch 1031/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0122 - val_loss: 0.0106 - learning_rate: 1.0000e-04\n",
      "Epoch 1032/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0109 - val_loss: 0.0167 - learning_rate: 1.0000e-04\n",
      "Epoch 1033/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0119 - val_loss: 0.0141 - learning_rate: 1.0000e-04\n",
      "Epoch 1034/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0138 - val_loss: 0.0158 - learning_rate: 1.0000e-04\n",
      "Epoch 1035/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0120 - val_loss: 0.0108 - learning_rate: 1.0000e-04\n",
      "Epoch 1036/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0092 - val_loss: 0.0090 - learning_rate: 1.0000e-04\n",
      "Epoch 1037/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0098 - val_loss: 0.0136 - learning_rate: 1.0000e-04\n",
      "Epoch 1038/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0116 - val_loss: 0.0182 - learning_rate: 1.0000e-04\n",
      "Epoch 1039/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0129 - val_loss: 0.0132 - learning_rate: 1.0000e-04\n",
      "Epoch 1040/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0123 - val_loss: 0.0108 - learning_rate: 1.0000e-04\n",
      "Epoch 1041/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0109 - val_loss: 0.0127 - learning_rate: 1.0000e-04\n",
      "Epoch 1042/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0136 - val_loss: 0.0399 - learning_rate: 1.0000e-04\n",
      "Epoch 1043/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0188 - val_loss: 0.0104 - learning_rate: 1.0000e-04\n",
      "Epoch 1044/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0115 - val_loss: 0.0107 - learning_rate: 1.0000e-04\n",
      "Epoch 1045/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0095 - val_loss: 0.0123 - learning_rate: 1.0000e-04\n",
      "Epoch 1046/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0100 - val_loss: 0.0088 - learning_rate: 1.0000e-04\n",
      "Epoch 1047/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0086 - val_loss: 0.0115 - learning_rate: 1.0000e-04\n",
      "Epoch 1048/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0097 - val_loss: 0.0112 - learning_rate: 1.0000e-04\n",
      "Epoch 1049/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0092 - val_loss: 0.0107 - learning_rate: 1.0000e-04\n",
      "Epoch 1050/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0097 - val_loss: 0.0115 - learning_rate: 1.0000e-04\n",
      "Epoch 1051/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0105 - val_loss: 0.0134 - learning_rate: 1.0000e-04\n",
      "Epoch 1052/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0113 - val_loss: 0.0113 - learning_rate: 1.0000e-04\n",
      "Epoch 1053/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0099 - val_loss: 0.0113 - learning_rate: 1.0000e-04\n",
      "Epoch 1054/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0100 - val_loss: 0.0110 - learning_rate: 1.0000e-04\n",
      "Epoch 1055/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0083 - val_loss: 0.0127 - learning_rate: 1.0000e-04\n",
      "Epoch 1056/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0098 - val_loss: 0.0116 - learning_rate: 1.0000e-04\n",
      "Epoch 1057/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0108 - val_loss: 0.0104 - learning_rate: 1.0000e-04\n",
      "Epoch 1058/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0089 - val_loss: 0.0100 - learning_rate: 1.0000e-04\n",
      "Epoch 1059/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0122 - val_loss: 0.0216 - learning_rate: 1.0000e-04\n",
      "Epoch 1060/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0213 - val_loss: 0.0158 - learning_rate: 1.0000e-04\n",
      "Epoch 1061/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0218 - val_loss: 0.0108 - learning_rate: 1.0000e-04\n",
      "Epoch 1062/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0125 - val_loss: 0.0181 - learning_rate: 1.0000e-04\n",
      "Epoch 1063/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0152 - val_loss: 0.0123 - learning_rate: 1.0000e-04\n",
      "Epoch 1064/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0119 - val_loss: 0.0156 - learning_rate: 1.0000e-04\n",
      "Epoch 1065/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0107 - val_loss: 0.0104 - learning_rate: 1.0000e-04\n",
      "Epoch 1066/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0093 - val_loss: 0.0169 - learning_rate: 1.0000e-04\n",
      "Epoch 1067/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0116 - val_loss: 0.0109 - learning_rate: 1.0000e-04\n",
      "Epoch 1068/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0101 - val_loss: 0.0097 - learning_rate: 1.0000e-04\n",
      "Epoch 1069/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0090 - val_loss: 0.0116 - learning_rate: 1.0000e-04\n",
      "Epoch 1070/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0109 - val_loss: 0.0114 - learning_rate: 1.0000e-04\n",
      "Epoch 1071/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0124 - val_loss: 0.0138 - learning_rate: 1.0000e-04\n",
      "Epoch 1072/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0120 - val_loss: 0.0137 - learning_rate: 1.0000e-04\n",
      "Epoch 1073/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0152 - val_loss: 0.0115 - learning_rate: 1.0000e-04\n",
      "Epoch 1074/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0098 - val_loss: 0.0098 - learning_rate: 1.0000e-04\n",
      "Epoch 1075/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0091 - val_loss: 0.0124 - learning_rate: 1.0000e-04\n",
      "Epoch 1076/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0089 - val_loss: 0.0108 - learning_rate: 1.0000e-04\n",
      "Epoch 1077/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0102 - val_loss: 0.0097 - learning_rate: 1.0000e-04\n",
      "Epoch 1078/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0133 - val_loss: 0.0122 - learning_rate: 1.0000e-04\n",
      "Epoch 1079/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0101 - val_loss: 0.0136 - learning_rate: 1.0000e-04\n",
      "Epoch 1080/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0111 - val_loss: 0.0132 - learning_rate: 1.0000e-04\n",
      "Epoch 1081/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0113 - val_loss: 0.0123 - learning_rate: 1.0000e-04\n",
      "Epoch 1082/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0107 - val_loss: 0.0243 - learning_rate: 1.0000e-04\n",
      "Epoch 1083/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0140 - val_loss: 0.0123 - learning_rate: 1.0000e-04\n",
      "Epoch 1084/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0096 - val_loss: 0.0088 - learning_rate: 1.0000e-04\n",
      "Epoch 1085/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0083 - val_loss: 0.0101 - learning_rate: 1.0000e-04\n",
      "Epoch 1086/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0090 - val_loss: 0.0096 - learning_rate: 1.0000e-04\n",
      "Epoch 1087/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0112 - val_loss: 0.0137 - learning_rate: 1.0000e-04\n",
      "Epoch 1088/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0117 - val_loss: 0.0168 - learning_rate: 1.0000e-04\n",
      "Epoch 1089/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0114 - val_loss: 0.0138 - learning_rate: 1.0000e-04\n",
      "Epoch 1090/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0085 - val_loss: 0.0082 - learning_rate: 5.0000e-05\n",
      "Epoch 1091/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0083 - learning_rate: 5.0000e-05\n",
      "Epoch 1092/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0089 - learning_rate: 5.0000e-05\n",
      "Epoch 1093/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0079 - val_loss: 0.0097 - learning_rate: 5.0000e-05\n",
      "Epoch 1094/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0094 - val_loss: 0.0089 - learning_rate: 5.0000e-05\n",
      "Epoch 1095/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0098 - learning_rate: 5.0000e-05\n",
      "Epoch 1096/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0094 - learning_rate: 5.0000e-05\n",
      "Epoch 1097/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0100 - val_loss: 0.0095 - learning_rate: 5.0000e-05\n",
      "Epoch 1098/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0081 - val_loss: 0.0109 - learning_rate: 5.0000e-05\n",
      "Epoch 1099/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0088 - val_loss: 0.0083 - learning_rate: 5.0000e-05\n",
      "Epoch 1100/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0084 - learning_rate: 5.0000e-05\n",
      "Epoch 1101/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0085 - learning_rate: 5.0000e-05\n",
      "Epoch 1102/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0094 - learning_rate: 5.0000e-05\n",
      "Epoch 1103/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0098 - val_loss: 0.0099 - learning_rate: 5.0000e-05\n",
      "Epoch 1104/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0089 - learning_rate: 5.0000e-05\n",
      "Epoch 1105/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0083 - learning_rate: 5.0000e-05\n",
      "Epoch 1106/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0092 - val_loss: 0.0117 - learning_rate: 5.0000e-05\n",
      "Epoch 1107/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0083 - val_loss: 0.0092 - learning_rate: 5.0000e-05\n",
      "Epoch 1108/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0080 - val_loss: 0.0089 - learning_rate: 5.0000e-05\n",
      "Epoch 1109/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0083 - val_loss: 0.0085 - learning_rate: 5.0000e-05\n",
      "Epoch 1110/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0076 - val_loss: 0.0099 - learning_rate: 5.0000e-05\n",
      "Epoch 1111/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0095 - val_loss: 0.0101 - learning_rate: 5.0000e-05\n",
      "Epoch 1112/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0088 - val_loss: 0.0107 - learning_rate: 5.0000e-05\n",
      "Epoch 1113/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0092 - val_loss: 0.0113 - learning_rate: 5.0000e-05\n",
      "Epoch 1114/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0085 - val_loss: 0.0090 - learning_rate: 5.0000e-05\n",
      "Epoch 1115/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0090 - val_loss: 0.0089 - learning_rate: 5.0000e-05\n",
      "Epoch 1116/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0081 - val_loss: 0.0082 - learning_rate: 5.0000e-05\n",
      "Epoch 1117/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0076 - val_loss: 0.0102 - learning_rate: 5.0000e-05\n",
      "Epoch 1118/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0082 - val_loss: 0.0090 - learning_rate: 5.0000e-05\n",
      "Epoch 1119/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0086 - val_loss: 0.0100 - learning_rate: 5.0000e-05\n",
      "Epoch 1120/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0085 - val_loss: 0.0099 - learning_rate: 5.0000e-05\n",
      "Epoch 1121/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0082 - val_loss: 0.0091 - learning_rate: 5.0000e-05\n",
      "Epoch 1122/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0093 - val_loss: 0.0091 - learning_rate: 5.0000e-05\n",
      "Epoch 1123/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0084 - val_loss: 0.0089 - learning_rate: 5.0000e-05\n",
      "Epoch 1124/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 - val_loss: 0.0096 - learning_rate: 5.0000e-05\n",
      "Epoch 1125/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0088 - val_loss: 0.0085 - learning_rate: 5.0000e-05\n",
      "Epoch 1126/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0083 - val_loss: 0.0096 - learning_rate: 5.0000e-05\n",
      "Epoch 1127/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0083 - val_loss: 0.0085 - learning_rate: 5.0000e-05\n",
      "Epoch 1128/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0080 - val_loss: 0.0121 - learning_rate: 5.0000e-05\n",
      "Epoch 1129/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0084 - val_loss: 0.0090 - learning_rate: 5.0000e-05\n",
      "Epoch 1130/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0083 - learning_rate: 5.0000e-05\n",
      "Epoch 1131/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0083 - learning_rate: 5.0000e-05\n",
      "Epoch 1132/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0090 - learning_rate: 5.0000e-05\n",
      "Epoch 1133/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0078 - val_loss: 0.0083 - learning_rate: 5.0000e-05\n",
      "Epoch 1134/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0085 - val_loss: 0.0090 - learning_rate: 5.0000e-05\n",
      "Epoch 1135/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0088 - val_loss: 0.0103 - learning_rate: 5.0000e-05\n",
      "Epoch 1136/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0086 - val_loss: 0.0093 - learning_rate: 5.0000e-05\n",
      "Epoch 1137/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0097 - val_loss: 0.0104 - learning_rate: 5.0000e-05\n",
      "Epoch 1138/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0090 - val_loss: 0.0099 - learning_rate: 5.0000e-05\n",
      "Epoch 1139/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0094 - val_loss: 0.0088 - learning_rate: 5.0000e-05\n",
      "Epoch 1140/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0080 - val_loss: 0.0086 - learning_rate: 5.0000e-05\n",
      "Epoch 1141/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0084 - val_loss: 0.0088 - learning_rate: 5.0000e-05\n",
      "Epoch 1142/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0079 - val_loss: 0.0087 - learning_rate: 5.0000e-05\n",
      "Epoch 1143/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0082 - val_loss: 0.0106 - learning_rate: 5.0000e-05\n",
      "Epoch 1144/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0090 - val_loss: 0.0091 - learning_rate: 5.0000e-05\n",
      "Epoch 1145/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0088 - val_loss: 0.0089 - learning_rate: 5.0000e-05\n",
      "Epoch 1146/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0093 - val_loss: 0.0091 - learning_rate: 5.0000e-05\n",
      "Epoch 1147/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0110 - learning_rate: 5.0000e-05\n",
      "Epoch 1148/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0096 - val_loss: 0.0101 - learning_rate: 5.0000e-05\n",
      "Epoch 1149/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0091 - val_loss: 0.0110 - learning_rate: 5.0000e-05\n",
      "Epoch 1150/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0095 - val_loss: 0.0116 - learning_rate: 5.0000e-05\n",
      "Epoch 1151/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0089 - val_loss: 0.0090 - learning_rate: 5.0000e-05\n",
      "Epoch 1152/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0086 - val_loss: 0.0108 - learning_rate: 5.0000e-05\n",
      "Epoch 1153/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0095 - val_loss: 0.0118 - learning_rate: 5.0000e-05\n",
      "Epoch 1154/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0090 - val_loss: 0.0095 - learning_rate: 5.0000e-05\n",
      "Epoch 1155/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0103 - val_loss: 0.0125 - learning_rate: 5.0000e-05\n",
      "Epoch 1156/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0095 - val_loss: 0.0099 - learning_rate: 5.0000e-05\n",
      "Epoch 1157/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0103 - val_loss: 0.0092 - learning_rate: 5.0000e-05\n",
      "Epoch 1158/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0087 - val_loss: 0.0098 - learning_rate: 5.0000e-05\n",
      "Epoch 1159/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0090 - val_loss: 0.0090 - learning_rate: 5.0000e-05\n",
      "Epoch 1160/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0081 - val_loss: 0.0084 - learning_rate: 5.0000e-05\n",
      "Epoch 1161/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0079 - val_loss: 0.0088 - learning_rate: 5.0000e-05\n",
      "Epoch 1162/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0080 - val_loss: 0.0096 - learning_rate: 5.0000e-05\n",
      "Epoch 1163/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0083 - val_loss: 0.0092 - learning_rate: 5.0000e-05\n",
      "Epoch 1164/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0092 - val_loss: 0.0123 - learning_rate: 5.0000e-05\n",
      "Epoch 1165/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0093 - val_loss: 0.0095 - learning_rate: 5.0000e-05\n",
      "Epoch 1166/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0083 - val_loss: 0.0100 - learning_rate: 5.0000e-05\n",
      "Epoch 1167/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0080 - val_loss: 0.0093 - learning_rate: 5.0000e-05\n",
      "Epoch 1168/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0081 - val_loss: 0.0095 - learning_rate: 5.0000e-05\n",
      "Epoch 1169/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0085 - val_loss: 0.0090 - learning_rate: 5.0000e-05\n",
      "Epoch 1170/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0086 - val_loss: 0.0103 - learning_rate: 5.0000e-05\n",
      "Epoch 1171/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0087 - val_loss: 0.0088 - learning_rate: 5.0000e-05\n",
      "Epoch 1172/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0077 - val_loss: 0.0087 - learning_rate: 5.0000e-05\n",
      "Epoch 1173/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0081 - val_loss: 0.0124 - learning_rate: 5.0000e-05\n",
      "Epoch 1174/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0094 - val_loss: 0.0109 - learning_rate: 5.0000e-05\n",
      "Epoch 1175/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0094 - val_loss: 0.0085 - learning_rate: 5.0000e-05\n",
      "Epoch 1176/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0076 - val_loss: 0.0090 - learning_rate: 5.0000e-05\n",
      "Epoch 1177/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0089 - val_loss: 0.0101 - learning_rate: 5.0000e-05\n",
      "Epoch 1178/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0101 - val_loss: 0.0104 - learning_rate: 5.0000e-05\n",
      "Epoch 1179/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0091 - val_loss: 0.0112 - learning_rate: 5.0000e-05\n",
      "Epoch 1180/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0103 - val_loss: 0.0087 - learning_rate: 5.0000e-05\n",
      "Epoch 1181/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0085 - val_loss: 0.0098 - learning_rate: 5.0000e-05\n",
      "Epoch 1182/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0091 - val_loss: 0.0141 - learning_rate: 5.0000e-05\n",
      "Epoch 1183/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0106 - val_loss: 0.0094 - learning_rate: 5.0000e-05\n",
      "Epoch 1184/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0081 - val_loss: 0.0111 - learning_rate: 5.0000e-05\n",
      "Epoch 1185/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0092 - val_loss: 0.0097 - learning_rate: 5.0000e-05\n",
      "Epoch 1186/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0094 - val_loss: 0.0131 - learning_rate: 5.0000e-05\n",
      "Epoch 1187/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0119 - val_loss: 0.0097 - learning_rate: 5.0000e-05\n",
      "Epoch 1188/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0094 - val_loss: 0.0102 - learning_rate: 5.0000e-05\n",
      "Epoch 1189/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0087 - val_loss: 0.0115 - learning_rate: 5.0000e-05\n",
      "Epoch 1190/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0103 - val_loss: 0.0093 - learning_rate: 5.0000e-05\n",
      "Epoch 1191/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0090 - val_loss: 0.0087 - learning_rate: 5.0000e-05\n",
      "Epoch 1192/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0098 - val_loss: 0.0090 - learning_rate: 5.0000e-05\n",
      "Epoch 1193/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0090 - val_loss: 0.0108 - learning_rate: 5.0000e-05\n",
      "Epoch 1194/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0106 - val_loss: 0.0105 - learning_rate: 5.0000e-05\n",
      "Epoch 1195/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0083 - val_loss: 0.0095 - learning_rate: 5.0000e-05\n",
      "Epoch 1196/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0089 - val_loss: 0.0104 - learning_rate: 5.0000e-05\n",
      "Epoch 1197/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 - val_loss: 0.0083 - learning_rate: 5.0000e-05\n",
      "Epoch 1198/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0082 - val_loss: 0.0094 - learning_rate: 5.0000e-05\n",
      "Epoch 1199/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0087 - val_loss: 0.0099 - learning_rate: 5.0000e-05\n",
      "Epoch 1200/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0084 - val_loss: 0.0100 - learning_rate: 5.0000e-05\n",
      "Epoch 1201/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0087 - val_loss: 0.0099 - learning_rate: 5.0000e-05\n",
      "Epoch 1202/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0074 - val_loss: 0.0087 - learning_rate: 5.0000e-05\n",
      "Epoch 1203/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0087 - val_loss: 0.0094 - learning_rate: 5.0000e-05\n",
      "Epoch 1204/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0090 - val_loss: 0.0109 - learning_rate: 5.0000e-05\n",
      "Epoch 1205/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0096 - val_loss: 0.0099 - learning_rate: 5.0000e-05\n",
      "Epoch 1206/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0093 - val_loss: 0.0094 - learning_rate: 5.0000e-05\n",
      "Epoch 1207/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0094 - val_loss: 0.0100 - learning_rate: 5.0000e-05\n",
      "Epoch 1208/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0085 - val_loss: 0.0095 - learning_rate: 5.0000e-05\n",
      "Epoch 1209/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0121 - val_loss: 0.0092 - learning_rate: 5.0000e-05\n",
      "Epoch 1210/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0074 - val_loss: 0.0104 - learning_rate: 5.0000e-05\n",
      "Epoch 1211/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0089 - val_loss: 0.0113 - learning_rate: 5.0000e-05\n",
      "Epoch 1212/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0096 - val_loss: 0.0107 - learning_rate: 5.0000e-05\n",
      "Epoch 1213/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0107 - val_loss: 0.0098 - learning_rate: 5.0000e-05\n",
      "Epoch 1214/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0086 - val_loss: 0.0104 - learning_rate: 5.0000e-05\n",
      "Epoch 1215/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0083 - val_loss: 0.0109 - learning_rate: 5.0000e-05\n",
      "Epoch 1216/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0094 - val_loss: 0.0092 - learning_rate: 5.0000e-05\n",
      "Epoch 1217/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0089 - val_loss: 0.0106 - learning_rate: 5.0000e-05\n",
      "Epoch 1218/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0093 - val_loss: 0.0087 - learning_rate: 5.0000e-05\n",
      "Epoch 1219/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0087 - val_loss: 0.0096 - learning_rate: 5.0000e-05\n",
      "Epoch 1220/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0075 - val_loss: 0.0084 - learning_rate: 5.0000e-05\n",
      "Epoch 1221/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0085 - val_loss: 0.0101 - learning_rate: 5.0000e-05\n",
      "Epoch 1222/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0087 - val_loss: 0.0109 - learning_rate: 5.0000e-05\n",
      "Epoch 1223/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0085 - val_loss: 0.0094 - learning_rate: 5.0000e-05\n",
      "Epoch 1224/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0084 - val_loss: 0.0098 - learning_rate: 5.0000e-05\n",
      "Epoch 1225/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0096 - val_loss: 0.0110 - learning_rate: 5.0000e-05\n",
      "Epoch 1226/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0088 - val_loss: 0.0131 - learning_rate: 5.0000e-05\n",
      "Epoch 1227/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0095 - val_loss: 0.0086 - learning_rate: 5.0000e-05\n",
      "Epoch 1228/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0090 - val_loss: 0.0097 - learning_rate: 5.0000e-05\n",
      "Epoch 1229/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0092 - val_loss: 0.0118 - learning_rate: 5.0000e-05\n",
      "Epoch 1230/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0092 - val_loss: 0.0102 - learning_rate: 5.0000e-05\n",
      "Epoch 1231/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0090 - val_loss: 0.0104 - learning_rate: 5.0000e-05\n",
      "Epoch 1232/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0085 - val_loss: 0.0127 - learning_rate: 5.0000e-05\n",
      "Epoch 1233/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0100 - val_loss: 0.0109 - learning_rate: 5.0000e-05\n",
      "Epoch 1234/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0098 - val_loss: 0.0091 - learning_rate: 5.0000e-05\n",
      "Epoch 1235/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0084 - val_loss: 0.0088 - learning_rate: 5.0000e-05\n",
      "Epoch 1236/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0078 - val_loss: 0.0084 - learning_rate: 5.0000e-05\n",
      "Epoch 1237/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0081 - val_loss: 0.0104 - learning_rate: 5.0000e-05\n",
      "Epoch 1238/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0090 - val_loss: 0.0087 - learning_rate: 5.0000e-05\n",
      "Epoch 1239/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0090 - val_loss: 0.0101 - learning_rate: 5.0000e-05\n",
      "Epoch 1240/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0094 - val_loss: 0.0099 - learning_rate: 5.0000e-05\n",
      "Epoch 1241/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0090 - val_loss: 0.0099 - learning_rate: 5.0000e-05\n",
      "Epoch 1242/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0088 - val_loss: 0.0102 - learning_rate: 5.0000e-05\n",
      "Epoch 1243/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0098 - learning_rate: 5.0000e-05\n",
      "Epoch 1244/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0085 - val_loss: 0.0091 - learning_rate: 5.0000e-05\n",
      "Epoch 1245/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0086 - val_loss: 0.0103 - learning_rate: 5.0000e-05\n",
      "Epoch 1246/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0097 - val_loss: 0.0116 - learning_rate: 5.0000e-05\n",
      "Epoch 1247/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0092 - val_loss: 0.0085 - learning_rate: 5.0000e-05\n",
      "Epoch 1248/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0107 - learning_rate: 5.0000e-05\n",
      "Epoch 1249/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0082 - val_loss: 0.0099 - learning_rate: 5.0000e-05\n",
      "Epoch 1250/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0093 - val_loss: 0.0120 - learning_rate: 5.0000e-05\n",
      "Epoch 1251/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0124 - val_loss: 0.0100 - learning_rate: 5.0000e-05\n",
      "Epoch 1252/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0085 - val_loss: 0.0086 - learning_rate: 5.0000e-05\n",
      "Epoch 1253/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0083 - val_loss: 0.0094 - learning_rate: 5.0000e-05\n",
      "Epoch 1254/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0095 - val_loss: 0.0096 - learning_rate: 5.0000e-05\n",
      "Epoch 1255/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0083 - val_loss: 0.0130 - learning_rate: 5.0000e-05\n",
      "Epoch 1256/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0099 - val_loss: 0.0102 - learning_rate: 5.0000e-05\n",
      "Epoch 1257/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0097 - val_loss: 0.0094 - learning_rate: 5.0000e-05\n",
      "Epoch 1258/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 - val_loss: 0.0134 - learning_rate: 5.0000e-05\n",
      "Epoch 1259/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0111 - val_loss: 0.0146 - learning_rate: 5.0000e-05\n",
      "Epoch 1260/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0092 - val_loss: 0.0092 - learning_rate: 5.0000e-05\n",
      "Epoch 1261/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0086 - val_loss: 0.0108 - learning_rate: 5.0000e-05\n",
      "Epoch 1262/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0082 - val_loss: 0.0088 - learning_rate: 5.0000e-05\n",
      "Epoch 1263/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0086 - learning_rate: 5.0000e-05\n",
      "Epoch 1264/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0080 - val_loss: 0.0101 - learning_rate: 5.0000e-05\n",
      "Epoch 1265/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0095 - val_loss: 0.0085 - learning_rate: 5.0000e-05\n",
      "Epoch 1266/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0095 - learning_rate: 5.0000e-05\n",
      "Epoch 1267/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0083 - val_loss: 0.0108 - learning_rate: 5.0000e-05\n",
      "Epoch 1268/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0085 - val_loss: 0.0094 - learning_rate: 5.0000e-05\n",
      "Epoch 1269/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0097 - val_loss: 0.0088 - learning_rate: 5.0000e-05\n",
      "Epoch 1270/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0086 - val_loss: 0.0104 - learning_rate: 5.0000e-05\n",
      "Epoch 1271/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0088 - learning_rate: 5.0000e-05\n",
      "Epoch 1272/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0110 - val_loss: 0.0218 - learning_rate: 5.0000e-05\n",
      "Epoch 1273/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0123 - val_loss: 0.0103 - learning_rate: 5.0000e-05\n",
      "Epoch 1274/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0095 - val_loss: 0.0095 - learning_rate: 5.0000e-05\n",
      "Epoch 1275/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0085 - val_loss: 0.0100 - learning_rate: 5.0000e-05\n",
      "Epoch 1276/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0090 - val_loss: 0.0101 - learning_rate: 5.0000e-05\n",
      "Epoch 1277/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0096 - learning_rate: 5.0000e-05\n",
      "Epoch 1278/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0102 - val_loss: 0.0096 - learning_rate: 5.0000e-05\n",
      "Epoch 1279/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0099 - learning_rate: 5.0000e-05\n",
      "Epoch 1280/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0083 - val_loss: 0.0110 - learning_rate: 5.0000e-05\n",
      "Epoch 1281/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0084 - val_loss: 0.0101 - learning_rate: 5.0000e-05\n",
      "Epoch 1282/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0096 - val_loss: 0.0087 - learning_rate: 5.0000e-05\n",
      "Epoch 1283/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0099 - val_loss: 0.0093 - learning_rate: 5.0000e-05\n",
      "Epoch 1284/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0091 - val_loss: 0.0132 - learning_rate: 5.0000e-05\n",
      "Epoch 1285/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0089 - val_loss: 0.0111 - learning_rate: 5.0000e-05\n",
      "Epoch 1286/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0084 - val_loss: 0.0087 - learning_rate: 5.0000e-05\n",
      "Epoch 1287/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0100 - learning_rate: 5.0000e-05\n",
      "Epoch 1288/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0090 - val_loss: 0.0117 - learning_rate: 5.0000e-05\n",
      "Epoch 1289/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0104 - val_loss: 0.0139 - learning_rate: 5.0000e-05\n",
      "Epoch 1290/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0102 - val_loss: 0.0108 - learning_rate: 5.0000e-05\n",
      "Epoch 1291/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0077 - val_loss: 0.0111 - learning_rate: 5.0000e-05\n",
      "Epoch 1292/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0099 - val_loss: 0.0095 - learning_rate: 5.0000e-05\n",
      "Epoch 1293/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0086 - val_loss: 0.0117 - learning_rate: 5.0000e-05\n",
      "Epoch 1294/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0093 - val_loss: 0.0089 - learning_rate: 5.0000e-05\n",
      "Epoch 1295/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0084 - learning_rate: 5.0000e-05\n",
      "Epoch 1296/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0082 - val_loss: 0.0092 - learning_rate: 5.0000e-05\n",
      "Epoch 1297/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0090 - learning_rate: 5.0000e-05\n",
      "Epoch 1298/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0085 - learning_rate: 5.0000e-05\n",
      "Epoch 1299/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0088 - learning_rate: 5.0000e-05\n",
      "Epoch 1300/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0085 - val_loss: 0.0112 - learning_rate: 5.0000e-05\n",
      "Epoch 1301/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 - val_loss: 0.0102 - learning_rate: 5.0000e-05\n",
      "Epoch 1302/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0090 - val_loss: 0.0094 - learning_rate: 5.0000e-05\n",
      "Epoch 1303/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0088 - val_loss: 0.0098 - learning_rate: 5.0000e-05\n",
      "Epoch 1304/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0120 - learning_rate: 5.0000e-05\n",
      "Epoch 1305/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0102 - val_loss: 0.0125 - learning_rate: 5.0000e-05\n",
      "Epoch 1306/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0099 - val_loss: 0.0113 - learning_rate: 5.0000e-05\n",
      "Epoch 1307/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0100 - val_loss: 0.0159 - learning_rate: 5.0000e-05\n",
      "Epoch 1308/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0110 - val_loss: 0.0093 - learning_rate: 5.0000e-05\n",
      "Epoch 1309/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0094 - val_loss: 0.0110 - learning_rate: 5.0000e-05\n",
      "Epoch 1310/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0093 - val_loss: 0.0147 - learning_rate: 5.0000e-05\n",
      "Epoch 1311/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0124 - val_loss: 0.0099 - learning_rate: 5.0000e-05\n",
      "Epoch 1312/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0133 - val_loss: 0.0194 - learning_rate: 5.0000e-05\n",
      "Epoch 1313/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0121 - val_loss: 0.0171 - learning_rate: 5.0000e-05\n",
      "Epoch 1314/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0106 - val_loss: 0.0091 - learning_rate: 5.0000e-05\n",
      "Epoch 1315/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0092 - val_loss: 0.0092 - learning_rate: 5.0000e-05\n",
      "Epoch 1316/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0084 - val_loss: 0.0091 - learning_rate: 5.0000e-05\n",
      "Epoch 1317/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0090 - val_loss: 0.0102 - learning_rate: 5.0000e-05\n",
      "Epoch 1318/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0089 - learning_rate: 5.0000e-05\n",
      "Epoch 1319/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0097 - learning_rate: 5.0000e-05\n",
      "Epoch 1320/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0112 - learning_rate: 5.0000e-05\n",
      "Epoch 1321/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0088 - val_loss: 0.0099 - learning_rate: 5.0000e-05\n",
      "Epoch 1322/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0084 - val_loss: 0.0096 - learning_rate: 5.0000e-05\n",
      "Epoch 1323/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0091 - learning_rate: 5.0000e-05\n",
      "Epoch 1324/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0088 - val_loss: 0.0097 - learning_rate: 5.0000e-05\n",
      "Epoch 1325/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0083 - val_loss: 0.0091 - learning_rate: 5.0000e-05\n",
      "Epoch 1326/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0082 - val_loss: 0.0112 - learning_rate: 5.0000e-05\n",
      "Epoch 1327/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0092 - val_loss: 0.0088 - learning_rate: 5.0000e-05\n",
      "Epoch 1328/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0086 - val_loss: 0.0106 - learning_rate: 5.0000e-05\n",
      "Epoch 1329/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0104 - val_loss: 0.0146 - learning_rate: 5.0000e-05\n",
      "Epoch 1330/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0113 - val_loss: 0.0109 - learning_rate: 5.0000e-05\n",
      "Epoch 1331/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 - val_loss: 0.0095 - learning_rate: 5.0000e-05\n",
      "Epoch 1332/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0090 - val_loss: 0.0109 - learning_rate: 5.0000e-05\n",
      "Epoch 1333/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0086 - val_loss: 0.0091 - learning_rate: 5.0000e-05\n",
      "Epoch 1334/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0086 - learning_rate: 5.0000e-05\n",
      "Epoch 1335/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0089 - val_loss: 0.0129 - learning_rate: 5.0000e-05\n",
      "Epoch 1336/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0110 - val_loss: 0.0102 - learning_rate: 5.0000e-05\n",
      "Epoch 1337/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0090 - learning_rate: 5.0000e-05\n",
      "Epoch 1338/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0085 - val_loss: 0.0141 - learning_rate: 5.0000e-05\n",
      "Epoch 1339/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0116 - val_loss: 0.0114 - learning_rate: 5.0000e-05\n",
      "Epoch 1340/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0093 - val_loss: 0.0113 - learning_rate: 5.0000e-05\n",
      "Epoch 1341/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0093 - val_loss: 0.0095 - learning_rate: 5.0000e-05\n",
      "Epoch 1342/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0088 - learning_rate: 5.0000e-05\n",
      "Epoch 1343/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0085 - val_loss: 0.0101 - learning_rate: 5.0000e-05\n",
      "Epoch 1344/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 - val_loss: 0.0088 - learning_rate: 5.0000e-05\n",
      "Epoch 1345/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0085 - val_loss: 0.0095 - learning_rate: 5.0000e-05\n",
      "Epoch 1346/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0085 - val_loss: 0.0090 - learning_rate: 5.0000e-05\n",
      "Epoch 1347/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0083 - val_loss: 0.0088 - learning_rate: 5.0000e-05\n",
      "Epoch 1348/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0086 - val_loss: 0.0094 - learning_rate: 5.0000e-05\n",
      "Epoch 1349/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0090 - val_loss: 0.0129 - learning_rate: 5.0000e-05\n",
      "Epoch 1350/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0089 - val_loss: 0.0109 - learning_rate: 5.0000e-05\n",
      "Epoch 1351/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0089 - val_loss: 0.0104 - learning_rate: 5.0000e-05\n",
      "Epoch 1352/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0084 - val_loss: 0.0101 - learning_rate: 5.0000e-05\n",
      "Epoch 1353/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0086 - learning_rate: 5.0000e-05\n",
      "Epoch 1354/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0131 - learning_rate: 5.0000e-05\n",
      "Epoch 1355/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0092 - val_loss: 0.0099 - learning_rate: 5.0000e-05\n",
      "Epoch 1356/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0089 - val_loss: 0.0096 - learning_rate: 5.0000e-05\n",
      "Epoch 1357/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0083 - val_loss: 0.0094 - learning_rate: 5.0000e-05\n",
      "Epoch 1358/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0086 - val_loss: 0.0123 - learning_rate: 5.0000e-05\n",
      "Epoch 1359/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0093 - val_loss: 0.0103 - learning_rate: 5.0000e-05\n",
      "Epoch 1360/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0089 - val_loss: 0.0120 - learning_rate: 5.0000e-05\n",
      "Epoch 1361/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0093 - val_loss: 0.0104 - learning_rate: 5.0000e-05\n",
      "Epoch 1362/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0106 - val_loss: 0.0090 - learning_rate: 5.0000e-05\n",
      "Epoch 1363/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0096 - val_loss: 0.0114 - learning_rate: 5.0000e-05\n",
      "Epoch 1364/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0107 - val_loss: 0.0093 - learning_rate: 5.0000e-05\n",
      "Epoch 1365/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0107 - val_loss: 0.0104 - learning_rate: 5.0000e-05\n",
      "Epoch 1366/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0088 - val_loss: 0.0106 - learning_rate: 5.0000e-05\n",
      "Epoch 1367/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0089 - val_loss: 0.0114 - learning_rate: 5.0000e-05\n",
      "Epoch 1368/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0106 - val_loss: 0.0116 - learning_rate: 5.0000e-05\n",
      "Epoch 1369/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0091 - val_loss: 0.0088 - learning_rate: 5.0000e-05\n",
      "Epoch 1370/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0113 - learning_rate: 5.0000e-05\n",
      "Epoch 1371/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0085 - val_loss: 0.0087 - learning_rate: 5.0000e-05\n",
      "Epoch 1372/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0090 - val_loss: 0.0100 - learning_rate: 5.0000e-05\n",
      "Epoch 1373/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0102 - val_loss: 0.0114 - learning_rate: 5.0000e-05\n",
      "Epoch 1374/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0089 - val_loss: 0.0092 - learning_rate: 5.0000e-05\n",
      "Epoch 1375/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0083 - val_loss: 0.0084 - learning_rate: 5.0000e-05\n",
      "Epoch 1376/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0092 - val_loss: 0.0133 - learning_rate: 5.0000e-05\n",
      "Epoch 1377/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0116 - val_loss: 0.0121 - learning_rate: 5.0000e-05\n",
      "Epoch 1378/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0109 - val_loss: 0.0112 - learning_rate: 5.0000e-05\n",
      "Epoch 1379/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0082 - val_loss: 0.0088 - learning_rate: 5.0000e-05\n",
      "Epoch 1380/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0089 - learning_rate: 5.0000e-05\n",
      "Epoch 1381/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0099 - learning_rate: 5.0000e-05\n",
      "Epoch 1382/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0084 - val_loss: 0.0162 - learning_rate: 5.0000e-05\n",
      "Epoch 1383/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0114 - val_loss: 0.0124 - learning_rate: 5.0000e-05\n",
      "Epoch 1384/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0093 - val_loss: 0.0100 - learning_rate: 5.0000e-05\n",
      "Epoch 1385/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0095 - val_loss: 0.0092 - learning_rate: 5.0000e-05\n",
      "Epoch 1386/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0084 - val_loss: 0.0091 - learning_rate: 5.0000e-05\n",
      "Epoch 1387/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 - val_loss: 0.0147 - learning_rate: 5.0000e-05\n",
      "Epoch 1388/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0102 - val_loss: 0.0128 - learning_rate: 5.0000e-05\n",
      "Epoch 1389/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0099 - val_loss: 0.0104 - learning_rate: 5.0000e-05\n",
      "Epoch 1390/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 - val_loss: 0.0115 - learning_rate: 5.0000e-05\n",
      "Epoch 1391/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0084 - val_loss: 0.0091 - learning_rate: 5.0000e-05\n",
      "Epoch 1392/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0083 - learning_rate: 5.0000e-05\n",
      "Epoch 1393/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0086 - learning_rate: 5.0000e-05\n",
      "Epoch 1394/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0099 - learning_rate: 5.0000e-05\n",
      "Epoch 1395/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0085 - val_loss: 0.0103 - learning_rate: 5.0000e-05\n",
      "Epoch 1396/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0083 - learning_rate: 5.0000e-05\n",
      "Epoch 1397/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0114 - learning_rate: 5.0000e-05\n",
      "Epoch 1398/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0106 - val_loss: 0.0129 - learning_rate: 5.0000e-05\n",
      "Epoch 1399/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0109 - val_loss: 0.0092 - learning_rate: 5.0000e-05\n",
      "Epoch 1400/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0102 - val_loss: 0.0093 - learning_rate: 5.0000e-05\n",
      "Epoch 1401/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0085 - val_loss: 0.0093 - learning_rate: 5.0000e-05\n",
      "Epoch 1402/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0092 - val_loss: 0.0093 - learning_rate: 5.0000e-05\n",
      "Epoch 1403/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0086 - val_loss: 0.0090 - learning_rate: 5.0000e-05\n",
      "Epoch 1404/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0088 - val_loss: 0.0101 - learning_rate: 5.0000e-05\n",
      "Epoch 1405/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0086 - val_loss: 0.0095 - learning_rate: 5.0000e-05\n",
      "Epoch 1406/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 - val_loss: 0.0093 - learning_rate: 5.0000e-05\n",
      "Epoch 1407/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0090 - val_loss: 0.0115 - learning_rate: 5.0000e-05\n",
      "Epoch 1408/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0091 - val_loss: 0.0092 - learning_rate: 5.0000e-05\n",
      "Epoch 1409/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0091 - learning_rate: 5.0000e-05\n",
      "Epoch 1410/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0087 - learning_rate: 5.0000e-05\n",
      "Epoch 1411/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0083 - learning_rate: 5.0000e-05\n",
      "Epoch 1412/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 - val_loss: 0.0107 - learning_rate: 5.0000e-05\n",
      "Epoch 1413/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0089 - val_loss: 0.0097 - learning_rate: 5.0000e-05\n",
      "Epoch 1414/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0083 - val_loss: 0.0113 - learning_rate: 5.0000e-05\n",
      "Epoch 1415/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0088 - val_loss: 0.0089 - learning_rate: 5.0000e-05\n",
      "Epoch 1416/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0084 - val_loss: 0.0104 - learning_rate: 5.0000e-05\n",
      "Epoch 1417/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0092 - val_loss: 0.0097 - learning_rate: 5.0000e-05\n",
      "Epoch 1418/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0092 - val_loss: 0.0095 - learning_rate: 5.0000e-05\n",
      "Epoch 1419/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0115 - learning_rate: 5.0000e-05\n",
      "Epoch 1420/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0088 - val_loss: 0.0091 - learning_rate: 5.0000e-05\n",
      "Epoch 1421/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0086 - val_loss: 0.0087 - learning_rate: 5.0000e-05\n",
      "Epoch 1422/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0099 - val_loss: 0.0187 - learning_rate: 5.0000e-05\n",
      "Epoch 1423/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0133 - val_loss: 0.0110 - learning_rate: 5.0000e-05\n",
      "Epoch 1424/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0096 - val_loss: 0.0167 - learning_rate: 5.0000e-05\n",
      "Epoch 1425/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0118 - val_loss: 0.0118 - learning_rate: 5.0000e-05\n",
      "Epoch 1426/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0091 - val_loss: 0.0101 - learning_rate: 5.0000e-05\n",
      "Epoch 1427/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0097 - val_loss: 0.0105 - learning_rate: 5.0000e-05\n",
      "Epoch 1428/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0108 - val_loss: 0.0096 - learning_rate: 5.0000e-05\n",
      "Epoch 1429/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0086 - val_loss: 0.0090 - learning_rate: 5.0000e-05\n",
      "Epoch 1430/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0106 - learning_rate: 5.0000e-05\n",
      "Epoch 1431/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0096 - val_loss: 0.0182 - learning_rate: 5.0000e-05\n",
      "Epoch 1432/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0125 - val_loss: 0.0106 - learning_rate: 5.0000e-05\n",
      "Epoch 1433/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0095 - val_loss: 0.0109 - learning_rate: 5.0000e-05\n",
      "Epoch 1434/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0093 - val_loss: 0.0088 - learning_rate: 5.0000e-05\n",
      "Epoch 1435/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0082 - val_loss: 0.0085 - learning_rate: 5.0000e-05\n",
      "Epoch 1436/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0093 - val_loss: 0.0150 - learning_rate: 5.0000e-05\n",
      "Epoch 1437/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0106 - val_loss: 0.0095 - learning_rate: 5.0000e-05\n",
      "Epoch 1438/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0095 - val_loss: 0.0110 - learning_rate: 5.0000e-05\n",
      "Epoch 1439/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0103 - val_loss: 0.0092 - learning_rate: 5.0000e-05\n",
      "Epoch 1440/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0084 - val_loss: 0.0107 - learning_rate: 5.0000e-05\n",
      "Epoch 1441/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0091 - val_loss: 0.0102 - learning_rate: 5.0000e-05\n",
      "Epoch 1442/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0092 - val_loss: 0.0113 - learning_rate: 5.0000e-05\n",
      "Epoch 1443/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0088 - val_loss: 0.0094 - learning_rate: 5.0000e-05\n",
      "Epoch 1444/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0094 - val_loss: 0.0096 - learning_rate: 5.0000e-05\n",
      "Epoch 1445/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0094 - learning_rate: 5.0000e-05\n",
      "Epoch 1446/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0098 - val_loss: 0.0102 - learning_rate: 5.0000e-05\n",
      "Epoch 1447/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0083 - val_loss: 0.0089 - learning_rate: 5.0000e-05\n",
      "Epoch 1448/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0088 - val_loss: 0.0099 - learning_rate: 5.0000e-05\n",
      "Epoch 1449/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0087 - val_loss: 0.0085 - learning_rate: 5.0000e-05\n",
      "Epoch 1450/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0085 - val_loss: 0.0169 - learning_rate: 5.0000e-05\n",
      "Epoch 1451/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0111 - val_loss: 0.0099 - learning_rate: 5.0000e-05\n",
      "Epoch 1452/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0094 - val_loss: 0.0117 - learning_rate: 5.0000e-05\n",
      "Epoch 1453/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0119 - val_loss: 0.0117 - learning_rate: 5.0000e-05\n",
      "Epoch 1454/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0094 - val_loss: 0.0082 - learning_rate: 5.0000e-05\n",
      "Epoch 1455/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0086 - val_loss: 0.0104 - learning_rate: 5.0000e-05\n",
      "Epoch 1456/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0083 - val_loss: 0.0086 - learning_rate: 5.0000e-05\n",
      "Epoch 1457/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0085 - val_loss: 0.0089 - learning_rate: 5.0000e-05\n",
      "Epoch 1458/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0092 - learning_rate: 5.0000e-05\n",
      "Epoch 1459/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0085 - val_loss: 0.0092 - learning_rate: 5.0000e-05\n",
      "Epoch 1460/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0105 - learning_rate: 5.0000e-05\n",
      "Epoch 1461/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 - val_loss: 0.0133 - learning_rate: 5.0000e-05\n",
      "Epoch 1462/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0096 - val_loss: 0.0095 - learning_rate: 5.0000e-05\n",
      "Epoch 1463/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0083 - val_loss: 0.0108 - learning_rate: 5.0000e-05\n",
      "Epoch 1464/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0092 - val_loss: 0.0088 - learning_rate: 5.0000e-05\n",
      "Epoch 1465/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0086 - val_loss: 0.0113 - learning_rate: 5.0000e-05\n",
      "Epoch 1466/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0097 - val_loss: 0.0090 - learning_rate: 5.0000e-05\n",
      "Epoch 1467/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0083 - val_loss: 0.0090 - learning_rate: 5.0000e-05\n",
      "Epoch 1468/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0090 - val_loss: 0.0096 - learning_rate: 5.0000e-05\n",
      "Epoch 1469/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0091 - val_loss: 0.0118 - learning_rate: 5.0000e-05\n",
      "Epoch 1470/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0098 - val_loss: 0.0108 - learning_rate: 5.0000e-05\n",
      "Epoch 1471/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0090 - val_loss: 0.0093 - learning_rate: 5.0000e-05\n",
      "Epoch 1472/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0076 - val_loss: 0.0115 - learning_rate: 5.0000e-05\n",
      "Epoch 1473/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0094 - val_loss: 0.0092 - learning_rate: 5.0000e-05\n",
      "Epoch 1474/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0082 - val_loss: 0.0095 - learning_rate: 5.0000e-05\n",
      "Epoch 1475/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0123 - learning_rate: 5.0000e-05\n",
      "Epoch 1476/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0097 - val_loss: 0.0093 - learning_rate: 5.0000e-05\n",
      "Epoch 1477/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0086 - val_loss: 0.0087 - learning_rate: 5.0000e-05\n",
      "Epoch 1478/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0082 - val_loss: 0.0088 - learning_rate: 5.0000e-05\n",
      "Epoch 1479/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0086 - val_loss: 0.0091 - learning_rate: 5.0000e-05\n",
      "Epoch 1480/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0085 - val_loss: 0.0094 - learning_rate: 5.0000e-05\n",
      "Epoch 1481/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0090 - learning_rate: 5.0000e-05\n",
      "Epoch 1482/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0085 - val_loss: 0.0109 - learning_rate: 5.0000e-05\n",
      "Epoch 1483/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0099 - val_loss: 0.0094 - learning_rate: 5.0000e-05\n",
      "Epoch 1484/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0094 - learning_rate: 5.0000e-05\n",
      "Epoch 1485/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0088 - val_loss: 0.0092 - learning_rate: 5.0000e-05\n",
      "Epoch 1486/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0098 - val_loss: 0.0124 - learning_rate: 5.0000e-05\n",
      "Epoch 1487/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0095 - val_loss: 0.0109 - learning_rate: 5.0000e-05\n",
      "Epoch 1488/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0104 - val_loss: 0.0093 - learning_rate: 5.0000e-05\n",
      "Epoch 1489/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0103 - learning_rate: 5.0000e-05\n",
      "Epoch 1490/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0104 - val_loss: 0.0105 - learning_rate: 5.0000e-05\n",
      "Epoch 1491/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0093 - val_loss: 0.0096 - learning_rate: 5.0000e-05\n",
      "Epoch 1492/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 - val_loss: 0.0094 - learning_rate: 5.0000e-05\n",
      "Epoch 1493/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0108 - learning_rate: 5.0000e-05\n",
      "Epoch 1494/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0098 - val_loss: 0.0090 - learning_rate: 5.0000e-05\n",
      "Epoch 1495/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0103 - learning_rate: 5.0000e-05\n",
      "Epoch 1496/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0089 - val_loss: 0.0128 - learning_rate: 5.0000e-05\n",
      "Epoch 1497/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0096 - val_loss: 0.0082 - learning_rate: 5.0000e-05\n",
      "Epoch 1498/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 - val_loss: 0.0126 - learning_rate: 5.0000e-05\n",
      "Epoch 1499/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0103 - val_loss: 0.0089 - learning_rate: 5.0000e-05\n",
      "Epoch 1500/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0088 - learning_rate: 5.0000e-05\n",
      "Epoch 1501/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0085 - learning_rate: 5.0000e-05\n",
      "Epoch 1502/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0103 - learning_rate: 5.0000e-05\n",
      "Epoch 1503/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0086 - val_loss: 0.0089 - learning_rate: 5.0000e-05\n",
      "Epoch 1504/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0083 - val_loss: 0.0109 - learning_rate: 5.0000e-05\n",
      "Epoch 1505/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0097 - val_loss: 0.0103 - learning_rate: 5.0000e-05\n",
      "Epoch 1506/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0094 - val_loss: 0.0087 - learning_rate: 5.0000e-05\n",
      "Epoch 1507/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0090 - val_loss: 0.0103 - learning_rate: 5.0000e-05\n",
      "Epoch 1508/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0095 - val_loss: 0.0115 - learning_rate: 5.0000e-05\n",
      "Epoch 1509/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0092 - val_loss: 0.0104 - learning_rate: 5.0000e-05\n",
      "Epoch 1510/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0090 - val_loss: 0.0110 - learning_rate: 5.0000e-05\n",
      "Epoch 1511/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0100 - val_loss: 0.0099 - learning_rate: 5.0000e-05\n",
      "Epoch 1512/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 - val_loss: 0.0090 - learning_rate: 5.0000e-05\n",
      "Epoch 1513/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0084 - val_loss: 0.0086 - learning_rate: 5.0000e-05\n",
      "Epoch 1514/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0085 - val_loss: 0.0118 - learning_rate: 5.0000e-05\n",
      "Epoch 1515/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0092 - val_loss: 0.0095 - learning_rate: 5.0000e-05\n",
      "Epoch 1516/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0093 - val_loss: 0.0107 - learning_rate: 5.0000e-05\n",
      "Epoch 1517/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0113 - val_loss: 0.0170 - learning_rate: 5.0000e-05\n",
      "Epoch 1518/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0106 - val_loss: 0.0106 - learning_rate: 5.0000e-05\n",
      "Epoch 1519/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0095 - val_loss: 0.0102 - learning_rate: 5.0000e-05\n",
      "Epoch 1520/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0087 - val_loss: 0.0097 - learning_rate: 5.0000e-05\n",
      "Epoch 1521/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0091 - val_loss: 0.0145 - learning_rate: 5.0000e-05\n",
      "Epoch 1522/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0102 - val_loss: 0.0110 - learning_rate: 5.0000e-05\n",
      "Epoch 1523/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0094 - val_loss: 0.0096 - learning_rate: 5.0000e-05\n",
      "Epoch 1524/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0085 - val_loss: 0.0088 - learning_rate: 5.0000e-05\n",
      "Epoch 1525/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0086 - val_loss: 0.0126 - learning_rate: 5.0000e-05\n",
      "Epoch 1526/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0095 - val_loss: 0.0106 - learning_rate: 5.0000e-05\n",
      "Epoch 1527/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0094 - val_loss: 0.0089 - learning_rate: 5.0000e-05\n",
      "Epoch 1528/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0074 - val_loss: 0.0086 - learning_rate: 5.0000e-05\n",
      "Epoch 1529/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0117 - learning_rate: 5.0000e-05\n",
      "Epoch 1530/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0102 - val_loss: 0.0154 - learning_rate: 5.0000e-05\n",
      "Epoch 1531/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0097 - val_loss: 0.0094 - learning_rate: 5.0000e-05\n",
      "Epoch 1532/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0091 - val_loss: 0.0089 - learning_rate: 5.0000e-05\n",
      "Epoch 1533/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0088 - val_loss: 0.0099 - learning_rate: 5.0000e-05\n",
      "Epoch 1534/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0093 - val_loss: 0.0087 - learning_rate: 5.0000e-05\n",
      "Epoch 1535/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0155 - learning_rate: 5.0000e-05\n",
      "Epoch 1536/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0106 - val_loss: 0.0094 - learning_rate: 5.0000e-05\n",
      "Epoch 1537/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 - val_loss: 0.0084 - learning_rate: 5.0000e-05\n",
      "Epoch 1538/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0089 - val_loss: 0.0110 - learning_rate: 5.0000e-05\n",
      "Epoch 1539/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0098 - val_loss: 0.0119 - learning_rate: 5.0000e-05\n",
      "Epoch 1540/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0097 - val_loss: 0.0086 - learning_rate: 5.0000e-05\n",
      "Epoch 1541/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0086 - val_loss: 0.0092 - learning_rate: 5.0000e-05\n",
      "Epoch 1542/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0090 - val_loss: 0.0087 - learning_rate: 5.0000e-05\n",
      "Epoch 1543/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0082 - val_loss: 0.0096 - learning_rate: 5.0000e-05\n",
      "Epoch 1544/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0098 - val_loss: 0.0112 - learning_rate: 5.0000e-05\n",
      "Epoch 1545/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0090 - val_loss: 0.0114 - learning_rate: 5.0000e-05\n",
      "Epoch 1546/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0087 - val_loss: 0.0096 - learning_rate: 5.0000e-05\n",
      "Epoch 1547/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0090 - learning_rate: 5.0000e-05\n",
      "Epoch 1548/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0085 - learning_rate: 5.0000e-05\n",
      "Epoch 1549/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0117 - learning_rate: 5.0000e-05\n",
      "Epoch 1550/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0091 - val_loss: 0.0093 - learning_rate: 5.0000e-05\n",
      "Epoch 1551/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0094 - val_loss: 0.0085 - learning_rate: 5.0000e-05\n",
      "Epoch 1552/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0129 - learning_rate: 5.0000e-05\n",
      "Epoch 1553/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0104 - val_loss: 0.0113 - learning_rate: 5.0000e-05\n",
      "Epoch 1554/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0098 - val_loss: 0.0094 - learning_rate: 5.0000e-05\n",
      "Epoch 1555/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0092 - val_loss: 0.0112 - learning_rate: 5.0000e-05\n",
      "Epoch 1556/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0082 - val_loss: 0.0092 - learning_rate: 5.0000e-05\n",
      "Epoch 1557/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0088 - val_loss: 0.0093 - learning_rate: 5.0000e-05\n",
      "Epoch 1558/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0094 - val_loss: 0.0090 - learning_rate: 5.0000e-05\n",
      "Epoch 1559/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0086 - val_loss: 0.0134 - learning_rate: 5.0000e-05\n",
      "Epoch 1560/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0091 - val_loss: 0.0097 - learning_rate: 5.0000e-05\n",
      "Epoch 1561/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0090 - val_loss: 0.0097 - learning_rate: 5.0000e-05\n",
      "Epoch 1562/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0094 - val_loss: 0.0086 - learning_rate: 5.0000e-05\n",
      "Epoch 1563/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0082 - learning_rate: 5.0000e-05\n",
      "Epoch 1564/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0079 - val_loss: 0.0108 - learning_rate: 5.0000e-05\n",
      "Epoch 1565/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0113 - val_loss: 0.0121 - learning_rate: 5.0000e-05\n",
      "Epoch 1566/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0092 - val_loss: 0.0098 - learning_rate: 5.0000e-05\n",
      "Epoch 1567/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0086 - val_loss: 0.0092 - learning_rate: 5.0000e-05\n",
      "Epoch 1568/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0097 - learning_rate: 5.0000e-05\n",
      "Epoch 1569/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0082 - val_loss: 0.0114 - learning_rate: 5.0000e-05\n",
      "Epoch 1570/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0085 - val_loss: 0.0093 - learning_rate: 5.0000e-05\n",
      "Epoch 1571/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0100 - val_loss: 0.0109 - learning_rate: 5.0000e-05\n",
      "Epoch 1572/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0086 - val_loss: 0.0085 - learning_rate: 5.0000e-05\n",
      "Epoch 1573/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0089 - val_loss: 0.0089 - learning_rate: 5.0000e-05\n",
      "Epoch 1574/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0098 - learning_rate: 5.0000e-05\n",
      "Epoch 1575/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0090 - val_loss: 0.0093 - learning_rate: 5.0000e-05\n",
      "Epoch 1576/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0082 - val_loss: 0.0084 - learning_rate: 5.0000e-05\n",
      "Epoch 1577/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0089 - val_loss: 0.0101 - learning_rate: 5.0000e-05\n",
      "Epoch 1578/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0102 - val_loss: 0.0094 - learning_rate: 5.0000e-05\n",
      "Epoch 1579/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0092 - val_loss: 0.0110 - learning_rate: 5.0000e-05\n",
      "Epoch 1580/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0103 - val_loss: 0.0109 - learning_rate: 5.0000e-05\n",
      "Epoch 1581/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0091 - val_loss: 0.0100 - learning_rate: 5.0000e-05\n",
      "Epoch 1582/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0079 - val_loss: 0.0084 - learning_rate: 5.0000e-05\n",
      "Epoch 1583/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0110 - learning_rate: 5.0000e-05\n",
      "Epoch 1584/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0086 - val_loss: 0.0101 - learning_rate: 5.0000e-05\n",
      "Epoch 1585/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0078 - val_loss: 0.0099 - learning_rate: 5.0000e-05\n",
      "Epoch 1586/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0092 - val_loss: 0.0101 - learning_rate: 5.0000e-05\n",
      "Epoch 1587/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0110 - val_loss: 0.0118 - learning_rate: 5.0000e-05\n",
      "Epoch 1588/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0085 - val_loss: 0.0090 - learning_rate: 5.0000e-05\n",
      "Epoch 1589/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0084 - val_loss: 0.0084 - learning_rate: 5.0000e-05\n",
      "Epoch 1590/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0091 - learning_rate: 5.0000e-05\n",
      "Epoch 1591/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0079 - val_loss: 0.0091 - learning_rate: 5.0000e-05\n",
      "Epoch 1592/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0086 - val_loss: 0.0092 - learning_rate: 5.0000e-05\n",
      "Epoch 1593/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0081 - learning_rate: 5.0000e-05\n",
      "Epoch 1594/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0082 - val_loss: 0.0106 - learning_rate: 5.0000e-05\n",
      "Epoch 1595/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0097 - val_loss: 0.0116 - learning_rate: 5.0000e-05\n",
      "Epoch 1596/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0095 - val_loss: 0.0104 - learning_rate: 5.0000e-05\n",
      "Epoch 1597/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0093 - val_loss: 0.0120 - learning_rate: 5.0000e-05\n",
      "Epoch 1598/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0100 - val_loss: 0.0090 - learning_rate: 5.0000e-05\n",
      "Epoch 1599/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0097 - val_loss: 0.0097 - learning_rate: 5.0000e-05\n",
      "Epoch 1600/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0096 - val_loss: 0.0143 - learning_rate: 5.0000e-05\n",
      "Epoch 1601/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0093 - val_loss: 0.0101 - learning_rate: 5.0000e-05\n",
      "Epoch 1602/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0085 - val_loss: 0.0090 - learning_rate: 5.0000e-05\n",
      "Epoch 1603/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0102 - learning_rate: 5.0000e-05\n",
      "Epoch 1604/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0088 - val_loss: 0.0094 - learning_rate: 5.0000e-05\n",
      "Epoch 1605/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0086 - val_loss: 0.0097 - learning_rate: 5.0000e-05\n",
      "Epoch 1606/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 - val_loss: 0.0126 - learning_rate: 5.0000e-05\n",
      "Epoch 1607/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0085 - val_loss: 0.0092 - learning_rate: 5.0000e-05\n",
      "Epoch 1608/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0094 - val_loss: 0.0152 - learning_rate: 5.0000e-05\n",
      "Epoch 1609/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0128 - val_loss: 0.0128 - learning_rate: 5.0000e-05\n",
      "Epoch 1610/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0108 - val_loss: 0.0112 - learning_rate: 5.0000e-05\n",
      "Epoch 1611/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0099 - val_loss: 0.0098 - learning_rate: 5.0000e-05\n",
      "Epoch 1612/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0089 - val_loss: 0.0087 - learning_rate: 5.0000e-05\n",
      "Epoch 1613/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0090 - val_loss: 0.0153 - learning_rate: 5.0000e-05\n",
      "Epoch 1614/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0099 - val_loss: 0.0094 - learning_rate: 5.0000e-05\n",
      "Epoch 1615/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 - val_loss: 0.0090 - learning_rate: 5.0000e-05\n",
      "Epoch 1616/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0089 - val_loss: 0.0106 - learning_rate: 5.0000e-05\n",
      "Epoch 1617/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0085 - val_loss: 0.0086 - learning_rate: 2.5000e-05\n",
      "Epoch 1618/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0084 - learning_rate: 2.5000e-05\n",
      "Epoch 1619/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0079 - learning_rate: 2.5000e-05\n",
      "Epoch 1620/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0080 - learning_rate: 2.5000e-05\n",
      "Epoch 1621/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0071 - val_loss: 0.0087 - learning_rate: 2.5000e-05\n",
      "Epoch 1622/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0072 - val_loss: 0.0081 - learning_rate: 2.5000e-05\n",
      "Epoch 1623/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0081 - learning_rate: 2.5000e-05\n",
      "Epoch 1624/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0076 - val_loss: 0.0085 - learning_rate: 2.5000e-05\n",
      "Epoch 1625/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0076 - val_loss: 0.0083 - learning_rate: 2.5000e-05\n",
      "Epoch 1626/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0085 - learning_rate: 2.5000e-05\n",
      "Epoch 1627/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0082 - learning_rate: 2.5000e-05\n",
      "Epoch 1628/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0075 - val_loss: 0.0081 - learning_rate: 2.5000e-05\n",
      "Epoch 1629/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0082 - learning_rate: 2.5000e-05\n",
      "Epoch 1630/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0075 - val_loss: 0.0100 - learning_rate: 2.5000e-05\n",
      "Epoch 1631/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0086 - val_loss: 0.0095 - learning_rate: 2.5000e-05\n",
      "Epoch 1632/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0086 - learning_rate: 2.5000e-05\n",
      "Epoch 1633/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0071 - val_loss: 0.0093 - learning_rate: 2.5000e-05\n",
      "Epoch 1634/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0073 - val_loss: 0.0092 - learning_rate: 2.5000e-05\n",
      "Epoch 1635/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0095 - learning_rate: 2.5000e-05\n",
      "Epoch 1636/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0089 - val_loss: 0.0084 - learning_rate: 2.5000e-05\n",
      "Epoch 1637/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0075 - val_loss: 0.0083 - learning_rate: 2.5000e-05\n",
      "Epoch 1638/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0085 - learning_rate: 2.5000e-05\n",
      "Epoch 1639/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0082 - val_loss: 0.0082 - learning_rate: 2.5000e-05\n",
      "Epoch 1640/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0079 - val_loss: 0.0089 - learning_rate: 2.5000e-05\n",
      "Epoch 1641/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0086 - learning_rate: 2.5000e-05\n",
      "Epoch 1642/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0093 - learning_rate: 2.5000e-05\n",
      "Epoch 1643/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0073 - val_loss: 0.0080 - learning_rate: 2.5000e-05\n",
      "Epoch 1644/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0089 - learning_rate: 2.5000e-05\n",
      "Epoch 1645/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0081 - val_loss: 0.0084 - learning_rate: 2.5000e-05\n",
      "Epoch 1646/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0088 - learning_rate: 2.5000e-05\n",
      "Epoch 1647/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0071 - val_loss: 0.0097 - learning_rate: 2.5000e-05\n",
      "Epoch 1648/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0081 - learning_rate: 2.5000e-05\n",
      "Epoch 1649/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0081 - learning_rate: 2.5000e-05\n",
      "Epoch 1650/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0087 - learning_rate: 2.5000e-05\n",
      "Epoch 1651/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0086 - learning_rate: 2.5000e-05\n",
      "Epoch 1652/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0082 - val_loss: 0.0094 - learning_rate: 2.5000e-05\n",
      "Epoch 1653/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0085 - learning_rate: 2.5000e-05\n",
      "Epoch 1654/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0077 - val_loss: 0.0096 - learning_rate: 2.5000e-05\n",
      "Epoch 1655/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0084 - val_loss: 0.0097 - learning_rate: 2.5000e-05\n",
      "Epoch 1656/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0084 - val_loss: 0.0091 - learning_rate: 2.5000e-05\n",
      "Epoch 1657/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0091 - learning_rate: 2.5000e-05\n",
      "Epoch 1658/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0075 - val_loss: 0.0083 - learning_rate: 2.5000e-05\n",
      "Epoch 1659/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0089 - learning_rate: 2.5000e-05\n",
      "Epoch 1660/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0076 - val_loss: 0.0086 - learning_rate: 2.5000e-05\n",
      "Epoch 1661/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0088 - learning_rate: 2.5000e-05\n",
      "Epoch 1662/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0089 - learning_rate: 2.5000e-05\n",
      "Epoch 1663/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0083 - val_loss: 0.0088 - learning_rate: 2.5000e-05\n",
      "Epoch 1664/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0091 - val_loss: 0.0084 - learning_rate: 2.5000e-05\n",
      "Epoch 1665/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0075 - val_loss: 0.0079 - learning_rate: 2.5000e-05\n",
      "Epoch 1666/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0080 - learning_rate: 2.5000e-05\n",
      "Epoch 1667/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0101 - learning_rate: 2.5000e-05\n",
      "Epoch 1668/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0094 - learning_rate: 2.5000e-05\n",
      "Epoch 1669/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0086 - val_loss: 0.0088 - learning_rate: 2.5000e-05\n",
      "Epoch 1670/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0082 - learning_rate: 2.5000e-05\n",
      "Epoch 1671/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0103 - learning_rate: 2.5000e-05\n",
      "Epoch 1672/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0083 - learning_rate: 2.5000e-05\n",
      "Epoch 1673/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0091 - learning_rate: 2.5000e-05\n",
      "Epoch 1674/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0082 - val_loss: 0.0087 - learning_rate: 2.5000e-05\n",
      "Epoch 1675/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0091 - learning_rate: 2.5000e-05\n",
      "Epoch 1676/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0072 - val_loss: 0.0093 - learning_rate: 2.5000e-05\n",
      "Epoch 1677/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0086 - learning_rate: 2.5000e-05\n",
      "Epoch 1678/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0091 - learning_rate: 2.5000e-05\n",
      "Epoch 1679/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0082 - val_loss: 0.0083 - learning_rate: 2.5000e-05\n",
      "Epoch 1680/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0084 - learning_rate: 2.5000e-05\n",
      "Epoch 1681/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0082 - val_loss: 0.0090 - learning_rate: 2.5000e-05\n",
      "Epoch 1682/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0078 - val_loss: 0.0095 - learning_rate: 2.5000e-05\n",
      "Epoch 1683/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0084 - val_loss: 0.0086 - learning_rate: 2.5000e-05\n",
      "Epoch 1684/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0077 - val_loss: 0.0086 - learning_rate: 2.5000e-05\n",
      "Epoch 1685/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0083 - val_loss: 0.0086 - learning_rate: 2.5000e-05\n",
      "Epoch 1686/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0079 - val_loss: 0.0092 - learning_rate: 2.5000e-05\n",
      "Epoch 1687/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0084 - val_loss: 0.0108 - learning_rate: 2.5000e-05\n",
      "Epoch 1688/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0083 - learning_rate: 2.5000e-05\n",
      "Epoch 1689/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0084 - learning_rate: 2.5000e-05\n",
      "Epoch 1690/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0072 - val_loss: 0.0094 - learning_rate: 2.5000e-05\n",
      "Epoch 1691/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0088 - val_loss: 0.0086 - learning_rate: 2.5000e-05\n",
      "Epoch 1692/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0082 - learning_rate: 2.5000e-05\n",
      "Epoch 1693/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 - val_loss: 0.0082 - learning_rate: 2.5000e-05\n",
      "Epoch 1694/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0086 - learning_rate: 2.5000e-05\n",
      "Epoch 1695/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0084 - learning_rate: 2.5000e-05\n",
      "Epoch 1696/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0084 - learning_rate: 2.5000e-05\n",
      "Epoch 1697/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0070 - val_loss: 0.0086 - learning_rate: 2.5000e-05\n",
      "Epoch 1698/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0082 - val_loss: 0.0088 - learning_rate: 2.5000e-05\n",
      "Epoch 1699/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0085 - val_loss: 0.0086 - learning_rate: 2.5000e-05\n",
      "Epoch 1700/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0078 - val_loss: 0.0088 - learning_rate: 2.5000e-05\n",
      "Epoch 1701/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0084 - learning_rate: 2.5000e-05\n",
      "Epoch 1702/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0086 - val_loss: 0.0098 - learning_rate: 2.5000e-05\n",
      "Epoch 1703/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0099 - learning_rate: 2.5000e-05\n",
      "Epoch 1704/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0083 - val_loss: 0.0088 - learning_rate: 2.5000e-05\n",
      "Epoch 1705/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0083 - val_loss: 0.0105 - learning_rate: 2.5000e-05\n",
      "Epoch 1706/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0090 - val_loss: 0.0097 - learning_rate: 2.5000e-05\n",
      "Epoch 1707/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0142 - learning_rate: 2.5000e-05\n",
      "Epoch 1708/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0098 - val_loss: 0.0090 - learning_rate: 2.5000e-05\n",
      "Epoch 1709/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0082 - val_loss: 0.0099 - learning_rate: 2.5000e-05\n",
      "Epoch 1710/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0074 - val_loss: 0.0100 - learning_rate: 2.5000e-05\n",
      "Epoch 1711/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0083 - val_loss: 0.0094 - learning_rate: 2.5000e-05\n",
      "Epoch 1712/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0087 - val_loss: 0.0107 - learning_rate: 2.5000e-05\n",
      "Epoch 1713/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0086 - val_loss: 0.0089 - learning_rate: 2.5000e-05\n",
      "Epoch 1714/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0089 - learning_rate: 2.5000e-05\n",
      "Epoch 1715/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0090 - learning_rate: 2.5000e-05\n",
      "Epoch 1716/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0078 - val_loss: 0.0084 - learning_rate: 2.5000e-05\n",
      "Epoch 1717/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0078 - val_loss: 0.0080 - learning_rate: 2.5000e-05\n",
      "Epoch 1718/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0084 - val_loss: 0.0095 - learning_rate: 2.5000e-05\n",
      "Epoch 1719/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0084 - val_loss: 0.0083 - learning_rate: 2.5000e-05\n",
      "Epoch 1720/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0074 - val_loss: 0.0092 - learning_rate: 2.5000e-05\n",
      "Epoch 1721/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0076 - val_loss: 0.0090 - learning_rate: 2.5000e-05\n",
      "Epoch 1722/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0084 - learning_rate: 2.5000e-05\n",
      "Epoch 1723/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0080 - learning_rate: 2.5000e-05\n",
      "Epoch 1724/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0071 - val_loss: 0.0088 - learning_rate: 2.5000e-05\n",
      "Epoch 1725/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0087 - learning_rate: 2.5000e-05\n",
      "Epoch 1726/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0096 - learning_rate: 2.5000e-05\n",
      "Epoch 1727/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0081 - val_loss: 0.0083 - learning_rate: 2.5000e-05\n",
      "Epoch 1728/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0076 - val_loss: 0.0098 - learning_rate: 2.5000e-05\n",
      "Epoch 1729/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0076 - val_loss: 0.0088 - learning_rate: 2.5000e-05\n",
      "Epoch 1730/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0075 - val_loss: 0.0090 - learning_rate: 2.5000e-05\n",
      "Epoch 1731/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0075 - val_loss: 0.0083 - learning_rate: 2.5000e-05\n",
      "Epoch 1732/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0073 - val_loss: 0.0095 - learning_rate: 2.5000e-05\n",
      "Epoch 1733/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0085 - val_loss: 0.0082 - learning_rate: 2.5000e-05\n",
      "Epoch 1734/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0086 - val_loss: 0.0090 - learning_rate: 2.5000e-05\n",
      "Epoch 1735/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0079 - val_loss: 0.0081 - learning_rate: 2.5000e-05\n",
      "Epoch 1736/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0084 - learning_rate: 2.5000e-05\n",
      "Epoch 1737/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0084 - learning_rate: 2.5000e-05\n",
      "Epoch 1738/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0075 - val_loss: 0.0087 - learning_rate: 2.5000e-05\n",
      "Epoch 1739/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0086 - learning_rate: 2.5000e-05\n",
      "Epoch 1740/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0098 - learning_rate: 2.5000e-05\n",
      "Epoch 1741/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0082 - learning_rate: 2.5000e-05\n",
      "Epoch 1742/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0084 - learning_rate: 2.5000e-05\n",
      "Epoch 1743/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0077 - val_loss: 0.0085 - learning_rate: 2.5000e-05\n",
      "Epoch 1744/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0086 - learning_rate: 2.5000e-05\n",
      "Epoch 1745/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0087 - learning_rate: 2.5000e-05\n",
      "Epoch 1746/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0083 - learning_rate: 2.5000e-05\n",
      "Epoch 1747/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0088 - val_loss: 0.0086 - learning_rate: 2.5000e-05\n",
      "Epoch 1748/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0082 - learning_rate: 2.5000e-05\n",
      "Epoch 1749/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0084 - learning_rate: 2.5000e-05\n",
      "Epoch 1750/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0104 - learning_rate: 2.5000e-05\n",
      "Epoch 1751/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0083 - val_loss: 0.0092 - learning_rate: 2.5000e-05\n",
      "Epoch 1752/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0079 - val_loss: 0.0091 - learning_rate: 2.5000e-05\n",
      "Epoch 1753/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0106 - learning_rate: 2.5000e-05\n",
      "Epoch 1754/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0085 - learning_rate: 2.5000e-05\n",
      "Epoch 1755/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0084 - val_loss: 0.0093 - learning_rate: 2.5000e-05\n",
      "Epoch 1756/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0076 - val_loss: 0.0102 - learning_rate: 2.5000e-05\n",
      "Epoch 1757/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0089 - val_loss: 0.0085 - learning_rate: 2.5000e-05\n",
      "Epoch 1758/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0071 - val_loss: 0.0080 - learning_rate: 2.5000e-05\n",
      "Epoch 1759/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0073 - val_loss: 0.0097 - learning_rate: 2.5000e-05\n",
      "Epoch 1760/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0079 - val_loss: 0.0085 - learning_rate: 2.5000e-05\n",
      "Epoch 1761/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0073 - val_loss: 0.0085 - learning_rate: 2.5000e-05\n",
      "Epoch 1762/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0097 - learning_rate: 2.5000e-05\n",
      "Epoch 1763/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0098 - val_loss: 0.0094 - learning_rate: 2.5000e-05\n",
      "Epoch 1764/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0085 - val_loss: 0.0089 - learning_rate: 2.5000e-05\n",
      "Epoch 1765/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0085 - learning_rate: 2.5000e-05\n",
      "Epoch 1766/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0083 - learning_rate: 2.5000e-05\n",
      "Epoch 1767/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0084 - learning_rate: 2.5000e-05\n",
      "Epoch 1768/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0087 - learning_rate: 2.5000e-05\n",
      "Epoch 1769/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0081 - learning_rate: 2.5000e-05\n",
      "Epoch 1770/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0084 - learning_rate: 2.5000e-05\n",
      "Epoch 1771/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0081 - learning_rate: 2.5000e-05\n",
      "Epoch 1772/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0083 - learning_rate: 2.5000e-05\n",
      "Epoch 1773/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0097 - learning_rate: 2.5000e-05\n",
      "Epoch 1774/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0091 - val_loss: 0.0085 - learning_rate: 2.5000e-05\n",
      "Epoch 1775/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0079 - val_loss: 0.0105 - learning_rate: 2.5000e-05\n",
      "Epoch 1776/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0084 - val_loss: 0.0152 - learning_rate: 2.5000e-05\n",
      "Epoch 1777/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0099 - val_loss: 0.0088 - learning_rate: 2.5000e-05\n",
      "Epoch 1778/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0092 - learning_rate: 2.5000e-05\n",
      "Epoch 1779/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0149 - learning_rate: 2.5000e-05\n",
      "Epoch 1780/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0096 - val_loss: 0.0096 - learning_rate: 2.5000e-05\n",
      "Epoch 1781/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0086 - val_loss: 0.0081 - learning_rate: 2.5000e-05\n",
      "Epoch 1782/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0073 - val_loss: 0.0085 - learning_rate: 2.5000e-05\n",
      "Epoch 1783/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0084 - learning_rate: 2.5000e-05\n",
      "Epoch 1784/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0091 - learning_rate: 2.5000e-05\n",
      "Epoch 1785/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0087 - learning_rate: 2.5000e-05\n",
      "Epoch 1786/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0085 - val_loss: 0.0087 - learning_rate: 2.5000e-05\n",
      "Epoch 1787/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0097 - learning_rate: 2.5000e-05\n",
      "Epoch 1788/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0091 - learning_rate: 2.5000e-05\n",
      "Epoch 1789/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0084 - val_loss: 0.0097 - learning_rate: 2.5000e-05\n",
      "Epoch 1790/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0088 - val_loss: 0.0118 - learning_rate: 2.5000e-05\n",
      "Epoch 1791/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0098 - val_loss: 0.0088 - learning_rate: 2.5000e-05\n",
      "Epoch 1792/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0089 - learning_rate: 2.5000e-05\n",
      "Epoch 1793/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0086 - val_loss: 0.0085 - learning_rate: 2.5000e-05\n",
      "Epoch 1794/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0085 - learning_rate: 2.5000e-05\n",
      "Epoch 1795/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0086 - val_loss: 0.0083 - learning_rate: 2.5000e-05\n",
      "Epoch 1796/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0078 - val_loss: 0.0083 - learning_rate: 2.5000e-05\n",
      "Epoch 1797/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0089 - learning_rate: 2.5000e-05\n",
      "Epoch 1798/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0072 - val_loss: 0.0084 - learning_rate: 2.5000e-05\n",
      "Epoch 1799/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0084 - learning_rate: 2.5000e-05\n",
      "Epoch 1800/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0081 - learning_rate: 2.5000e-05\n",
      "Epoch 1801/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0073 - val_loss: 0.0084 - learning_rate: 2.5000e-05\n",
      "Epoch 1802/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0098 - learning_rate: 2.5000e-05\n",
      "Epoch 1803/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0082 - learning_rate: 2.5000e-05\n",
      "Epoch 1804/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0083 - learning_rate: 2.5000e-05\n",
      "Epoch 1805/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0085 - learning_rate: 2.5000e-05\n",
      "Epoch 1806/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0085 - val_loss: 0.0087 - learning_rate: 2.5000e-05\n",
      "Epoch 1807/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0093 - learning_rate: 2.5000e-05\n",
      "Epoch 1808/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0085 - learning_rate: 2.5000e-05\n",
      "Epoch 1809/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0074 - val_loss: 0.0084 - learning_rate: 2.5000e-05\n",
      "Epoch 1810/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0086 - learning_rate: 2.5000e-05\n",
      "Epoch 1811/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0080 - val_loss: 0.0098 - learning_rate: 2.5000e-05\n",
      "Epoch 1812/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0090 - learning_rate: 2.5000e-05\n",
      "Epoch 1813/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0096 - learning_rate: 2.5000e-05\n",
      "Epoch 1814/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0084 - val_loss: 0.0087 - learning_rate: 2.5000e-05\n",
      "Epoch 1815/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0088 - val_loss: 0.0122 - learning_rate: 2.5000e-05\n",
      "Epoch 1816/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0084 - val_loss: 0.0090 - learning_rate: 2.5000e-05\n",
      "Epoch 1817/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0083 - val_loss: 0.0082 - learning_rate: 2.5000e-05\n",
      "Epoch 1818/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0082 - learning_rate: 2.5000e-05\n",
      "Epoch 1819/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0083 - learning_rate: 2.5000e-05\n",
      "Epoch 1820/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0081 - learning_rate: 2.5000e-05\n",
      "Epoch 1821/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0081 - val_loss: 0.0100 - learning_rate: 2.5000e-05\n",
      "Epoch 1822/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0086 - val_loss: 0.0094 - learning_rate: 2.5000e-05\n",
      "Epoch 1823/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0078 - val_loss: 0.0086 - learning_rate: 2.5000e-05\n",
      "Epoch 1824/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0083 - val_loss: 0.0082 - learning_rate: 2.5000e-05\n",
      "Epoch 1825/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0086 - learning_rate: 2.5000e-05\n",
      "Epoch 1826/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0082 - val_loss: 0.0087 - learning_rate: 2.5000e-05\n",
      "Epoch 1827/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0084 - learning_rate: 2.5000e-05\n",
      "Epoch 1828/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0074 - val_loss: 0.0084 - learning_rate: 2.5000e-05\n",
      "Epoch 1829/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0090 - learning_rate: 2.5000e-05\n",
      "Epoch 1830/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0086 - val_loss: 0.0090 - learning_rate: 2.5000e-05\n",
      "Epoch 1831/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0100 - learning_rate: 2.5000e-05\n",
      "Epoch 1832/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0105 - learning_rate: 2.5000e-05\n",
      "Epoch 1833/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0089 - val_loss: 0.0092 - learning_rate: 2.5000e-05\n",
      "Epoch 1834/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0078 - val_loss: 0.0082 - learning_rate: 2.5000e-05\n",
      "Epoch 1835/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0083 - val_loss: 0.0098 - learning_rate: 2.5000e-05\n",
      "Epoch 1836/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0087 - learning_rate: 2.5000e-05\n",
      "Epoch 1837/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0082 - val_loss: 0.0132 - learning_rate: 2.5000e-05\n",
      "Epoch 1838/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0117 - val_loss: 0.0098 - learning_rate: 2.5000e-05\n",
      "Epoch 1839/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0091 - val_loss: 0.0098 - learning_rate: 2.5000e-05\n",
      "Epoch 1840/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0087 - learning_rate: 2.5000e-05\n",
      "Epoch 1841/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0081 - learning_rate: 2.5000e-05\n",
      "Epoch 1842/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0082 - learning_rate: 2.5000e-05\n",
      "Epoch 1843/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0088 - learning_rate: 2.5000e-05\n",
      "Epoch 1844/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0093 - learning_rate: 2.5000e-05\n",
      "Epoch 1845/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0087 - learning_rate: 2.5000e-05\n",
      "Epoch 1846/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0084 - learning_rate: 2.5000e-05\n",
      "Epoch 1847/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0083 - learning_rate: 2.5000e-05\n",
      "Epoch 1848/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0091 - learning_rate: 2.5000e-05\n",
      "Epoch 1849/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0085 - learning_rate: 2.5000e-05\n",
      "Epoch 1850/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0095 - learning_rate: 2.5000e-05\n",
      "Epoch 1851/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0098 - learning_rate: 2.5000e-05\n",
      "Epoch 1852/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0091 - learning_rate: 2.5000e-05\n",
      "Epoch 1853/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0088 - val_loss: 0.0082 - learning_rate: 2.5000e-05\n",
      "Epoch 1854/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0082 - val_loss: 0.0088 - learning_rate: 2.5000e-05\n",
      "Epoch 1855/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0085 - val_loss: 0.0083 - learning_rate: 2.5000e-05\n",
      "Epoch 1856/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0092 - learning_rate: 2.5000e-05\n",
      "Epoch 1857/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0078 - val_loss: 0.0095 - learning_rate: 2.5000e-05\n",
      "Epoch 1858/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0086 - val_loss: 0.0109 - learning_rate: 2.5000e-05\n",
      "Epoch 1859/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0082 - val_loss: 0.0092 - learning_rate: 2.5000e-05\n",
      "Epoch 1860/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0082 - learning_rate: 2.5000e-05\n",
      "Epoch 1861/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0081 - learning_rate: 2.5000e-05\n",
      "Epoch 1862/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0100 - learning_rate: 2.5000e-05\n",
      "Epoch 1863/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0081 - learning_rate: 2.5000e-05\n",
      "Epoch 1864/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0084 - learning_rate: 2.5000e-05\n",
      "Epoch 1865/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0098 - learning_rate: 2.5000e-05\n",
      "Epoch 1866/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0100 - learning_rate: 2.5000e-05\n",
      "Epoch 1867/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0084 - val_loss: 0.0095 - learning_rate: 2.5000e-05\n",
      "Epoch 1868/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0088 - val_loss: 0.0106 - learning_rate: 2.5000e-05\n",
      "Epoch 1869/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0089 - val_loss: 0.0083 - learning_rate: 2.5000e-05\n",
      "Epoch 1870/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0081 - learning_rate: 2.5000e-05\n",
      "Epoch 1871/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0082 - learning_rate: 2.5000e-05\n",
      "Epoch 1872/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0088 - learning_rate: 2.5000e-05\n",
      "Epoch 1873/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0089 - learning_rate: 2.5000e-05\n",
      "Epoch 1874/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0086 - val_loss: 0.0109 - learning_rate: 2.5000e-05\n",
      "Epoch 1875/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0087 - val_loss: 0.0082 - learning_rate: 2.5000e-05\n",
      "Epoch 1876/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0080 - learning_rate: 2.5000e-05\n",
      "Epoch 1877/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0101 - learning_rate: 2.5000e-05\n",
      "Epoch 1878/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0087 - learning_rate: 2.5000e-05\n",
      "Epoch 1879/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0080 - learning_rate: 2.5000e-05\n",
      "Epoch 1880/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0085 - learning_rate: 2.5000e-05\n",
      "Epoch 1881/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0089 - learning_rate: 2.5000e-05\n",
      "Epoch 1882/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0086 - learning_rate: 2.5000e-05\n",
      "Epoch 1883/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0083 - val_loss: 0.0086 - learning_rate: 2.5000e-05\n",
      "Epoch 1884/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0086 - learning_rate: 2.5000e-05\n",
      "Epoch 1885/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0109 - learning_rate: 2.5000e-05\n",
      "Epoch 1886/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0097 - val_loss: 0.0094 - learning_rate: 2.5000e-05\n",
      "Epoch 1887/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0096 - learning_rate: 2.5000e-05\n",
      "Epoch 1888/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0088 - learning_rate: 2.5000e-05\n",
      "Epoch 1889/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0088 - learning_rate: 2.5000e-05\n",
      "Epoch 1890/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0084 - learning_rate: 2.5000e-05\n",
      "Epoch 1891/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0085 - val_loss: 0.0091 - learning_rate: 2.5000e-05\n",
      "Epoch 1892/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0086 - val_loss: 0.0082 - learning_rate: 2.5000e-05\n",
      "Epoch 1893/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0094 - learning_rate: 2.5000e-05\n",
      "Epoch 1894/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0085 - learning_rate: 2.5000e-05\n",
      "Epoch 1895/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0129 - learning_rate: 2.5000e-05\n",
      "Epoch 1896/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0090 - val_loss: 0.0081 - learning_rate: 2.5000e-05\n",
      "Epoch 1897/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0087 - learning_rate: 2.5000e-05\n",
      "Epoch 1898/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0080 - val_loss: 0.0090 - learning_rate: 2.5000e-05\n",
      "Epoch 1899/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0081 - val_loss: 0.0088 - learning_rate: 2.5000e-05\n",
      "Epoch 1900/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0089 - learning_rate: 2.5000e-05\n",
      "Epoch 1901/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0087 - learning_rate: 2.5000e-05\n",
      "Epoch 1902/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0088 - learning_rate: 2.5000e-05\n",
      "Epoch 1903/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0086 - val_loss: 0.0096 - learning_rate: 2.5000e-05\n",
      "Epoch 1904/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0104 - learning_rate: 2.5000e-05\n",
      "Epoch 1905/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0091 - learning_rate: 2.5000e-05\n",
      "Epoch 1906/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0084 - val_loss: 0.0084 - learning_rate: 2.5000e-05\n",
      "Epoch 1907/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0095 - learning_rate: 2.5000e-05\n",
      "Epoch 1908/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0084 - val_loss: 0.0088 - learning_rate: 2.5000e-05\n",
      "Epoch 1909/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0089 - val_loss: 0.0093 - learning_rate: 2.5000e-05\n",
      "Epoch 1910/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0082 - val_loss: 0.0089 - learning_rate: 2.5000e-05\n",
      "Epoch 1911/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0096 - val_loss: 0.0092 - learning_rate: 2.5000e-05\n",
      "Epoch 1912/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0083 - learning_rate: 2.5000e-05\n",
      "Epoch 1913/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0072 - val_loss: 0.0109 - learning_rate: 2.5000e-05\n",
      "Epoch 1914/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0084 - val_loss: 0.0084 - learning_rate: 2.5000e-05\n",
      "Epoch 1915/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0113 - learning_rate: 2.5000e-05\n",
      "Epoch 1916/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0091 - val_loss: 0.0091 - learning_rate: 2.5000e-05\n",
      "Epoch 1917/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0096 - learning_rate: 2.5000e-05\n",
      "Epoch 1918/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0090 - learning_rate: 2.5000e-05\n",
      "Epoch 1919/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0086 - learning_rate: 2.5000e-05\n",
      "Epoch 1920/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0082 - val_loss: 0.0096 - learning_rate: 2.5000e-05\n",
      "Epoch 1921/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0082 - val_loss: 0.0092 - learning_rate: 2.5000e-05\n",
      "Epoch 1922/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0080 - val_loss: 0.0094 - learning_rate: 2.5000e-05\n",
      "Epoch 1923/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0111 - learning_rate: 2.5000e-05\n",
      "Epoch 1924/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0088 - val_loss: 0.0085 - learning_rate: 2.5000e-05\n",
      "Epoch 1925/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0082 - val_loss: 0.0100 - learning_rate: 2.5000e-05\n",
      "Epoch 1926/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0086 - learning_rate: 2.5000e-05\n",
      "Epoch 1927/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0094 - learning_rate: 2.5000e-05\n",
      "Epoch 1928/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0123 - learning_rate: 2.5000e-05\n",
      "Epoch 1929/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0083 - val_loss: 0.0085 - learning_rate: 2.5000e-05\n",
      "Epoch 1930/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0090 - learning_rate: 2.5000e-05\n",
      "Epoch 1931/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0094 - learning_rate: 2.5000e-05\n",
      "Epoch 1932/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0092 - learning_rate: 2.5000e-05\n",
      "Epoch 1933/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0086 - learning_rate: 2.5000e-05\n",
      "Epoch 1934/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0088 - val_loss: 0.0104 - learning_rate: 2.5000e-05\n",
      "Epoch 1935/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0088 - val_loss: 0.0082 - learning_rate: 2.5000e-05\n",
      "Epoch 1936/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0096 - learning_rate: 2.5000e-05\n",
      "Epoch 1937/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0100 - learning_rate: 2.5000e-05\n",
      "Epoch 1938/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0092 - val_loss: 0.0098 - learning_rate: 2.5000e-05\n",
      "Epoch 1939/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0092 - learning_rate: 2.5000e-05\n",
      "Epoch 1940/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0090 - learning_rate: 2.5000e-05\n",
      "Epoch 1941/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0084 - learning_rate: 2.5000e-05\n",
      "Epoch 1942/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0083 - learning_rate: 2.5000e-05\n",
      "Epoch 1943/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0081 - learning_rate: 2.5000e-05\n",
      "Epoch 1944/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0074 - val_loss: 0.0096 - learning_rate: 2.5000e-05\n",
      "Epoch 1945/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0091 - learning_rate: 2.5000e-05\n",
      "Epoch 1946/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0092 - learning_rate: 2.5000e-05\n",
      "Epoch 1947/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0096 - val_loss: 0.0107 - learning_rate: 2.5000e-05\n",
      "Epoch 1948/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0086 - val_loss: 0.0089 - learning_rate: 2.5000e-05\n",
      "Epoch 1949/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0093 - learning_rate: 2.5000e-05\n",
      "Epoch 1950/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 - val_loss: 0.0099 - learning_rate: 2.5000e-05\n",
      "Epoch 1951/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0083 - val_loss: 0.0087 - learning_rate: 2.5000e-05\n",
      "Epoch 1952/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0090 - learning_rate: 2.5000e-05\n",
      "Epoch 1953/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0085 - val_loss: 0.0086 - learning_rate: 2.5000e-05\n",
      "Epoch 1954/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0092 - learning_rate: 2.5000e-05\n",
      "Epoch 1955/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0087 - learning_rate: 2.5000e-05\n",
      "Epoch 1956/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0084 - learning_rate: 2.5000e-05\n",
      "Epoch 1957/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0084 - learning_rate: 2.5000e-05\n",
      "Epoch 1958/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0091 - learning_rate: 2.5000e-05\n",
      "Epoch 1959/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0120 - learning_rate: 2.5000e-05\n",
      "Epoch 1960/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0094 - val_loss: 0.0090 - learning_rate: 2.5000e-05\n",
      "Epoch 1961/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0084 - val_loss: 0.0089 - learning_rate: 2.5000e-05\n",
      "Epoch 1962/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0081 - learning_rate: 2.5000e-05\n",
      "Epoch 1963/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0096 - learning_rate: 2.5000e-05\n",
      "Epoch 1964/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0083 - val_loss: 0.0096 - learning_rate: 2.5000e-05\n",
      "Epoch 1965/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0089 - learning_rate: 2.5000e-05\n",
      "Epoch 1966/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0084 - learning_rate: 2.5000e-05\n",
      "Epoch 1967/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0078 - val_loss: 0.0092 - learning_rate: 2.5000e-05\n",
      "Epoch 1968/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0086 - val_loss: 0.0096 - learning_rate: 2.5000e-05\n",
      "Epoch 1969/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0101 - learning_rate: 2.5000e-05\n",
      "Epoch 1970/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0105 - learning_rate: 2.5000e-05\n",
      "Epoch 1971/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0086 - learning_rate: 2.5000e-05\n",
      "Epoch 1972/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0092 - learning_rate: 2.5000e-05\n",
      "Epoch 1973/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0089 - learning_rate: 2.5000e-05\n",
      "Epoch 1974/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0084 - val_loss: 0.0096 - learning_rate: 2.5000e-05\n",
      "Epoch 1975/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0091 - val_loss: 0.0083 - learning_rate: 2.5000e-05\n",
      "Epoch 1976/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0082 - learning_rate: 2.5000e-05\n",
      "Epoch 1977/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0084 - val_loss: 0.0098 - learning_rate: 2.5000e-05\n",
      "Epoch 1978/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0086 - val_loss: 0.0102 - learning_rate: 2.5000e-05\n",
      "Epoch 1979/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0093 - learning_rate: 2.5000e-05\n",
      "Epoch 1980/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0092 - learning_rate: 2.5000e-05\n",
      "Epoch 1981/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0081 - learning_rate: 2.5000e-05\n",
      "Epoch 1982/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0083 - learning_rate: 2.5000e-05\n",
      "Epoch 1983/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0095 - learning_rate: 2.5000e-05\n",
      "Epoch 1984/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0085 - learning_rate: 2.5000e-05\n",
      "Epoch 1985/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0085 - learning_rate: 2.5000e-05\n",
      "Epoch 1986/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0082 - learning_rate: 2.5000e-05\n",
      "Epoch 1987/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0084 - learning_rate: 2.5000e-05\n",
      "Epoch 1988/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0089 - learning_rate: 2.5000e-05\n",
      "Epoch 1989/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0082 - val_loss: 0.0088 - learning_rate: 2.5000e-05\n",
      "Epoch 1990/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0071 - val_loss: 0.0103 - learning_rate: 2.5000e-05\n",
      "Epoch 1991/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0088 - val_loss: 0.0088 - learning_rate: 2.5000e-05\n",
      "Epoch 1992/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0089 - learning_rate: 2.5000e-05\n",
      "Epoch 1993/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0082 - learning_rate: 2.5000e-05\n",
      "Epoch 1994/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0083 - learning_rate: 2.5000e-05\n",
      "Epoch 1995/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0105 - learning_rate: 2.5000e-05\n",
      "Epoch 1996/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0082 - val_loss: 0.0094 - learning_rate: 2.5000e-05\n",
      "Epoch 1997/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0088 - val_loss: 0.0093 - learning_rate: 2.5000e-05\n",
      "Epoch 1998/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0091 - learning_rate: 2.5000e-05\n",
      "Epoch 1999/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0084 - val_loss: 0.0095 - learning_rate: 2.5000e-05\n",
      "Epoch 2000/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0084 - val_loss: 0.0092 - learning_rate: 2.5000e-05\n",
      "Epoch 2001/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0091 - learning_rate: 2.5000e-05\n",
      "Epoch 2002/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0082 - learning_rate: 2.5000e-05\n",
      "Epoch 2003/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0089 - learning_rate: 2.5000e-05\n",
      "Epoch 2004/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0087 - learning_rate: 2.5000e-05\n",
      "Epoch 2005/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0100 - learning_rate: 2.5000e-05\n",
      "Epoch 2006/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0085 - learning_rate: 2.5000e-05\n",
      "Epoch 2007/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0086 - learning_rate: 2.5000e-05\n",
      "Epoch 2008/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0091 - learning_rate: 2.5000e-05\n",
      "Epoch 2009/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0084 - val_loss: 0.0090 - learning_rate: 2.5000e-05\n",
      "Epoch 2010/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0088 - val_loss: 0.0090 - learning_rate: 2.5000e-05\n",
      "Epoch 2011/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0090 - val_loss: 0.0087 - learning_rate: 2.5000e-05\n",
      "Epoch 2012/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0081 - learning_rate: 2.5000e-05\n",
      "Epoch 2013/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0084 - learning_rate: 2.5000e-05\n",
      "Epoch 2014/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0084 - learning_rate: 2.5000e-05\n",
      "Epoch 2015/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0085 - learning_rate: 2.5000e-05\n",
      "Epoch 2016/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0083 - learning_rate: 2.5000e-05\n",
      "Epoch 2017/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0101 - learning_rate: 2.5000e-05\n",
      "Epoch 2018/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0088 - val_loss: 0.0096 - learning_rate: 2.5000e-05\n",
      "Epoch 2019/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0076 - val_loss: 0.0089 - learning_rate: 2.5000e-05\n",
      "Epoch 2020/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0083 - val_loss: 0.0110 - learning_rate: 2.5000e-05\n",
      "Epoch 2021/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0105 - val_loss: 0.0096 - learning_rate: 2.5000e-05\n",
      "Epoch 2022/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0084 - val_loss: 0.0105 - learning_rate: 2.5000e-05\n",
      "Epoch 2023/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0086 - learning_rate: 2.5000e-05\n",
      "Epoch 2024/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0089 - learning_rate: 2.5000e-05\n",
      "Epoch 2025/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0090 - learning_rate: 2.5000e-05\n",
      "Epoch 2026/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0090 - learning_rate: 2.5000e-05\n",
      "Epoch 2027/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0082 - val_loss: 0.0086 - learning_rate: 2.5000e-05\n",
      "Epoch 2028/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0086 - learning_rate: 2.5000e-05\n",
      "Epoch 2029/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0084 - learning_rate: 2.5000e-05\n",
      "Epoch 2030/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0085 - learning_rate: 2.5000e-05\n",
      "Epoch 2031/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0080 - learning_rate: 2.5000e-05\n",
      "Epoch 2032/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0084 - val_loss: 0.0096 - learning_rate: 2.5000e-05\n",
      "Epoch 2033/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0095 - val_loss: 0.0089 - learning_rate: 2.5000e-05\n",
      "Epoch 2034/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0081 - val_loss: 0.0106 - learning_rate: 2.5000e-05\n",
      "Epoch 2035/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0085 - val_loss: 0.0111 - learning_rate: 2.5000e-05\n",
      "Epoch 2036/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0090 - val_loss: 0.0083 - learning_rate: 2.5000e-05\n",
      "Epoch 2037/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0094 - learning_rate: 2.5000e-05\n",
      "Epoch 2038/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0092 - learning_rate: 2.5000e-05\n",
      "Epoch 2039/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 - val_loss: 0.0101 - learning_rate: 2.5000e-05\n",
      "Epoch 2040/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0082 - learning_rate: 2.5000e-05\n",
      "Epoch 2041/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0092 - learning_rate: 2.5000e-05\n",
      "Epoch 2042/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0083 - learning_rate: 2.5000e-05\n",
      "Epoch 2043/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0081 - learning_rate: 2.5000e-05\n",
      "Epoch 2044/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0097 - learning_rate: 2.5000e-05\n",
      "Epoch 2045/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0086 - learning_rate: 2.5000e-05\n",
      "Epoch 2046/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0091 - learning_rate: 2.5000e-05\n",
      "Epoch 2047/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0097 - val_loss: 0.0086 - learning_rate: 2.5000e-05\n",
      "Epoch 2048/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0075 - val_loss: 0.0084 - learning_rate: 2.5000e-05\n",
      "Epoch 2049/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0085 - learning_rate: 2.5000e-05\n",
      "Epoch 2050/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0100 - learning_rate: 2.5000e-05\n",
      "Epoch 2051/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0111 - learning_rate: 2.5000e-05\n",
      "Epoch 2052/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0090 - val_loss: 0.0086 - learning_rate: 2.5000e-05\n",
      "Epoch 2053/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0086 - learning_rate: 2.5000e-05\n",
      "Epoch 2054/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0083 - val_loss: 0.0084 - learning_rate: 2.5000e-05\n",
      "Epoch 2055/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0101 - learning_rate: 2.5000e-05\n",
      "Epoch 2056/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0096 - learning_rate: 2.5000e-05\n",
      "Epoch 2057/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0099 - learning_rate: 2.5000e-05\n",
      "Epoch 2058/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0083 - learning_rate: 2.5000e-05\n",
      "Epoch 2059/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0091 - learning_rate: 2.5000e-05\n",
      "Epoch 2060/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0082 - learning_rate: 2.5000e-05\n",
      "Epoch 2061/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0091 - learning_rate: 2.5000e-05\n",
      "Epoch 2062/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0083 - learning_rate: 2.5000e-05\n",
      "Epoch 2063/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0086 - learning_rate: 2.5000e-05\n",
      "Epoch 2064/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0087 - learning_rate: 2.5000e-05\n",
      "Epoch 2065/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0084 - learning_rate: 2.5000e-05\n",
      "Epoch 2066/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0083 - learning_rate: 2.5000e-05\n",
      "Epoch 2067/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0089 - learning_rate: 2.5000e-05\n",
      "Epoch 2068/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0083 - val_loss: 0.0099 - learning_rate: 2.5000e-05\n",
      "Epoch 2069/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0088 - learning_rate: 2.5000e-05\n",
      "Epoch 2070/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0089 - val_loss: 0.0085 - learning_rate: 2.5000e-05\n",
      "Epoch 2071/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0096 - learning_rate: 2.5000e-05\n",
      "Epoch 2072/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0088 - val_loss: 0.0083 - learning_rate: 2.5000e-05\n",
      "Epoch 2073/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0096 - learning_rate: 2.5000e-05\n",
      "Epoch 2074/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0082 - val_loss: 0.0088 - learning_rate: 2.5000e-05\n",
      "Epoch 2075/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0081 - learning_rate: 2.5000e-05\n",
      "Epoch 2076/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0090 - learning_rate: 2.5000e-05\n",
      "Epoch 2077/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0094 - learning_rate: 2.5000e-05\n",
      "Epoch 2078/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0095 - learning_rate: 2.5000e-05\n",
      "Epoch 2079/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0088 - learning_rate: 2.5000e-05\n",
      "Epoch 2080/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0097 - learning_rate: 2.5000e-05\n",
      "Epoch 2081/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0082 - val_loss: 0.0088 - learning_rate: 2.5000e-05\n",
      "Epoch 2082/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0083 - learning_rate: 2.5000e-05\n",
      "Epoch 2083/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0082 - val_loss: 0.0100 - learning_rate: 2.5000e-05\n",
      "Epoch 2084/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0082 - learning_rate: 2.5000e-05\n",
      "Epoch 2085/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0086 - learning_rate: 2.5000e-05\n",
      "Epoch 2086/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0101 - learning_rate: 2.5000e-05\n",
      "Epoch 2087/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0083 - val_loss: 0.0099 - learning_rate: 2.5000e-05\n",
      "Epoch 2088/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0088 - val_loss: 0.0095 - learning_rate: 2.5000e-05\n",
      "Epoch 2089/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0076 - val_loss: 0.0081 - learning_rate: 2.5000e-05\n",
      "Epoch 2090/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0106 - learning_rate: 2.5000e-05\n",
      "Epoch 2091/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 - val_loss: 0.0080 - learning_rate: 2.5000e-05\n",
      "Epoch 2092/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0098 - learning_rate: 2.5000e-05\n",
      "Epoch 2093/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0084 - learning_rate: 2.5000e-05\n",
      "Epoch 2094/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0083 - val_loss: 0.0104 - learning_rate: 2.5000e-05\n",
      "Epoch 2095/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0085 - learning_rate: 2.5000e-05\n",
      "Epoch 2096/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0086 - learning_rate: 2.5000e-05\n",
      "Epoch 2097/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0091 - learning_rate: 2.5000e-05\n",
      "Epoch 2098/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0090 - learning_rate: 2.5000e-05\n",
      "Epoch 2099/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0087 - learning_rate: 2.5000e-05\n",
      "Epoch 2100/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0085 - learning_rate: 2.5000e-05\n",
      "Epoch 2101/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0080 - learning_rate: 2.5000e-05\n",
      "Epoch 2102/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0094 - learning_rate: 2.5000e-05\n",
      "Epoch 2103/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0080 - learning_rate: 2.5000e-05\n",
      "Epoch 2104/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0084 - learning_rate: 2.5000e-05\n",
      "Epoch 2105/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0082 - learning_rate: 2.5000e-05\n",
      "Epoch 2106/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0082 - learning_rate: 2.5000e-05\n",
      "Epoch 2107/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0085 - learning_rate: 2.5000e-05\n",
      "Epoch 2108/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0079 - learning_rate: 2.5000e-05\n",
      "Epoch 2109/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0092 - learning_rate: 2.5000e-05\n",
      "Epoch 2110/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0081 - val_loss: 0.0082 - learning_rate: 2.5000e-05\n",
      "Epoch 2111/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0094 - val_loss: 0.0090 - learning_rate: 2.5000e-05\n",
      "Epoch 2112/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0100 - learning_rate: 2.5000e-05\n",
      "Epoch 2113/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0091 - learning_rate: 2.5000e-05\n",
      "Epoch 2114/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0082 - val_loss: 0.0084 - learning_rate: 2.5000e-05\n",
      "Epoch 2115/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0086 - learning_rate: 2.5000e-05\n",
      "Epoch 2116/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0086 - learning_rate: 2.5000e-05\n",
      "Epoch 2117/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0081 - learning_rate: 2.5000e-05\n",
      "Epoch 2118/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0082 - learning_rate: 2.5000e-05\n",
      "Epoch 2119/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0088 - learning_rate: 2.5000e-05\n",
      "Epoch 2120/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0086 - learning_rate: 1.2500e-05\n",
      "Epoch 2121/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0085 - learning_rate: 1.2500e-05\n",
      "Epoch 2122/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0071 - val_loss: 0.0083 - learning_rate: 1.2500e-05\n",
      "Epoch 2123/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0078 - learning_rate: 1.2500e-05\n",
      "Epoch 2124/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0085 - learning_rate: 1.2500e-05\n",
      "Epoch 2125/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0083 - learning_rate: 1.2500e-05\n",
      "Epoch 2126/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0081 - learning_rate: 1.2500e-05\n",
      "Epoch 2127/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0087 - learning_rate: 1.2500e-05\n",
      "Epoch 2128/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0084 - learning_rate: 1.2500e-05\n",
      "Epoch 2129/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0081 - learning_rate: 1.2500e-05\n",
      "Epoch 2130/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0082 - learning_rate: 1.2500e-05\n",
      "Epoch 2131/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0071 - val_loss: 0.0080 - learning_rate: 1.2500e-05\n",
      "Epoch 2132/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0081 - learning_rate: 1.2500e-05\n",
      "Epoch 2133/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0081 - learning_rate: 1.2500e-05\n",
      "Epoch 2134/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0085 - learning_rate: 1.2500e-05\n",
      "Epoch 2135/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0090 - learning_rate: 1.2500e-05\n",
      "Epoch 2136/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0086 - learning_rate: 1.2500e-05\n",
      "Epoch 2137/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0092 - learning_rate: 1.2500e-05\n",
      "Epoch 2138/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0084 - learning_rate: 1.2500e-05\n",
      "Epoch 2139/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0089 - learning_rate: 1.2500e-05\n",
      "Epoch 2140/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0081 - learning_rate: 1.2500e-05\n",
      "Epoch 2141/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0087 - learning_rate: 1.2500e-05\n",
      "Epoch 2142/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0081 - learning_rate: 1.2500e-05\n",
      "Epoch 2143/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0086 - learning_rate: 1.2500e-05\n",
      "Epoch 2144/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0073 - val_loss: 0.0084 - learning_rate: 1.2500e-05\n",
      "Epoch 2145/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0075 - val_loss: 0.0080 - learning_rate: 1.2500e-05\n",
      "Epoch 2146/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0078 - val_loss: 0.0086 - learning_rate: 1.2500e-05\n",
      "Epoch 2147/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0083 - val_loss: 0.0084 - learning_rate: 1.2500e-05\n",
      "Epoch 2148/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0082 - learning_rate: 1.2500e-05\n",
      "Epoch 2149/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0079 - learning_rate: 1.2500e-05\n",
      "Epoch 2150/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0071 - val_loss: 0.0083 - learning_rate: 1.2500e-05\n",
      "Epoch 2151/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0071 - val_loss: 0.0079 - learning_rate: 1.2500e-05\n",
      "Epoch 2152/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0080 - learning_rate: 1.2500e-05\n",
      "Epoch 2153/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0087 - learning_rate: 1.2500e-05\n",
      "Epoch 2154/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0091 - learning_rate: 1.2500e-05\n",
      "Epoch 2155/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0082 - learning_rate: 1.2500e-05\n",
      "Epoch 2156/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0080 - learning_rate: 1.2500e-05\n",
      "Epoch 2157/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0080 - learning_rate: 1.2500e-05\n",
      "Epoch 2158/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0079 - learning_rate: 1.2500e-05\n",
      "Epoch 2159/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0088 - learning_rate: 1.2500e-05\n",
      "Epoch 2160/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0080 - learning_rate: 1.2500e-05\n",
      "Epoch 2161/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0077 - val_loss: 0.0079 - learning_rate: 1.2500e-05\n",
      "Epoch 2162/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0080 - learning_rate: 1.2500e-05\n",
      "Epoch 2163/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0083 - learning_rate: 1.2500e-05\n",
      "Epoch 2164/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0084 - learning_rate: 1.2500e-05\n",
      "Epoch 2165/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0085 - val_loss: 0.0089 - learning_rate: 1.2500e-05\n",
      "Epoch 2166/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0082 - learning_rate: 1.2500e-05\n",
      "Epoch 2167/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0080 - learning_rate: 1.2500e-05\n",
      "Epoch 2168/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0079 - learning_rate: 1.2500e-05\n",
      "Epoch 2169/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0082 - val_loss: 0.0082 - learning_rate: 1.2500e-05\n",
      "Epoch 2170/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0082 - learning_rate: 1.2500e-05\n",
      "Epoch 2171/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0067 - val_loss: 0.0081 - learning_rate: 1.2500e-05\n",
      "Epoch 2172/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0073 - val_loss: 0.0082 - learning_rate: 1.2500e-05\n",
      "Epoch 2173/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0070 - val_loss: 0.0082 - learning_rate: 1.2500e-05\n",
      "Epoch 2174/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0073 - val_loss: 0.0089 - learning_rate: 1.2500e-05\n",
      "Epoch 2175/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0085 - learning_rate: 1.2500e-05\n",
      "Epoch 2176/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0080 - learning_rate: 1.2500e-05\n",
      "Epoch 2177/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0082 - learning_rate: 1.2500e-05\n",
      "Epoch 2178/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0079 - learning_rate: 1.2500e-05\n",
      "Epoch 2179/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0084 - learning_rate: 1.2500e-05\n",
      "Epoch 2180/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0075 - val_loss: 0.0081 - learning_rate: 1.2500e-05\n",
      "Epoch 2181/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0086 - learning_rate: 1.2500e-05\n",
      "Epoch 2182/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0084 - learning_rate: 1.2500e-05\n",
      "Epoch 2183/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0076 - val_loss: 0.0080 - learning_rate: 1.2500e-05\n",
      "Epoch 2184/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0073 - val_loss: 0.0079 - learning_rate: 1.2500e-05\n",
      "Epoch 2185/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0077 - val_loss: 0.0084 - learning_rate: 1.2500e-05\n",
      "Epoch 2186/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0083 - learning_rate: 1.2500e-05\n",
      "Epoch 2187/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 - val_loss: 0.0095 - learning_rate: 1.2500e-05\n",
      "Epoch 2188/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0086 - val_loss: 0.0082 - learning_rate: 1.2500e-05\n",
      "Epoch 2189/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0082 - learning_rate: 1.2500e-05\n",
      "Epoch 2190/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0081 - learning_rate: 1.2500e-05\n",
      "Epoch 2191/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0086 - learning_rate: 1.2500e-05\n",
      "Epoch 2192/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0093 - learning_rate: 1.2500e-05\n",
      "Epoch 2193/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0083 - learning_rate: 1.2500e-05\n",
      "Epoch 2194/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0073 - val_loss: 0.0080 - learning_rate: 1.2500e-05\n",
      "Epoch 2195/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0075 - val_loss: 0.0090 - learning_rate: 1.2500e-05\n",
      "Epoch 2196/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0078 - val_loss: 0.0085 - learning_rate: 1.2500e-05\n",
      "Epoch 2197/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0071 - val_loss: 0.0082 - learning_rate: 1.2500e-05\n",
      "Epoch 2198/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0077 - val_loss: 0.0093 - learning_rate: 1.2500e-05\n",
      "Epoch 2199/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0081 - learning_rate: 1.2500e-05\n",
      "Epoch 2200/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0080 - learning_rate: 1.2500e-05\n",
      "Epoch 2201/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0085 - learning_rate: 1.2500e-05\n",
      "Epoch 2202/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0081 - learning_rate: 1.2500e-05\n",
      "Epoch 2203/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0070 - val_loss: 0.0079 - learning_rate: 1.2500e-05\n",
      "Epoch 2204/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0079 - learning_rate: 1.2500e-05\n",
      "Epoch 2205/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0080 - learning_rate: 1.2500e-05\n",
      "Epoch 2206/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0071 - val_loss: 0.0082 - learning_rate: 1.2500e-05\n",
      "Epoch 2207/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0082 - learning_rate: 1.2500e-05\n",
      "Epoch 2208/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0087 - learning_rate: 1.2500e-05\n",
      "Epoch 2209/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0084 - learning_rate: 1.2500e-05\n",
      "Epoch 2210/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0080 - learning_rate: 1.2500e-05\n",
      "Epoch 2211/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0084 - learning_rate: 1.2500e-05\n",
      "Epoch 2212/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0079 - learning_rate: 1.2500e-05\n",
      "Epoch 2213/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0080 - learning_rate: 1.2500e-05\n",
      "Epoch 2214/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0084 - learning_rate: 1.2500e-05\n",
      "Epoch 2215/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0080 - learning_rate: 1.2500e-05\n",
      "Epoch 2216/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0085 - learning_rate: 1.2500e-05\n",
      "Epoch 2217/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0083 - learning_rate: 1.2500e-05\n",
      "Epoch 2218/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0082 - learning_rate: 1.2500e-05\n",
      "Epoch 2219/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0085 - learning_rate: 1.2500e-05\n",
      "Epoch 2220/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0100 - learning_rate: 1.2500e-05\n",
      "Epoch 2221/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0102 - learning_rate: 1.2500e-05\n",
      "Epoch 2222/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0082 - learning_rate: 1.2500e-05\n",
      "Epoch 2223/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0081 - learning_rate: 1.2500e-05\n",
      "Epoch 2224/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0080 - learning_rate: 1.2500e-05\n",
      "Epoch 2225/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0077 - val_loss: 0.0087 - learning_rate: 1.2500e-05\n",
      "Epoch 2226/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0081 - learning_rate: 1.2500e-05\n",
      "Epoch 2227/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0080 - learning_rate: 1.2500e-05\n",
      "Epoch 2228/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0085 - learning_rate: 1.2500e-05\n",
      "Epoch 2229/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0085 - learning_rate: 1.2500e-05\n",
      "Epoch 2230/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0084 - learning_rate: 1.2500e-05\n",
      "Epoch 2231/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0079 - val_loss: 0.0086 - learning_rate: 1.2500e-05\n",
      "Epoch 2232/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0083 - learning_rate: 1.2500e-05\n",
      "Epoch 2233/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0081 - learning_rate: 1.2500e-05\n",
      "Epoch 2234/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0096 - learning_rate: 1.2500e-05\n",
      "Epoch 2235/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0083 - learning_rate: 1.2500e-05\n",
      "Epoch 2236/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0082 - learning_rate: 1.2500e-05\n",
      "Epoch 2237/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0079 - learning_rate: 1.2500e-05\n",
      "Epoch 2238/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0070 - val_loss: 0.0086 - learning_rate: 1.2500e-05\n",
      "Epoch 2239/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0087 - learning_rate: 1.2500e-05\n",
      "Epoch 2240/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0084 - learning_rate: 1.2500e-05\n",
      "Epoch 2241/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0071 - val_loss: 0.0080 - learning_rate: 1.2500e-05\n",
      "Epoch 2242/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0079 - learning_rate: 1.2500e-05\n",
      "Epoch 2243/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0080 - learning_rate: 1.2500e-05\n",
      "Epoch 2244/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0079 - learning_rate: 1.2500e-05\n",
      "Epoch 2245/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0084 - learning_rate: 1.2500e-05\n",
      "Epoch 2246/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0085 - learning_rate: 1.2500e-05\n",
      "Epoch 2247/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0092 - learning_rate: 1.2500e-05\n",
      "Epoch 2248/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0085 - learning_rate: 1.2500e-05\n",
      "Epoch 2249/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0082 - learning_rate: 1.2500e-05\n",
      "Epoch 2250/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0082 - learning_rate: 1.2500e-05\n",
      "Epoch 2251/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0086 - learning_rate: 1.2500e-05\n",
      "Epoch 2252/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0082 - val_loss: 0.0082 - learning_rate: 1.2500e-05\n",
      "Epoch 2253/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0084 - learning_rate: 1.2500e-05\n",
      "Epoch 2254/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0082 - learning_rate: 1.2500e-05\n",
      "Epoch 2255/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0082 - learning_rate: 1.2500e-05\n",
      "Epoch 2256/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0088 - learning_rate: 1.2500e-05\n",
      "Epoch 2257/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0089 - learning_rate: 1.2500e-05\n",
      "Epoch 2258/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0082 - learning_rate: 1.2500e-05\n",
      "Epoch 2259/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0080 - learning_rate: 1.2500e-05\n",
      "Epoch 2260/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0081 - learning_rate: 1.2500e-05\n",
      "Epoch 2261/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0069 - val_loss: 0.0082 - learning_rate: 1.2500e-05\n",
      "Epoch 2262/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0081 - learning_rate: 1.2500e-05\n",
      "Epoch 2263/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0084 - learning_rate: 1.2500e-05\n",
      "Epoch 2264/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0068 - val_loss: 0.0083 - learning_rate: 1.2500e-05\n",
      "Epoch 2265/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0081 - learning_rate: 1.2500e-05\n",
      "Epoch 2266/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0080 - learning_rate: 1.2500e-05\n",
      "Epoch 2267/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0083 - learning_rate: 1.2500e-05\n",
      "Epoch 2268/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0097 - learning_rate: 1.2500e-05\n",
      "Epoch 2269/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0082 - val_loss: 0.0093 - learning_rate: 1.2500e-05\n",
      "Epoch 2270/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0085 - learning_rate: 1.2500e-05\n",
      "Epoch 2271/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0081 - learning_rate: 1.2500e-05\n",
      "Epoch 2272/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0080 - learning_rate: 1.2500e-05\n",
      "Epoch 2273/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0084 - learning_rate: 1.2500e-05\n",
      "Epoch 2274/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0085 - val_loss: 0.0084 - learning_rate: 1.2500e-05\n",
      "Epoch 2275/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0084 - learning_rate: 1.2500e-05\n",
      "Epoch 2276/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0090 - learning_rate: 1.2500e-05\n",
      "Epoch 2277/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0079 - learning_rate: 1.2500e-05\n",
      "Epoch 2278/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0074 - val_loss: 0.0081 - learning_rate: 1.2500e-05\n",
      "Epoch 2279/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0091 - learning_rate: 1.2500e-05\n",
      "Epoch 2280/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0083 - learning_rate: 1.2500e-05\n",
      "Epoch 2281/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0083 - learning_rate: 1.2500e-05\n",
      "Epoch 2282/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0085 - learning_rate: 1.2500e-05\n",
      "Epoch 2283/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0082 - learning_rate: 1.2500e-05\n",
      "Epoch 2284/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0077 - val_loss: 0.0078 - learning_rate: 1.2500e-05\n",
      "Epoch 2285/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0092 - learning_rate: 1.2500e-05\n",
      "Epoch 2286/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0084 - learning_rate: 1.2500e-05\n",
      "Epoch 2287/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0086 - learning_rate: 1.2500e-05\n",
      "Epoch 2288/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0071 - val_loss: 0.0081 - learning_rate: 1.2500e-05\n",
      "Epoch 2289/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0079 - learning_rate: 1.2500e-05\n",
      "Epoch 2290/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0099 - learning_rate: 1.2500e-05\n",
      "Epoch 2291/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0082 - learning_rate: 1.2500e-05\n",
      "Epoch 2292/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0085 - learning_rate: 1.2500e-05\n",
      "Epoch 2293/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0087 - learning_rate: 1.2500e-05\n",
      "Epoch 2294/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0082 - learning_rate: 1.2500e-05\n",
      "Epoch 2295/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0085 - learning_rate: 1.2500e-05\n",
      "Epoch 2296/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0086 - learning_rate: 1.2500e-05\n",
      "Epoch 2297/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0070 - val_loss: 0.0083 - learning_rate: 1.2500e-05\n",
      "Epoch 2298/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0084 - learning_rate: 1.2500e-05\n",
      "Epoch 2299/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0082 - learning_rate: 1.2500e-05\n",
      "Epoch 2300/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0075 - val_loss: 0.0082 - learning_rate: 1.2500e-05\n",
      "Epoch 2301/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0080 - learning_rate: 1.2500e-05\n",
      "Epoch 2302/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0096 - learning_rate: 1.2500e-05\n",
      "Epoch 2303/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0087 - learning_rate: 1.2500e-05\n",
      "Epoch 2304/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0081 - learning_rate: 1.2500e-05\n",
      "Epoch 2305/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0076 - val_loss: 0.0103 - learning_rate: 1.2500e-05\n",
      "Epoch 2306/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0085 - val_loss: 0.0087 - learning_rate: 1.2500e-05\n",
      "Epoch 2307/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0079 - val_loss: 0.0084 - learning_rate: 1.2500e-05\n",
      "Epoch 2308/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0082 - learning_rate: 1.2500e-05\n",
      "Epoch 2309/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0090 - learning_rate: 1.2500e-05\n",
      "Epoch 2310/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0081 - learning_rate: 1.2500e-05\n",
      "Epoch 2311/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0086 - learning_rate: 1.2500e-05\n",
      "Epoch 2312/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0082 - learning_rate: 1.2500e-05\n",
      "Epoch 2313/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0080 - learning_rate: 1.2500e-05\n",
      "Epoch 2314/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0080 - learning_rate: 1.2500e-05\n",
      "Epoch 2315/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0084 - learning_rate: 1.2500e-05\n",
      "Epoch 2316/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0082 - learning_rate: 1.2500e-05\n",
      "Epoch 2317/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0086 - learning_rate: 1.2500e-05\n",
      "Epoch 2318/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0080 - learning_rate: 1.2500e-05\n",
      "Epoch 2319/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0084 - learning_rate: 1.2500e-05\n",
      "Epoch 2320/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0089 - learning_rate: 1.2500e-05\n",
      "Epoch 2321/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0085 - learning_rate: 1.2500e-05\n",
      "Epoch 2322/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0078 - val_loss: 0.0089 - learning_rate: 1.2500e-05\n",
      "Epoch 2323/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0082 - val_loss: 0.0084 - learning_rate: 1.2500e-05\n",
      "Epoch 2324/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0081 - val_loss: 0.0089 - learning_rate: 1.2500e-05\n",
      "Epoch 2325/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0084 - learning_rate: 1.2500e-05\n",
      "Epoch 2326/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0075 - val_loss: 0.0081 - learning_rate: 1.2500e-05\n",
      "Epoch 2327/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0086 - learning_rate: 1.2500e-05\n",
      "Epoch 2328/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0082 - learning_rate: 1.2500e-05\n",
      "Epoch 2329/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0081 - learning_rate: 1.2500e-05\n",
      "Epoch 2330/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0082 - learning_rate: 1.2500e-05\n",
      "Epoch 2331/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0080 - learning_rate: 1.2500e-05\n",
      "Epoch 2332/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0079 - learning_rate: 1.2500e-05\n",
      "Epoch 2333/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0081 - learning_rate: 1.2500e-05\n",
      "Epoch 2334/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0081 - learning_rate: 1.2500e-05\n",
      "Epoch 2335/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0079 - learning_rate: 1.2500e-05\n",
      "Epoch 2336/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0095 - learning_rate: 1.2500e-05\n",
      "Epoch 2337/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0084 - learning_rate: 1.2500e-05\n",
      "Epoch 2338/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0089 - learning_rate: 1.2500e-05\n",
      "Epoch 2339/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0082 - val_loss: 0.0095 - learning_rate: 1.2500e-05\n",
      "Epoch 2340/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0086 - learning_rate: 1.2500e-05\n",
      "Epoch 2341/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0083 - val_loss: 0.0082 - learning_rate: 1.2500e-05\n",
      "Epoch 2342/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0083 - learning_rate: 1.2500e-05\n",
      "Epoch 2343/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0085 - learning_rate: 1.2500e-05\n",
      "Epoch 2344/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0092 - learning_rate: 1.2500e-05\n",
      "Epoch 2345/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0077 - val_loss: 0.0086 - learning_rate: 1.2500e-05\n",
      "Epoch 2346/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0079 - val_loss: 0.0089 - learning_rate: 1.2500e-05\n",
      "Epoch 2347/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0077 - val_loss: 0.0080 - learning_rate: 1.2500e-05\n",
      "Epoch 2348/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0080 - learning_rate: 1.2500e-05\n",
      "Epoch 2349/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0080 - learning_rate: 1.2500e-05\n",
      "Epoch 2350/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0083 - learning_rate: 1.2500e-05\n",
      "Epoch 2351/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0086 - learning_rate: 1.2500e-05\n",
      "Epoch 2352/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0084 - learning_rate: 1.2500e-05\n",
      "Epoch 2353/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0080 - learning_rate: 1.2500e-05\n",
      "Epoch 2354/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0081 - learning_rate: 1.2500e-05\n",
      "Epoch 2355/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0080 - learning_rate: 1.2500e-05\n",
      "Epoch 2356/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0068 - val_loss: 0.0085 - learning_rate: 1.2500e-05\n",
      "Epoch 2357/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0083 - learning_rate: 1.2500e-05\n",
      "Epoch 2358/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0086 - learning_rate: 1.2500e-05\n",
      "Epoch 2359/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0081 - learning_rate: 1.2500e-05\n",
      "Epoch 2360/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0081 - learning_rate: 1.2500e-05\n",
      "Epoch 2361/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0091 - learning_rate: 1.2500e-05\n",
      "Epoch 2362/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0086 - learning_rate: 1.2500e-05\n",
      "Epoch 2363/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0083 - learning_rate: 1.2500e-05\n",
      "Epoch 2364/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0087 - learning_rate: 1.2500e-05\n",
      "Epoch 2365/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0090 - learning_rate: 1.2500e-05\n",
      "Epoch 2366/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0082 - val_loss: 0.0088 - learning_rate: 1.2500e-05\n",
      "Epoch 2367/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0082 - learning_rate: 1.2500e-05\n",
      "Epoch 2368/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0089 - learning_rate: 1.2500e-05\n",
      "Epoch 2369/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0081 - learning_rate: 1.2500e-05\n",
      "Epoch 2370/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0080 - learning_rate: 1.2500e-05\n",
      "Epoch 2371/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0088 - learning_rate: 1.2500e-05\n",
      "Epoch 2372/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0075 - val_loss: 0.0082 - learning_rate: 1.2500e-05\n",
      "Epoch 2373/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0086 - learning_rate: 1.2500e-05\n",
      "Epoch 2374/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0080 - learning_rate: 1.2500e-05\n",
      "Epoch 2375/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0086 - learning_rate: 1.2500e-05\n",
      "Epoch 2376/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0081 - learning_rate: 1.2500e-05\n",
      "Epoch 2377/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0081 - learning_rate: 1.2500e-05\n",
      "Epoch 2378/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0095 - learning_rate: 1.2500e-05\n",
      "Epoch 2379/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0085 - learning_rate: 1.2500e-05\n",
      "Epoch 2380/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0081 - learning_rate: 1.2500e-05\n",
      "Epoch 2381/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0080 - learning_rate: 1.2500e-05\n",
      "Epoch 2382/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0071 - val_loss: 0.0086 - learning_rate: 1.2500e-05\n",
      "Epoch 2383/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0087 - learning_rate: 1.2500e-05\n",
      "Epoch 2384/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0069 - val_loss: 0.0079 - learning_rate: 1.2500e-05\n",
      "Epoch 2385/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0084 - learning_rate: 1.2500e-05\n",
      "Epoch 2386/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0082 - learning_rate: 1.2500e-05\n",
      "Epoch 2387/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0083 - learning_rate: 1.2500e-05\n",
      "Epoch 2388/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0084 - learning_rate: 1.2500e-05\n",
      "Epoch 2389/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0087 - learning_rate: 1.2500e-05\n",
      "Epoch 2390/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0081 - learning_rate: 1.2500e-05\n",
      "Epoch 2391/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0083 - learning_rate: 1.2500e-05\n",
      "Epoch 2392/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0081 - learning_rate: 1.2500e-05\n",
      "Epoch 2393/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0092 - learning_rate: 1.2500e-05\n",
      "Epoch 2394/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0084 - learning_rate: 1.2500e-05\n",
      "Epoch 2395/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0087 - learning_rate: 1.2500e-05\n",
      "Epoch 2396/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0080 - learning_rate: 1.2500e-05\n",
      "Epoch 2397/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0079 - learning_rate: 1.2500e-05\n",
      "Epoch 2398/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0080 - learning_rate: 1.2500e-05\n",
      "Epoch 2399/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0096 - learning_rate: 1.2500e-05\n",
      "Epoch 2400/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0079 - learning_rate: 1.2500e-05\n",
      "Epoch 2401/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0086 - learning_rate: 1.2500e-05\n",
      "Epoch 2402/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0079 - val_loss: 0.0096 - learning_rate: 1.2500e-05\n",
      "Epoch 2403/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0088 - learning_rate: 1.2500e-05\n",
      "Epoch 2404/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0082 - learning_rate: 1.2500e-05\n",
      "Epoch 2405/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0088 - learning_rate: 1.2500e-05\n",
      "Epoch 2406/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0080 - learning_rate: 1.2500e-05\n",
      "Epoch 2407/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0083 - learning_rate: 1.2500e-05\n",
      "Epoch 2408/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0080 - learning_rate: 1.2500e-05\n",
      "Epoch 2409/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0084 - learning_rate: 1.2500e-05\n",
      "Epoch 2410/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0079 - learning_rate: 1.2500e-05\n",
      "Epoch 2411/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0085 - learning_rate: 1.2500e-05\n",
      "Epoch 2412/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0082 - val_loss: 0.0096 - learning_rate: 1.2500e-05\n",
      "Epoch 2413/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0096 - learning_rate: 1.2500e-05\n",
      "Epoch 2414/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0094 - learning_rate: 1.2500e-05\n",
      "Epoch 2415/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0083 - learning_rate: 1.2500e-05\n",
      "Epoch 2416/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0081 - learning_rate: 1.2500e-05\n",
      "Epoch 2417/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0084 - learning_rate: 1.2500e-05\n",
      "Epoch 2418/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0085 - learning_rate: 1.2500e-05\n",
      "Epoch 2419/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0080 - learning_rate: 1.2500e-05\n",
      "Epoch 2420/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0081 - learning_rate: 1.2500e-05\n",
      "Epoch 2421/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0081 - learning_rate: 1.2500e-05\n",
      "Epoch 2422/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0092 - learning_rate: 1.2500e-05\n",
      "Epoch 2423/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0085 - learning_rate: 1.2500e-05\n",
      "Epoch 2424/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0084 - learning_rate: 1.2500e-05\n",
      "Epoch 2425/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0081 - learning_rate: 1.2500e-05\n",
      "Epoch 2426/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0082 - learning_rate: 1.2500e-05\n",
      "Epoch 2427/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0089 - learning_rate: 1.2500e-05\n",
      "Epoch 2428/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0082 - val_loss: 0.0082 - learning_rate: 1.2500e-05\n",
      "Epoch 2429/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0083 - learning_rate: 1.2500e-05\n",
      "Epoch 2430/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0083 - learning_rate: 1.2500e-05\n",
      "Epoch 2431/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0084 - learning_rate: 1.2500e-05\n",
      "Epoch 2432/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0081 - learning_rate: 1.2500e-05\n",
      "Epoch 2433/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0083 - learning_rate: 1.2500e-05\n",
      "Epoch 2434/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0081 - learning_rate: 1.2500e-05\n",
      "Epoch 2435/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0082 - learning_rate: 1.2500e-05\n",
      "Epoch 2436/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0086 - learning_rate: 1.2500e-05\n",
      "Epoch 2437/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0082 - learning_rate: 1.2500e-05\n",
      "Epoch 2438/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0086 - learning_rate: 1.2500e-05\n",
      "Epoch 2439/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0084 - learning_rate: 1.2500e-05\n",
      "Epoch 2440/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0082 - learning_rate: 1.2500e-05\n",
      "Epoch 2441/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0071 - val_loss: 0.0082 - learning_rate: 1.2500e-05\n",
      "Epoch 2442/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0070 - val_loss: 0.0079 - learning_rate: 1.2500e-05\n",
      "Epoch 2443/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0102 - learning_rate: 1.2500e-05\n",
      "Epoch 2444/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0086 - learning_rate: 1.2500e-05\n",
      "Epoch 2445/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0080 - learning_rate: 1.2500e-05\n",
      "Epoch 2446/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0083 - learning_rate: 1.2500e-05\n",
      "Epoch 2447/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0081 - learning_rate: 1.2500e-05\n",
      "Epoch 2448/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0100 - learning_rate: 1.2500e-05\n",
      "Epoch 2449/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 - val_loss: 0.0086 - learning_rate: 1.2500e-05\n",
      "Epoch 2450/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0087 - learning_rate: 1.2500e-05\n",
      "Epoch 2451/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0079 - learning_rate: 1.2500e-05\n",
      "Epoch 2452/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0080 - learning_rate: 1.2500e-05\n",
      "Epoch 2453/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0080 - learning_rate: 1.2500e-05\n",
      "Epoch 2454/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0081 - learning_rate: 1.2500e-05\n",
      "Epoch 2455/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0083 - learning_rate: 1.2500e-05\n",
      "Epoch 2456/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0085 - learning_rate: 1.2500e-05\n",
      "Epoch 2457/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0081 - learning_rate: 1.2500e-05\n",
      "Epoch 2458/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0083 - learning_rate: 1.2500e-05\n",
      "Epoch 2459/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0081 - learning_rate: 1.2500e-05\n",
      "Epoch 2460/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0075 - val_loss: 0.0091 - learning_rate: 1.2500e-05\n",
      "Epoch 2461/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0083 - learning_rate: 1.2500e-05\n",
      "Epoch 2462/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0081 - learning_rate: 1.2500e-05\n",
      "Epoch 2463/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0082 - learning_rate: 1.2500e-05\n",
      "Epoch 2464/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0082 - learning_rate: 1.2500e-05\n",
      "Epoch 2465/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0089 - learning_rate: 1.2500e-05\n",
      "Epoch 2466/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0082 - learning_rate: 1.2500e-05\n",
      "Epoch 2467/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0084 - learning_rate: 1.2500e-05\n",
      "Epoch 2468/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0086 - learning_rate: 1.2500e-05\n",
      "Epoch 2469/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0086 - learning_rate: 1.2500e-05\n",
      "Epoch 2470/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0095 - learning_rate: 1.2500e-05\n",
      "Epoch 2471/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0082 - val_loss: 0.0082 - learning_rate: 1.2500e-05\n",
      "Epoch 2472/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0066 - val_loss: 0.0080 - learning_rate: 1.2500e-05\n",
      "Epoch 2473/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0083 - learning_rate: 1.2500e-05\n",
      "Epoch 2474/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0073 - val_loss: 0.0079 - learning_rate: 1.2500e-05\n",
      "Epoch 2475/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0070 - val_loss: 0.0082 - learning_rate: 1.2500e-05\n",
      "Epoch 2476/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0071 - val_loss: 0.0081 - learning_rate: 1.2500e-05\n",
      "Epoch 2477/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0079 - learning_rate: 1.2500e-05\n",
      "Epoch 2478/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0068 - val_loss: 0.0082 - learning_rate: 1.2500e-05\n",
      "Epoch 2479/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0072 - val_loss: 0.0085 - learning_rate: 1.2500e-05\n",
      "Epoch 2480/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0089 - learning_rate: 1.2500e-05\n",
      "Epoch 2481/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0083 - learning_rate: 1.2500e-05\n",
      "Epoch 2482/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0083 - learning_rate: 1.2500e-05\n",
      "Epoch 2483/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0082 - learning_rate: 1.2500e-05\n",
      "Epoch 2484/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0086 - learning_rate: 1.2500e-05\n",
      "Epoch 2485/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0081 - learning_rate: 1.2500e-05\n",
      "Epoch 2486/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0086 - learning_rate: 1.2500e-05\n",
      "Epoch 2487/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0082 - learning_rate: 1.2500e-05\n",
      "Epoch 2488/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0088 - learning_rate: 1.2500e-05\n",
      "Epoch 2489/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0082 - val_loss: 0.0087 - learning_rate: 1.2500e-05\n",
      "Epoch 2490/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0081 - learning_rate: 1.2500e-05\n",
      "Epoch 2491/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0080 - learning_rate: 1.2500e-05\n",
      "Epoch 2492/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0079 - learning_rate: 1.2500e-05\n",
      "Epoch 2493/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0067 - val_loss: 0.0095 - learning_rate: 1.2500e-05\n",
      "Epoch 2494/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0074 - val_loss: 0.0086 - learning_rate: 1.2500e-05\n",
      "Epoch 2495/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0088 - learning_rate: 1.2500e-05\n",
      "Epoch 2496/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0083 - val_loss: 0.0080 - learning_rate: 1.2500e-05\n",
      "Epoch 2497/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0073 - val_loss: 0.0085 - learning_rate: 1.2500e-05\n",
      "Epoch 2498/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0086 - learning_rate: 1.2500e-05\n",
      "Epoch 2499/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0090 - learning_rate: 1.2500e-05\n",
      "Epoch 2500/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0082 - learning_rate: 1.2500e-05\n",
      "Epoch 2501/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0080 - learning_rate: 1.2500e-05\n",
      "Epoch 2502/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0083 - learning_rate: 1.2500e-05\n",
      "Epoch 2503/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0097 - learning_rate: 1.2500e-05\n",
      "Epoch 2504/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0085 - learning_rate: 1.2500e-05\n",
      "Epoch 2505/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0091 - learning_rate: 1.2500e-05\n",
      "Epoch 2506/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0082 - val_loss: 0.0083 - learning_rate: 1.2500e-05\n",
      "Epoch 2507/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0086 - learning_rate: 1.2500e-05\n",
      "Epoch 2508/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0085 - learning_rate: 1.2500e-05\n",
      "Epoch 2509/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0083 - learning_rate: 1.2500e-05\n",
      "Epoch 2510/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0085 - learning_rate: 1.2500e-05\n",
      "Epoch 2511/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0085 - learning_rate: 1.2500e-05\n",
      "Epoch 2512/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0085 - learning_rate: 1.2500e-05\n",
      "Epoch 2513/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0080 - learning_rate: 1.2500e-05\n",
      "Epoch 2514/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0074 - val_loss: 0.0082 - learning_rate: 1.2500e-05\n",
      "Epoch 2515/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0080 - learning_rate: 1.2500e-05\n",
      "Epoch 2516/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0076 - val_loss: 0.0080 - learning_rate: 1.2500e-05\n",
      "Epoch 2517/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0085 - learning_rate: 1.2500e-05\n",
      "Epoch 2518/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0083 - learning_rate: 1.2500e-05\n",
      "Epoch 2519/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0099 - learning_rate: 1.2500e-05\n",
      "Epoch 2520/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0089 - learning_rate: 1.2500e-05\n",
      "Epoch 2521/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0090 - learning_rate: 1.2500e-05\n",
      "Epoch 2522/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0082 - learning_rate: 1.2500e-05\n",
      "Epoch 2523/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0079 - learning_rate: 1.2500e-05\n",
      "Epoch 2524/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0080 - learning_rate: 1.2500e-05\n",
      "Epoch 2525/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0094 - learning_rate: 1.2500e-05\n",
      "Epoch 2526/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0093 - learning_rate: 1.2500e-05\n",
      "Epoch 2527/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0082 - val_loss: 0.0080 - learning_rate: 1.2500e-05\n",
      "Epoch 2528/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0081 - val_loss: 0.0084 - learning_rate: 1.2500e-05\n",
      "Epoch 2529/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0071 - val_loss: 0.0084 - learning_rate: 1.2500e-05\n",
      "Epoch 2530/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0081 - learning_rate: 1.2500e-05\n",
      "Epoch 2531/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0069 - val_loss: 0.0080 - learning_rate: 1.2500e-05\n",
      "Epoch 2532/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0074 - val_loss: 0.0087 - learning_rate: 1.2500e-05\n",
      "Epoch 2533/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0101 - learning_rate: 1.2500e-05\n",
      "Epoch 2534/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0082 - val_loss: 0.0086 - learning_rate: 1.2500e-05\n",
      "Epoch 2535/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0084 - learning_rate: 1.2500e-05\n",
      "Epoch 2536/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0078 - learning_rate: 1.2500e-05\n",
      "Epoch 2537/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0081 - learning_rate: 1.2500e-05\n",
      "Epoch 2538/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0084 - learning_rate: 1.2500e-05\n",
      "Epoch 2539/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0082 - learning_rate: 1.2500e-05\n",
      "Epoch 2540/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0080 - learning_rate: 1.2500e-05\n",
      "Epoch 2541/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0089 - learning_rate: 1.2500e-05\n",
      "Epoch 2542/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0079 - learning_rate: 1.2500e-05\n",
      "Epoch 2543/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0081 - learning_rate: 1.2500e-05\n",
      "Epoch 2544/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0071 - val_loss: 0.0084 - learning_rate: 1.2500e-05\n",
      "Epoch 2545/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0114 - learning_rate: 1.2500e-05\n",
      "Epoch 2546/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 - val_loss: 0.0087 - learning_rate: 1.2500e-05\n",
      "Epoch 2547/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0081 - learning_rate: 1.2500e-05\n",
      "Epoch 2548/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0076 - val_loss: 0.0085 - learning_rate: 1.2500e-05\n",
      "Epoch 2549/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0085 - learning_rate: 1.2500e-05\n",
      "Epoch 2550/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0079 - learning_rate: 1.2500e-05\n",
      "Epoch 2551/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0082 - learning_rate: 1.2500e-05\n",
      "Epoch 2552/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0105 - learning_rate: 1.2500e-05\n",
      "Epoch 2553/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0086 - val_loss: 0.0085 - learning_rate: 1.2500e-05\n",
      "Epoch 2554/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0083 - learning_rate: 1.2500e-05\n",
      "Epoch 2555/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0084 - learning_rate: 1.2500e-05\n",
      "Epoch 2556/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0082 - learning_rate: 1.2500e-05\n",
      "Epoch 2557/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0089 - learning_rate: 1.2500e-05\n",
      "Epoch 2558/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0084 - learning_rate: 1.2500e-05\n",
      "Epoch 2559/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0088 - learning_rate: 1.2500e-05\n",
      "Epoch 2560/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0084 - learning_rate: 1.2500e-05\n",
      "Epoch 2561/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0082 - learning_rate: 1.2500e-05\n",
      "Epoch 2562/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0082 - learning_rate: 1.2500e-05\n",
      "Epoch 2563/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0090 - learning_rate: 1.2500e-05\n",
      "Epoch 2564/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0080 - learning_rate: 1.2500e-05\n",
      "Epoch 2565/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0087 - learning_rate: 1.2500e-05\n",
      "Epoch 2566/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0070 - val_loss: 0.0080 - learning_rate: 1.2500e-05\n",
      "Epoch 2567/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0079 - learning_rate: 1.2500e-05\n",
      "Epoch 2568/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0083 - learning_rate: 1.2500e-05\n",
      "Epoch 2569/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0083 - learning_rate: 1.2500e-05\n",
      "Epoch 2570/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0088 - learning_rate: 1.2500e-05\n",
      "Epoch 2571/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0080 - learning_rate: 1.2500e-05\n",
      "Epoch 2572/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0088 - learning_rate: 1.2500e-05\n",
      "Epoch 2573/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0084 - learning_rate: 1.2500e-05\n",
      "Epoch 2574/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0084 - learning_rate: 1.2500e-05\n",
      "Epoch 2575/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0102 - learning_rate: 1.2500e-05\n",
      "Epoch 2576/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0080 - learning_rate: 1.2500e-05\n",
      "Epoch 2577/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0071 - val_loss: 0.0085 - learning_rate: 1.2500e-05\n",
      "Epoch 2578/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0081 - learning_rate: 1.2500e-05\n",
      "Epoch 2579/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0081 - learning_rate: 1.2500e-05\n",
      "Epoch 2580/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0081 - learning_rate: 1.2500e-05\n",
      "Epoch 2581/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0081 - learning_rate: 1.2500e-05\n",
      "Epoch 2582/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0083 - learning_rate: 1.2500e-05\n",
      "Epoch 2583/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0077 - val_loss: 0.0081 - learning_rate: 1.2500e-05\n",
      "Epoch 2584/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0084 - learning_rate: 1.2500e-05\n",
      "Epoch 2585/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0081 - learning_rate: 1.2500e-05\n",
      "Epoch 2586/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0085 - learning_rate: 1.2500e-05\n",
      "Epoch 2587/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0081 - learning_rate: 1.2500e-05\n",
      "Epoch 2588/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0088 - learning_rate: 1.2500e-05\n",
      "Epoch 2589/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0082 - learning_rate: 1.2500e-05\n",
      "Epoch 2590/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0085 - learning_rate: 1.2500e-05\n",
      "Epoch 2591/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0085 - learning_rate: 1.2500e-05\n",
      "Epoch 2592/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0080 - learning_rate: 1.2500e-05\n",
      "Epoch 2593/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0080 - learning_rate: 1.2500e-05\n",
      "Epoch 2594/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0076 - val_loss: 0.0082 - learning_rate: 1.2500e-05\n",
      "Epoch 2595/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0073 - val_loss: 0.0082 - learning_rate: 1.2500e-05\n",
      "Epoch 2596/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0086 - learning_rate: 1.2500e-05\n",
      "Epoch 2597/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0085 - learning_rate: 1.2500e-05\n",
      "Epoch 2598/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0089 - learning_rate: 1.2500e-05\n",
      "Epoch 2599/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0089 - learning_rate: 1.2500e-05\n",
      "Epoch 2600/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0083 - learning_rate: 1.2500e-05\n",
      "Epoch 2601/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0084 - learning_rate: 1.2500e-05\n",
      "Epoch 2602/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0083 - learning_rate: 1.2500e-05\n",
      "Epoch 2603/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0084 - learning_rate: 1.2500e-05\n",
      "Epoch 2604/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0088 - learning_rate: 1.2500e-05\n",
      "Epoch 2605/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0094 - val_loss: 0.0087 - learning_rate: 1.2500e-05\n",
      "Epoch 2606/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0082 - learning_rate: 1.2500e-05\n",
      "Epoch 2607/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0085 - learning_rate: 1.2500e-05\n",
      "Epoch 2608/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0072 - val_loss: 0.0080 - learning_rate: 1.2500e-05\n",
      "Epoch 2609/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0091 - learning_rate: 1.2500e-05\n",
      "Epoch 2610/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0082 - val_loss: 0.0080 - learning_rate: 1.2500e-05\n",
      "Epoch 2611/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0074 - val_loss: 0.0085 - learning_rate: 1.2500e-05\n",
      "Epoch 2612/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0080 - learning_rate: 1.2500e-05\n",
      "Epoch 2613/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0084 - learning_rate: 1.2500e-05\n",
      "Epoch 2614/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0091 - learning_rate: 1.2500e-05\n",
      "Epoch 2615/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0079 - learning_rate: 1.2500e-05\n",
      "Epoch 2616/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0082 - learning_rate: 1.2500e-05\n",
      "Epoch 2617/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0070 - val_loss: 0.0094 - learning_rate: 1.2500e-05\n",
      "Epoch 2618/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0084 - learning_rate: 1.2500e-05\n",
      "Epoch 2619/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0082 - learning_rate: 1.2500e-05\n",
      "Epoch 2620/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0084 - learning_rate: 1.2500e-05\n",
      "Epoch 2621/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0085 - learning_rate: 1.2500e-05\n",
      "Epoch 2622/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0082 - learning_rate: 1.2500e-05\n",
      "Epoch 2623/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0082 - learning_rate: 1.2500e-05\n",
      "Epoch 2624/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0079 - learning_rate: 6.2500e-06\n",
      "Epoch 2625/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0068 - val_loss: 0.0079 - learning_rate: 6.2500e-06\n",
      "Epoch 2626/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0080 - learning_rate: 6.2500e-06\n",
      "Epoch 2627/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0082 - learning_rate: 6.2500e-06\n",
      "Epoch 2628/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0068 - val_loss: 0.0078 - learning_rate: 6.2500e-06\n",
      "Epoch 2629/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0079 - learning_rate: 6.2500e-06\n",
      "Epoch 2630/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0080 - learning_rate: 6.2500e-06\n",
      "Epoch 2631/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0080 - learning_rate: 6.2500e-06\n",
      "Epoch 2632/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0070 - val_loss: 0.0078 - learning_rate: 6.2500e-06\n",
      "Epoch 2633/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0079 - learning_rate: 6.2500e-06\n",
      "Epoch 2634/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0080 - learning_rate: 6.2500e-06\n",
      "Epoch 2635/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0079 - learning_rate: 6.2500e-06\n",
      "Epoch 2636/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0079 - learning_rate: 6.2500e-06\n",
      "Epoch 2637/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0079 - learning_rate: 6.2500e-06\n",
      "Epoch 2638/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0067 - val_loss: 0.0079 - learning_rate: 6.2500e-06\n",
      "Epoch 2639/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0081 - learning_rate: 6.2500e-06\n",
      "Epoch 2640/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0078 - learning_rate: 6.2500e-06\n",
      "Epoch 2641/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0080 - learning_rate: 6.2500e-06\n",
      "Epoch 2642/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0078 - learning_rate: 6.2500e-06\n",
      "Epoch 2643/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0078 - learning_rate: 6.2500e-06\n",
      "Epoch 2644/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0078 - learning_rate: 6.2500e-06\n",
      "Epoch 2645/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0080 - learning_rate: 6.2500e-06\n",
      "Epoch 2646/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0084 - learning_rate: 6.2500e-06\n",
      "Epoch 2647/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0080 - learning_rate: 6.2500e-06\n",
      "Epoch 2648/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0079 - learning_rate: 6.2500e-06\n",
      "Epoch 2649/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0079 - learning_rate: 6.2500e-06\n",
      "Epoch 2650/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0081 - learning_rate: 6.2500e-06\n",
      "Epoch 2651/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0080 - learning_rate: 6.2500e-06\n",
      "Epoch 2652/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0080 - learning_rate: 6.2500e-06\n",
      "Epoch 2653/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0082 - learning_rate: 6.2500e-06\n",
      "Epoch 2654/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0079 - learning_rate: 6.2500e-06\n",
      "Epoch 2655/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0081 - learning_rate: 6.2500e-06\n",
      "Epoch 2656/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0073 - val_loss: 0.0078 - learning_rate: 6.2500e-06\n",
      "Epoch 2657/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0079 - learning_rate: 6.2500e-06\n",
      "Epoch 2658/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0078 - learning_rate: 6.2500e-06\n",
      "Epoch 2659/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0079 - learning_rate: 6.2500e-06\n",
      "Epoch 2660/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0094 - learning_rate: 6.2500e-06\n",
      "Epoch 2661/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0080 - learning_rate: 6.2500e-06\n",
      "Epoch 2662/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0079 - learning_rate: 6.2500e-06\n",
      "Epoch 2663/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0084 - learning_rate: 6.2500e-06\n",
      "Epoch 2664/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0080 - learning_rate: 6.2500e-06\n",
      "Epoch 2665/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0078 - learning_rate: 6.2500e-06\n",
      "Epoch 2666/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0080 - learning_rate: 6.2500e-06\n",
      "Epoch 2667/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0082 - learning_rate: 6.2500e-06\n",
      "Epoch 2668/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0080 - learning_rate: 6.2500e-06\n",
      "Epoch 2669/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0082 - learning_rate: 6.2500e-06\n",
      "Epoch 2670/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0075 - val_loss: 0.0083 - learning_rate: 6.2500e-06\n",
      "Epoch 2671/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0087 - learning_rate: 6.2500e-06\n",
      "Epoch 2672/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0082 - learning_rate: 6.2500e-06\n",
      "Epoch 2673/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0084 - learning_rate: 6.2500e-06\n",
      "Epoch 2674/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0081 - learning_rate: 6.2500e-06\n",
      "Epoch 2675/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0080 - learning_rate: 6.2500e-06\n",
      "Epoch 2676/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0082 - learning_rate: 6.2500e-06\n",
      "Epoch 2677/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0084 - learning_rate: 6.2500e-06\n",
      "Epoch 2678/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0080 - learning_rate: 6.2500e-06\n",
      "Epoch 2679/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0079 - learning_rate: 6.2500e-06\n",
      "Epoch 2680/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0079 - learning_rate: 6.2500e-06\n",
      "Epoch 2681/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0079 - learning_rate: 6.2500e-06\n",
      "Epoch 2682/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0082 - learning_rate: 6.2500e-06\n",
      "Epoch 2683/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0080 - learning_rate: 6.2500e-06\n",
      "Epoch 2684/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0075 - val_loss: 0.0080 - learning_rate: 6.2500e-06\n",
      "Epoch 2685/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0082 - learning_rate: 6.2500e-06\n",
      "Epoch 2686/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0081 - learning_rate: 6.2500e-06\n",
      "Epoch 2687/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0074 - val_loss: 0.0080 - learning_rate: 6.2500e-06\n",
      "Epoch 2688/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0080 - learning_rate: 6.2500e-06\n",
      "Epoch 2689/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0079 - learning_rate: 6.2500e-06\n",
      "Epoch 2690/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0084 - learning_rate: 6.2500e-06\n",
      "Epoch 2691/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0068 - val_loss: 0.0079 - learning_rate: 6.2500e-06\n",
      "Epoch 2692/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0078 - learning_rate: 6.2500e-06\n",
      "Epoch 2693/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0083 - learning_rate: 6.2500e-06\n",
      "Epoch 2694/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0078 - learning_rate: 6.2500e-06\n",
      "Epoch 2695/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0082 - learning_rate: 6.2500e-06\n",
      "Epoch 2696/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0080 - val_loss: 0.0080 - learning_rate: 6.2500e-06\n",
      "Epoch 2697/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0085 - learning_rate: 6.2500e-06\n",
      "Epoch 2698/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0068 - val_loss: 0.0079 - learning_rate: 6.2500e-06\n",
      "Epoch 2699/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0079 - learning_rate: 6.2500e-06\n",
      "Epoch 2700/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0075 - val_loss: 0.0078 - learning_rate: 6.2500e-06\n",
      "Epoch 2701/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0072 - val_loss: 0.0079 - learning_rate: 6.2500e-06\n",
      "Epoch 2702/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0073 - val_loss: 0.0081 - learning_rate: 6.2500e-06\n",
      "Epoch 2703/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0070 - val_loss: 0.0079 - learning_rate: 6.2500e-06\n",
      "Epoch 2704/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0067 - val_loss: 0.0080 - learning_rate: 6.2500e-06\n",
      "Epoch 2705/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0069 - val_loss: 0.0079 - learning_rate: 6.2500e-06\n",
      "Epoch 2706/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0074 - val_loss: 0.0082 - learning_rate: 6.2500e-06\n",
      "Epoch 2707/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0069 - val_loss: 0.0080 - learning_rate: 6.2500e-06\n",
      "Epoch 2708/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0077 - val_loss: 0.0084 - learning_rate: 6.2500e-06\n",
      "Epoch 2709/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0071 - val_loss: 0.0079 - learning_rate: 6.2500e-06\n",
      "Epoch 2710/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0078 - learning_rate: 6.2500e-06\n",
      "Epoch 2711/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0082 - learning_rate: 6.2500e-06\n",
      "Epoch 2712/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0082 - learning_rate: 6.2500e-06\n",
      "Epoch 2713/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0069 - val_loss: 0.0081 - learning_rate: 6.2500e-06\n",
      "Epoch 2714/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0083 - learning_rate: 6.2500e-06\n",
      "Epoch 2715/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0067 - val_loss: 0.0088 - learning_rate: 6.2500e-06\n",
      "Epoch 2716/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0078 - val_loss: 0.0080 - learning_rate: 6.2500e-06\n",
      "Epoch 2717/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0075 - val_loss: 0.0079 - learning_rate: 6.2500e-06\n",
      "Epoch 2718/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0069 - val_loss: 0.0079 - learning_rate: 6.2500e-06\n",
      "Epoch 2719/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0069 - val_loss: 0.0081 - learning_rate: 6.2500e-06\n",
      "Epoch 2720/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0068 - val_loss: 0.0080 - learning_rate: 6.2500e-06\n",
      "Epoch 2721/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0068 - val_loss: 0.0079 - learning_rate: 6.2500e-06\n",
      "Epoch 2722/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0076 - val_loss: 0.0081 - learning_rate: 6.2500e-06\n",
      "Epoch 2723/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0077 - val_loss: 0.0079 - learning_rate: 6.2500e-06\n",
      "Epoch 2724/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0068 - val_loss: 0.0083 - learning_rate: 6.2500e-06\n",
      "Epoch 2725/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0081 - learning_rate: 6.2500e-06\n",
      "Epoch 2726/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0079 - learning_rate: 6.2500e-06\n",
      "Epoch 2727/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0078 - learning_rate: 6.2500e-06\n",
      "Epoch 2728/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0081 - learning_rate: 6.2500e-06\n",
      "Epoch 2729/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0080 - learning_rate: 6.2500e-06\n",
      "Epoch 2730/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0071 - val_loss: 0.0078 - learning_rate: 6.2500e-06\n",
      "Epoch 2731/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0083 - learning_rate: 6.2500e-06\n",
      "Epoch 2732/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0082 - learning_rate: 6.2500e-06\n",
      "Epoch 2733/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0080 - learning_rate: 6.2500e-06\n",
      "Epoch 2734/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0078 - learning_rate: 6.2500e-06\n",
      "Epoch 2735/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0079 - learning_rate: 6.2500e-06\n",
      "Epoch 2736/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0079 - learning_rate: 6.2500e-06\n",
      "Epoch 2737/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0086 - learning_rate: 6.2500e-06\n",
      "Epoch 2738/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0071 - val_loss: 0.0083 - learning_rate: 6.2500e-06\n",
      "Epoch 2739/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0071 - val_loss: 0.0081 - learning_rate: 6.2500e-06\n",
      "Epoch 2740/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0079 - learning_rate: 6.2500e-06\n",
      "Epoch 2741/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0080 - learning_rate: 6.2500e-06\n",
      "Epoch 2742/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0079 - learning_rate: 6.2500e-06\n",
      "Epoch 2743/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0070 - val_loss: 0.0078 - learning_rate: 6.2500e-06\n",
      "Epoch 2744/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0079 - learning_rate: 6.2500e-06\n",
      "Epoch 2745/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0073 - val_loss: 0.0081 - learning_rate: 6.2500e-06\n",
      "Epoch 2746/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0082 - learning_rate: 6.2500e-06\n",
      "Epoch 2747/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0079 - learning_rate: 6.2500e-06\n",
      "Epoch 2748/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0078 - learning_rate: 6.2500e-06\n",
      "Epoch 2749/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0082 - learning_rate: 6.2500e-06\n",
      "Epoch 2750/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0080 - learning_rate: 6.2500e-06\n",
      "Epoch 2751/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0078 - learning_rate: 6.2500e-06\n",
      "Epoch 2752/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0079 - learning_rate: 6.2500e-06\n",
      "Epoch 2753/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0068 - val_loss: 0.0079 - learning_rate: 6.2500e-06\n",
      "Epoch 2754/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0100 - learning_rate: 6.2500e-06\n",
      "Epoch 2755/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0075 - val_loss: 0.0081 - learning_rate: 6.2500e-06\n",
      "Epoch 2756/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0080 - learning_rate: 6.2500e-06\n",
      "Epoch 2757/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0082 - learning_rate: 6.2500e-06\n",
      "Epoch 2758/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0082 - learning_rate: 6.2500e-06\n",
      "Epoch 2759/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0068 - val_loss: 0.0080 - learning_rate: 6.2500e-06\n",
      "Epoch 2760/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0073 - val_loss: 0.0079 - learning_rate: 6.2500e-06\n",
      "Epoch 2761/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0078 - learning_rate: 6.2500e-06\n",
      "Epoch 2762/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0079 - learning_rate: 6.2500e-06\n",
      "Epoch 2763/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0082 - learning_rate: 6.2500e-06\n",
      "Epoch 2764/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0083 - learning_rate: 6.2500e-06\n",
      "Epoch 2765/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0081 - learning_rate: 6.2500e-06\n",
      "Epoch 2766/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0080 - learning_rate: 6.2500e-06\n",
      "Epoch 2767/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0080 - learning_rate: 6.2500e-06\n",
      "Epoch 2768/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0084 - learning_rate: 6.2500e-06\n",
      "Epoch 2769/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0072 - val_loss: 0.0079 - learning_rate: 6.2500e-06\n",
      "Epoch 2770/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0085 - learning_rate: 6.2500e-06\n",
      "Epoch 2771/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0081 - learning_rate: 6.2500e-06\n",
      "Epoch 2772/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0079 - learning_rate: 6.2500e-06\n",
      "Epoch 2773/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0090 - learning_rate: 6.2500e-06\n",
      "Epoch 2774/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0083 - val_loss: 0.0080 - learning_rate: 6.2500e-06\n",
      "Epoch 2775/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0080 - learning_rate: 6.2500e-06\n",
      "Epoch 2776/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0077 - val_loss: 0.0089 - learning_rate: 6.2500e-06\n",
      "Epoch 2777/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0082 - learning_rate: 6.2500e-06\n",
      "Epoch 2778/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0081 - learning_rate: 6.2500e-06\n",
      "Epoch 2779/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0084 - learning_rate: 6.2500e-06\n",
      "Epoch 2780/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0074 - val_loss: 0.0084 - learning_rate: 6.2500e-06\n",
      "Epoch 2781/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0071 - val_loss: 0.0079 - learning_rate: 6.2500e-06\n",
      "Epoch 2782/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0081 - learning_rate: 6.2500e-06\n",
      "Epoch 2783/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0081 - learning_rate: 6.2500e-06\n",
      "Epoch 2784/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0082 - learning_rate: 6.2500e-06\n",
      "Epoch 2785/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0088 - learning_rate: 6.2500e-06\n",
      "Epoch 2786/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0084 - learning_rate: 6.2500e-06\n",
      "Epoch 2787/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0080 - learning_rate: 6.2500e-06\n",
      "Epoch 2788/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0079 - learning_rate: 6.2500e-06\n",
      "Epoch 2789/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0083 - learning_rate: 6.2500e-06\n",
      "Epoch 2790/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0081 - learning_rate: 6.2500e-06\n",
      "Epoch 2791/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0080 - learning_rate: 6.2500e-06\n",
      "Epoch 2792/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0071 - val_loss: 0.0078 - learning_rate: 6.2500e-06\n",
      "Epoch 2793/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0086 - learning_rate: 6.2500e-06\n",
      "Epoch 2794/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0079 - learning_rate: 6.2500e-06\n",
      "Epoch 2795/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0080 - learning_rate: 6.2500e-06\n",
      "Epoch 2796/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0081 - learning_rate: 6.2500e-06\n",
      "Epoch 2797/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0066 - val_loss: 0.0081 - learning_rate: 6.2500e-06\n",
      "Epoch 2798/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0079 - learning_rate: 6.2500e-06\n",
      "Epoch 2799/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0079 - learning_rate: 6.2500e-06\n",
      "Epoch 2800/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0082 - learning_rate: 6.2500e-06\n",
      "Epoch 2801/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0081 - learning_rate: 6.2500e-06\n",
      "Epoch 2802/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0081 - learning_rate: 6.2500e-06\n",
      "Epoch 2803/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0073 - val_loss: 0.0079 - learning_rate: 6.2500e-06\n",
      "Epoch 2804/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0079 - learning_rate: 6.2500e-06\n",
      "Epoch 2805/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0083 - learning_rate: 6.2500e-06\n",
      "Epoch 2806/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0082 - learning_rate: 6.2500e-06\n",
      "Epoch 2807/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0081 - learning_rate: 6.2500e-06\n",
      "Epoch 2808/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0079 - learning_rate: 6.2500e-06\n",
      "Epoch 2809/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0078 - learning_rate: 6.2500e-06\n",
      "Epoch 2810/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0079 - learning_rate: 6.2500e-06\n",
      "Epoch 2811/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0080 - learning_rate: 6.2500e-06\n",
      "Epoch 2812/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0083 - learning_rate: 6.2500e-06\n",
      "Epoch 2813/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0077 - val_loss: 0.0079 - learning_rate: 6.2500e-06\n",
      "Epoch 2814/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0081 - learning_rate: 6.2500e-06\n",
      "Epoch 2815/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0083 - learning_rate: 6.2500e-06\n",
      "Epoch 2816/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0067 - val_loss: 0.0079 - learning_rate: 6.2500e-06\n",
      "Epoch 2817/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0082 - learning_rate: 6.2500e-06\n",
      "Epoch 2818/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0079 - learning_rate: 6.2500e-06\n",
      "Epoch 2819/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0084 - learning_rate: 6.2500e-06\n",
      "Epoch 2820/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0080 - learning_rate: 6.2500e-06\n",
      "Epoch 2821/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0082 - learning_rate: 6.2500e-06\n",
      "Epoch 2822/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0092 - learning_rate: 6.2500e-06\n",
      "Epoch 2823/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0090 - learning_rate: 6.2500e-06\n",
      "Epoch 2824/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0085 - learning_rate: 6.2500e-06\n",
      "Epoch 2825/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0081 - learning_rate: 6.2500e-06\n",
      "Epoch 2826/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0082 - learning_rate: 6.2500e-06\n",
      "Epoch 2827/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0082 - learning_rate: 6.2500e-06\n",
      "Epoch 2828/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0081 - learning_rate: 6.2500e-06\n",
      "Epoch 2829/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0072 - val_loss: 0.0081 - learning_rate: 6.2500e-06\n",
      "Epoch 2830/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0072 - val_loss: 0.0083 - learning_rate: 6.2500e-06\n",
      "Epoch 2831/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0083 - learning_rate: 6.2500e-06\n",
      "Epoch 2832/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0079 - learning_rate: 6.2500e-06\n",
      "Epoch 2833/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0080 - learning_rate: 6.2500e-06\n",
      "Epoch 2834/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0083 - learning_rate: 6.2500e-06\n",
      "Epoch 2835/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0078 - learning_rate: 6.2500e-06\n",
      "Epoch 2836/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0080 - learning_rate: 6.2500e-06\n",
      "Epoch 2837/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0087 - learning_rate: 6.2500e-06\n",
      "Epoch 2838/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0079 - learning_rate: 6.2500e-06\n",
      "Epoch 2839/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0078 - learning_rate: 6.2500e-06\n",
      "Epoch 2840/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0078 - learning_rate: 6.2500e-06\n",
      "Epoch 2841/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0090 - learning_rate: 6.2500e-06\n",
      "Epoch 2842/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0082 - learning_rate: 6.2500e-06\n",
      "Epoch 2843/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0069 - val_loss: 0.0080 - learning_rate: 6.2500e-06\n",
      "Epoch 2844/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0079 - learning_rate: 6.2500e-06\n",
      "Epoch 2845/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0081 - learning_rate: 6.2500e-06\n",
      "Epoch 2846/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0070 - val_loss: 0.0084 - learning_rate: 6.2500e-06\n",
      "Epoch 2847/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0082 - val_loss: 0.0086 - learning_rate: 6.2500e-06\n",
      "Epoch 2848/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0080 - learning_rate: 6.2500e-06\n",
      "Epoch 2849/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0073 - val_loss: 0.0079 - learning_rate: 6.2500e-06\n",
      "Epoch 2850/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0079 - learning_rate: 6.2500e-06\n",
      "Epoch 2851/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0078 - learning_rate: 6.2500e-06\n",
      "Epoch 2852/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0078 - learning_rate: 6.2500e-06\n",
      "Epoch 2853/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0083 - learning_rate: 6.2500e-06\n",
      "Epoch 2854/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0088 - learning_rate: 6.2500e-06\n",
      "Epoch 2855/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0080 - learning_rate: 6.2500e-06\n",
      "Epoch 2856/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0081 - learning_rate: 6.2500e-06\n",
      "Epoch 2857/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0080 - learning_rate: 6.2500e-06\n",
      "Epoch 2858/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0091 - learning_rate: 6.2500e-06\n",
      "Epoch 2859/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0085 - learning_rate: 6.2500e-06\n",
      "Epoch 2860/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0081 - learning_rate: 6.2500e-06\n",
      "Epoch 2861/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0080 - learning_rate: 6.2500e-06\n",
      "Epoch 2862/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0067 - val_loss: 0.0079 - learning_rate: 6.2500e-06\n",
      "Epoch 2863/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0080 - learning_rate: 6.2500e-06\n",
      "Epoch 2864/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0078 - learning_rate: 6.2500e-06\n",
      "Epoch 2865/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0076 - val_loss: 0.0081 - learning_rate: 6.2500e-06\n",
      "Epoch 2866/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0082 - learning_rate: 6.2500e-06\n",
      "Epoch 2867/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0070 - val_loss: 0.0079 - learning_rate: 6.2500e-06\n",
      "Epoch 2868/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0080 - learning_rate: 6.2500e-06\n",
      "Epoch 2869/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0079 - learning_rate: 6.2500e-06\n",
      "Epoch 2870/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0078 - learning_rate: 6.2500e-06\n",
      "Epoch 2871/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0074 - val_loss: 0.0087 - learning_rate: 6.2500e-06\n",
      "Epoch 2872/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0080 - learning_rate: 6.2500e-06\n",
      "Epoch 2873/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0071 - val_loss: 0.0080 - learning_rate: 6.2500e-06\n",
      "Epoch 2874/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0078 - learning_rate: 6.2500e-06\n",
      "Epoch 2875/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0085 - learning_rate: 6.2500e-06\n",
      "Epoch 2876/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0084 - learning_rate: 6.2500e-06\n",
      "Epoch 2877/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0089 - learning_rate: 6.2500e-06\n",
      "Epoch 2878/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0071 - val_loss: 0.0080 - learning_rate: 6.2500e-06\n",
      "Epoch 2879/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0079 - learning_rate: 6.2500e-06\n",
      "Epoch 2880/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0081 - learning_rate: 6.2500e-06\n",
      "Epoch 2881/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0080 - learning_rate: 6.2500e-06\n",
      "Epoch 2882/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0073 - val_loss: 0.0081 - learning_rate: 6.2500e-06\n",
      "Epoch 2883/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0078 - learning_rate: 6.2500e-06\n",
      "Epoch 2884/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0072 - val_loss: 0.0079 - learning_rate: 6.2500e-06\n",
      "Epoch 2885/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0079 - learning_rate: 6.2500e-06\n",
      "Epoch 2886/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0078 - learning_rate: 6.2500e-06\n",
      "Epoch 2887/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0082 - learning_rate: 6.2500e-06\n",
      "Epoch 2888/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0069 - val_loss: 0.0083 - learning_rate: 6.2500e-06\n",
      "Epoch 2889/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0079 - learning_rate: 6.2500e-06\n",
      "Epoch 2890/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0084 - learning_rate: 6.2500e-06\n",
      "Epoch 2891/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0070 - val_loss: 0.0081 - learning_rate: 6.2500e-06\n",
      "Epoch 2892/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0082 - learning_rate: 6.2500e-06\n",
      "Epoch 2893/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0080 - learning_rate: 6.2500e-06\n",
      "Epoch 2894/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0082 - learning_rate: 6.2500e-06\n",
      "Epoch 2895/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0073 - val_loss: 0.0079 - learning_rate: 6.2500e-06\n",
      "Epoch 2896/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0071 - val_loss: 0.0081 - learning_rate: 6.2500e-06\n",
      "Epoch 2897/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0084 - learning_rate: 6.2500e-06\n",
      "Epoch 2898/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0079 - learning_rate: 6.2500e-06\n",
      "Epoch 2899/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0078 - learning_rate: 6.2500e-06\n",
      "Epoch 2900/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0078 - learning_rate: 6.2500e-06\n",
      "Epoch 2901/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0078 - learning_rate: 6.2500e-06\n",
      "Epoch 2902/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0078 - learning_rate: 6.2500e-06\n",
      "Epoch 2903/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0066 - val_loss: 0.0080 - learning_rate: 6.2500e-06\n",
      "Epoch 2904/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0079 - learning_rate: 6.2500e-06\n",
      "Epoch 2905/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0078 - learning_rate: 6.2500e-06\n",
      "Epoch 2906/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0080 - learning_rate: 6.2500e-06\n",
      "Epoch 2907/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0080 - learning_rate: 6.2500e-06\n",
      "Epoch 2908/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0088 - learning_rate: 6.2500e-06\n",
      "Epoch 2909/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0082 - learning_rate: 6.2500e-06\n",
      "Epoch 2910/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0086 - learning_rate: 6.2500e-06\n",
      "Epoch 2911/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0074 - val_loss: 0.0078 - learning_rate: 6.2500e-06\n",
      "Epoch 2912/10000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0079 - learning_rate: 6.2500e-06\n",
      "Epoch 2913/10000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 52\u001b[0m\n\u001b[1;32m     48\u001b[0m X_test_combined \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate((X_test, coarse_y_test), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m model_adj_NN\u001b[38;5;241m.\u001b[39mfit(X_train_combined, y_train, epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10000\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39m (X_test_combined, y_test), callbacks\u001b[38;5;241m=\u001b[39mlearning_rate_scheduler)\n\u001b[1;32m     54\u001b[0m model_adj_NN\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./models/model_adj_NN.keras\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/bima/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/bima/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:325\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    324\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 325\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[1;32m    326\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(\n\u001b[1;32m    327\u001b[0m         step, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    328\u001b[0m     )\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/miniconda3/envs/bima/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/bima/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/bima/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    879\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[1;32m    880\u001b[0m )\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/bima/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:132\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    130\u001b[0m args \u001b[38;5;241m=\u001b[39m args \u001b[38;5;28;01mif\u001b[39;00m args \u001b[38;5;28;01melse\u001b[39;00m ()\n\u001b[1;32m    131\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m kwargs \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m--> 132\u001b[0m function \u001b[38;5;241m=\u001b[39m trace_function(\n\u001b[1;32m    133\u001b[0m     args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs, tracing_options\u001b[38;5;241m=\u001b[39mtracing_options\n\u001b[1;32m    134\u001b[0m )\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# Bind it ourselves to skip unnecessary canonicalization of default call.\u001b[39;00m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/bima/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:178\u001b[0m, in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    175\u001b[0m     args \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[1;32m    176\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 178\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m _maybe_define_function(\n\u001b[1;32m    179\u001b[0m       args, kwargs, tracing_options\n\u001b[1;32m    180\u001b[0m   )\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mbind_graph_to_function:\n\u001b[1;32m    183\u001b[0m   concrete_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/bima/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:205\u001b[0m, in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_maybe_define_function\u001b[39m(args, kwargs, tracing_options):\n\u001b[1;32m    189\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Gets a function for these inputs, defining it if necessary.\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \n\u001b[1;32m    191\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;124;03m      shape relaxation retracing.\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 205\u001b[0m   bound_args \u001b[38;5;241m=\u001b[39m function_type_utils\u001b[38;5;241m.\u001b[39mcanonicalize_function_inputs(\n\u001b[1;32m    206\u001b[0m       args,\n\u001b[1;32m    207\u001b[0m       kwargs,\n\u001b[1;32m    208\u001b[0m       tracing_options\u001b[38;5;241m.\u001b[39mpolymorphic_type,\n\u001b[1;32m    209\u001b[0m       tracing_options\u001b[38;5;241m.\u001b[39mdefault_values,\n\u001b[1;32m    210\u001b[0m       tracing_options\u001b[38;5;241m.\u001b[39mis_pure,\n\u001b[1;32m    211\u001b[0m   )\n\u001b[1;32m    212\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m bound_args\u001b[38;5;241m.\u001b[39margs, bound_args\u001b[38;5;241m.\u001b[39mkwargs\n\u001b[1;32m    214\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39minput_signature \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/bima/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/function_type_utils.py:422\u001b[0m, in \u001b[0;36mcanonicalize_function_inputs\u001b[0;34m(args, kwargs, function_type, default_values, is_pure)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_pure:\n\u001b[1;32m    421\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m _convert_variables_to_tensors(args, kwargs)\n\u001b[0;32m--> 422\u001b[0m bound_arguments \u001b[38;5;241m=\u001b[39m bind_function_inputs(\n\u001b[1;32m    423\u001b[0m     args, kwargs, function_type, default_values\n\u001b[1;32m    424\u001b[0m )\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m bound_arguments\n",
      "File \u001b[0;32m~/miniconda3/envs/bima/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/function_type_utils.py:442\u001b[0m, in \u001b[0;36mbind_function_inputs\u001b[0;34m(args, kwargs, function_type, default_values)\u001b[0m\n\u001b[1;32m    434\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    435\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mName collision after sanitization. Please rename \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    436\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.function input parameters. Original: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    437\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msorted\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Sanitized: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    438\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msorted\u001b[39m(sanitized_kwargs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    439\u001b[0m   )\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 442\u001b[0m   bound_arguments \u001b[38;5;241m=\u001b[39m function_type\u001b[38;5;241m.\u001b[39mbind_with_defaults(\n\u001b[1;32m    443\u001b[0m       args, sanitized_kwargs, default_values\n\u001b[1;32m    444\u001b[0m   )\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    447\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBinding inputs to tf.function failed due to `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    448\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived args: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and kwargs: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msanitized_kwargs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for signature:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    449\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunction_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    450\u001b[0m   ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/bima/lib/python3.11/site-packages/tensorflow/core/function/polymorphism/function_type.py:264\u001b[0m, in \u001b[0;36mFunctionType.bind_with_defaults\u001b[0;34m(self, args, kwargs, default_values)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbind_with_defaults\u001b[39m(\u001b[38;5;28mself\u001b[39m, args, kwargs, default_values):\n\u001b[1;32m    263\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns BoundArguments with default values filled in.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 264\u001b[0m   bound_arguments \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    265\u001b[0m   bound_arguments\u001b[38;5;241m.\u001b[39mapply_defaults()\n\u001b[1;32m    267\u001b[0m   with_default_args \u001b[38;5;241m=\u001b[39m collections\u001b[38;5;241m.\u001b[39mOrderedDict()\n",
      "File \u001b[0;32m~/miniconda3/envs/bima/lib/python3.11/inspect.py:3212\u001b[0m, in \u001b[0;36mSignature.bind\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3207\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbind\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   3208\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get a BoundArguments object, that maps the passed `args`\u001b[39;00m\n\u001b[1;32m   3209\u001b[0m \u001b[38;5;124;03m    and `kwargs` to the function's signature.  Raises `TypeError`\u001b[39;00m\n\u001b[1;32m   3210\u001b[0m \u001b[38;5;124;03m    if the passed arguments can not be bound.\u001b[39;00m\n\u001b[1;32m   3211\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3212\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bind(args, kwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/bima/lib/python3.11/inspect.py:3160\u001b[0m, in \u001b[0;36mSignature._bind\u001b[0;34m(self, args, kwargs, partial)\u001b[0m\n\u001b[1;32m   3157\u001b[0m \u001b[38;5;66;03m# Now, we iterate through the remaining parameters to process\u001b[39;00m\n\u001b[1;32m   3158\u001b[0m \u001b[38;5;66;03m# keyword arguments\u001b[39;00m\n\u001b[1;32m   3159\u001b[0m kwargs_param \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 3160\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(parameters_ex, parameters):\n\u001b[1;32m   3161\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m param\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m _VAR_KEYWORD:\n\u001b[1;32m   3162\u001b[0m         \u001b[38;5;66;03m# Memorize that we have a '**kwargs'-like parameter\u001b[39;00m\n\u001b[1;32m   3163\u001b[0m         kwargs_param \u001b[38;5;241m=\u001b[39m param\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Training = False\n",
    "\n",
    "num_samples = 640\n",
    "num_parameters = 3\n",
    "num_coarse_values = 150\n",
    "\n",
    "# Define the initial weighsts matrix \n",
    "weight_matrix = [ np.vstack([np.zeros((3,150)), np.eye(150)] ),  np.zeros(150) ]\n",
    "#weight_matrix = [ np.vstack([w0,w1,w2, np.eye(150)] ),  np.zeros(150) ]\n",
    "\n",
    "# Define the neural network model\n",
    "model_adj_NN = Sequential([\n",
    "        Dense(150, input_shape=(num_parameters + num_coarse_values,),activation='linear')\n",
    "       ])\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "    # Calculate loss for the coarse solution\n",
    "    coarse_loss = tf.reduce_mean(tf.square(y_pred - y_true))\n",
    "    \n",
    "    # Add regularization term to penalize changes in the weights of the coarse solution\n",
    "    regularization_loss = tf.reduce_mean(tf.square(model_adj_NN.layers[0].weights[0][3:] - np.eye(150)))\n",
    "    \n",
    "    # Total loss\n",
    "    total_loss = coarse_loss + regularization_loss*1e5\n",
    "    return total_loss\n",
    "\n",
    "# Set the initial weights for the dense layer\n",
    "model_adj_NN.layers[0].set_weights(weight_matrix)\n",
    "\n",
    "weight_to_freeze = np.vstack( (  np.ones((3,150)), np.zeros((150,150))  )  ).astype(int)\n",
    "#model_adj_NN.layers[0].trainable_weights[0][weight_to_freeze] = 0  # Set the weights to fix to zero\n",
    "#print(model_adj_NN.layers[0].trainable_weights[0][3:])\n",
    "\n",
    "if Training: \n",
    "       \n",
    "       # Define the optimizer with an initial learning rate\n",
    "       initial_learning_rate = 1e-4\n",
    "       optimizer = Adam(learning_rate=initial_learning_rate) \n",
    "\n",
    "       # Compile the model with the optimizer\n",
    "       model_adj_NN.compile(optimizer=optimizer, loss= custom_loss) #'mean_squared_error')\n",
    "\n",
    "       # Define a learning rate scheduler\n",
    "       learning_rate_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=500, min_lr=1e-6)\n",
    "\n",
    "       # Concatenate input parameters and coarse solutions\n",
    "       X_train_combined = np.concatenate((X_train, coarse_y_train), axis=1)\n",
    "       X_test_combined = np.concatenate((X_test, coarse_y_test), axis=1)\n",
    "    \n",
    "\n",
    "       # Train the model\n",
    "       model_adj_NN.fit(X_train_combined, y_train, epochs = 10000, batch_size=32, validation_data= (X_test_combined, y_test), callbacks=learning_rate_scheduler)\n",
    "\n",
    "       model_adj_NN.save('./models/model_adj_NN.keras')\n",
    "\n",
    "\n",
    "# Load the model\n",
    "#model_adj_NN = load_model('./models/model_adj_NN.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(54,), dtype=float32, numpy=\n",
       "array([-0.21902496, -0.16362718, -0.11842529, -0.0839361 , -0.05877977,\n",
       "       -0.04311477, -0.0356038 , -0.0343717 , -0.04091887, -0.0441989 ,\n",
       "       -0.05398948, -0.06047267, -0.070446  , -0.07894647, -0.08656528,\n",
       "       -0.09359398, -0.09992059, -0.10565532, -0.10747549, -0.10939648,\n",
       "       -0.11117665, -0.10993127, -0.10891264, -0.10737673, -0.10464664,\n",
       "       -0.10177431, -0.09841612, -0.09430341, -0.09072948, -0.08698898,\n",
       "       -0.08338045, -0.08009314, -0.07784703, -0.07413474, -0.07164513,\n",
       "       -0.07049834, -0.06917841, -0.06577135, -0.06452557, -0.06314325,\n",
       "       -0.06243589, -0.06056603, -0.06046208, -0.05954407, -0.05914033,\n",
       "       -0.05995621, -0.05923726, -0.05893051, -0.05853039, -0.05816014,\n",
       "       -0.0574123 , -0.05714226, -0.0570005 , -0.0569686 ], dtype=float32)>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_adj_NN.layers[0].weights[0][0][96:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Coarse and Fine model \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load fine model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and load model\n",
    "model_I = NN_Model()\n",
    "model_I.load_model(data_processor_I.config['MODEL_PATH'])\n",
    "\n",
    "# Define forward function\n",
    "forward_model = create_forward_model_function(data_processor_I, model_I)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare fine and coarse model on the paramters x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Coarse 1.0266109160002088\n",
      "Time fine 38.71975554199889\n"
     ]
    }
   ],
   "source": [
    "# Define parameters x\n",
    "X = np.random.uniform(np.array([0.1, -0.5, 29.0]), np.array([0.5, 0.5, 31.0]), size=[1000,3])\n",
    "# RMB: lower_bound= [0.1, -0.5, 29.0],  upper_bound=[0.5, 0.5, 31.0]\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "res_coarse = [coarse_model_adj(X[i,:]) for i in range(1000)]  \n",
    "end_time = timeit.default_timer()\n",
    "\n",
    "res_fine = [forward_model(X[i,:]) for i in range(1000)] \n",
    "end_time2 = timeit.default_timer()\n",
    "\n",
    "print('Time Coarse', end_time-start_time)\n",
    "print('Time fine', end_time2-end_time)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bima",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
