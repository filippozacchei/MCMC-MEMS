{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze the TIME / ESS distribution \n",
    "\n",
    "Randomly choose 25 samples and evaluate the model's Time / ESS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-22 15:41:13.373514: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ray module not found. Multiprocessing features are not available\n"
     ]
    }
   ],
   "source": [
    "# Standard library imports\n",
    "import sys\n",
    "\n",
    "import os\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = '1'\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "\n",
    "# Third-party library imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gaussian_kde\n",
    "import arviz as az\n",
    "import timeit\n",
    "\n",
    "import scipy.stats as stats\n",
    "from keras.models import Model as Model_nn\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Concatenate\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.layers import Input, Dense, Add\n",
    "\n",
    "#Try with TinyDA\n",
    "import tinyDA as tda\n",
    "from scipy.stats import multivariate_normal\n",
    "from scipy.stats import uniform\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "# Local module imports\n",
    "sys.path.append('../../')\n",
    "sys.path.append('../../solver')\n",
    "#sys.path.append('./src/InverseProblems')\n",
    "#sys.path.append('./src/utils')\n",
    "from utils import * \n",
    "from plotting import *\n",
    "from random_process import *\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose the 25 random samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([57, 32, 55, 69,  3])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 25 \n",
    "np.random.seed(2109)\n",
    "random_samples = np.random.randint(0, 160, n)\n",
    "random_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data and surrogate model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract test data for visualization or further processing\n",
    "n_eig = 64\n",
    "X_values = np.loadtxt('../../data/50-25-10/X_test_50resolution.csv', delimiter = ',')\n",
    "y_values = np.loadtxt('../../data/50-25-10/y_test_50resolution.csv',delimiter = ',')\n",
    "\n",
    "# Set the resolution of the model and the random field parameters.\n",
    "resolution = (50, 50)\n",
    "field_mean = 1\n",
    "field_stdev = 1\n",
    "lamb_cov = 0.1\n",
    "mkl_fine = 64\n",
    "\n",
    "model_fine = Model(resolution, field_mean, field_stdev, mkl_fine, lamb_cov)\n",
    "\n",
    "# Define the sampling points.\n",
    "x_data = y_data = np.array([0.1, 0.3, 0.5, 0.7, 0.9])\n",
    "datapoints = np.array(list(product(x_data, y_data)))\n",
    "\n",
    "\n",
    "def model_hf(x):\n",
    "    model_fine.solve(x)\n",
    "    return np.array(model_fine.get_data(datapoints)).reshape(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time / ESS noise 0.001 and multiplicative coefficient "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample =  57\n",
      "Sampling chain 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running chain, α = 0.26: 100%|██████████| 1000/1000 [00:14<00:00, 68.78it/s]\n",
      "/Users/lucacaroselli/miniconda3/envs/fenics/lib/python3.11/site-packages/arviz/data/inference_data.py:157: UserWarning: qoi group is not defined in the InferenceData scheme\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 14.630855666997377    ESS:  6.676060405398516    Time/ESS:  2.1915403364484707       1 / 5\n",
      "Sample =  32\n",
      "Sampling chain 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running chain, α = 0.27: 100%|██████████| 1000/1000 [00:14<00:00, 70.67it/s]\n",
      "/Users/lucacaroselli/miniconda3/envs/fenics/lib/python3.11/site-packages/arviz/data/inference_data.py:157: UserWarning: qoi group is not defined in the InferenceData scheme\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 14.165547250013333    ESS:  5.250921243938362    Time/ESS:  2.6977260926101247       1 / 5\n",
      "Sample =  55\n",
      "Sampling chain 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running chain, α = 0.29: 100%|██████████| 1000/1000 [00:20<00:00, 49.16it/s]\n",
      "/Users/lucacaroselli/miniconda3/envs/fenics/lib/python3.11/site-packages/arviz/data/inference_data.py:157: UserWarning: qoi group is not defined in the InferenceData scheme\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20.365632250002818    ESS:  5.18817436703251    Time/ESS:  3.925394716764577       1 / 5\n",
      "Sample =  69\n",
      "Sampling chain 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running chain, α = 0.24: 100%|██████████| 1000/1000 [00:15<00:00, 64.76it/s]\n",
      "/Users/lucacaroselli/miniconda3/envs/fenics/lib/python3.11/site-packages/arviz/data/inference_data.py:157: UserWarning: qoi group is not defined in the InferenceData scheme\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 15.460581499995897    ESS:  4.118500501565335    Time/ESS:  3.7539345920001055       1 / 5\n",
      "Sample =  3\n",
      "Sampling chain 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running chain, α = 0.27: 100%|██████████| 1000/1000 [00:15<00:00, 64.50it/s]\n",
      "/Users/lucacaroselli/miniconda3/envs/fenics/lib/python3.11/site-packages/arviz/data/inference_data.py:157: UserWarning: qoi group is not defined in the InferenceData scheme\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 15.519572541001253    ESS:  5.333051546376481    Time/ESS:  2.9100736053350094       1 / 5\n"
     ]
    }
   ],
   "source": [
    "noise = 0.001\n",
    "scaling = 0.05\n",
    "n_iter = 55000\n",
    "burnin = 5000\n",
    "thin = 50\n",
    "\n",
    "Times = []\n",
    "Time_ESS = []\n",
    "ESS = []\n",
    "i = 1\n",
    "\n",
    "# Define the prior distribution and the proposal (common to all samples)\n",
    "x_distribution = stats.multivariate_normal(mean = np.zeros(64), cov = np.eye(64))\n",
    "my_proposal = tda.CrankNicolson(scaling=scaling, adaptive=False, gamma = 1.01, period=100)\n",
    "\n",
    "for sample in random_samples:\n",
    "    print('Sample = ', sample)\n",
    "    x_true = X_values[sample]\n",
    "    y_true = y_values[sample]\n",
    "\n",
    "    y_observed = y_true + np.random.normal(scale=noise,size=y_true.shape[0])\n",
    "\n",
    "    # LIKELYHOOD\n",
    "    cov_likelihood = noise**2 * np.eye(25)\n",
    "    y_distribution = tda.GaussianLogLike(y_observed, cov_likelihood*100)  \n",
    "\n",
    "    # initialise the Posterior\n",
    "    my_posterior = tda.Posterior(x_distribution, y_distribution, model_hf)\n",
    "\n",
    "    # RUN THE MCMC\n",
    "    start = timeit.default_timer()\n",
    "    samples = tda.sample(my_posterior, my_proposal, iterations=n_iter, n_chains=1, initial_parameters=np.zeros(64))\n",
    "    end = timeit.default_timer()\n",
    "\n",
    "    # Remove the burnin and sub-sample\n",
    "    idata = tda.to_inference_data(samples, level='fine')\n",
    "    idata = idata.sel(draw=slice(burnin, None, thin), groups=\"posterior\")\n",
    "    ess = az.ess(idata)\n",
    "\n",
    "    #Compute the time\n",
    "    t = end-start\n",
    "    Times.append(t)\n",
    "\n",
    "    # Compute the mean ESS on the 64 parameters\n",
    "    e = np.mean([ess.data_vars['x'+str(i)].values for i in range(64)])\n",
    "    ESS.append(e)\n",
    "\n",
    "    #Compute Time / ESS\n",
    "    Time_ESS.append(t/e)\n",
    "    \n",
    "    print('Time:', t, '   ESS: ', e, '   Time/ESS: ',t/e , '     ',i,'/', len(random_samples))\n",
    "\n",
    "# Save the results \n",
    "# Specify the folder path (assuming it already exists)\n",
    "folder_path = './recorded_values'  # Replace with your actual path\n",
    "\n",
    "# Save the file in the specified folder\n",
    "file_path = os.path.join(folder_path, 'FOM_time_ess_001.npy')\n",
    "np.save(file_path, Time_ESS)\n",
    "file_path = os.path.join(folder_path, 'FOM_Times_001.npy')\n",
    "np.save(file_path, Times)\n",
    "file_path = os.path.join(folder_path, 'FOM_ESS_001.npy')\n",
    "np.save(file_path, ESS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time/ESS Higher Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample =  57\n",
      "Sampling chain 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running chain, α = 0.37: 100%|██████████| 1000/1000 [00:21<00:00, 47.58it/s]\n",
      "/Users/lucacaroselli/miniconda3/envs/fenics/lib/python3.11/site-packages/arviz/data/inference_data.py:157: UserWarning: qoi group is not defined in the InferenceData scheme\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 21.24005325001781    ESS:  5.134508327768005    Time/ESS:  4.136725835100741\n",
      "Sample =  32\n",
      "Sampling chain 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running chain, α = 0.36: 100%|██████████| 1000/1000 [00:19<00:00, 51.41it/s]\n",
      "/Users/lucacaroselli/miniconda3/envs/fenics/lib/python3.11/site-packages/arviz/data/inference_data.py:157: UserWarning: qoi group is not defined in the InferenceData scheme\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 19.472266500000842    ESS:  5.603682219292248    Time/ESS:  3.4749055599480823\n",
      "Sample =  55\n",
      "Sampling chain 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running chain, α = 0.34: 100%|██████████| 1000/1000 [00:18<00:00, 54.20it/s]\n",
      "/Users/lucacaroselli/miniconda3/envs/fenics/lib/python3.11/site-packages/arviz/data/inference_data.py:157: UserWarning: qoi group is not defined in the InferenceData scheme\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 18.478969958989182    ESS:  4.829065942951579    Time/ESS:  3.826613713146901\n",
      "Sample =  69\n",
      "Sampling chain 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running chain, α = 0.32: 100%|██████████| 1000/1000 [00:17<00:00, 56.75it/s]\n",
      "/Users/lucacaroselli/miniconda3/envs/fenics/lib/python3.11/site-packages/arviz/data/inference_data.py:157: UserWarning: qoi group is not defined in the InferenceData scheme\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 17.639678750012536    ESS:  4.594724224147746    Time/ESS:  3.839115883670785\n",
      "Sample =  3\n",
      "Sampling chain 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running chain, α = 0.41: 100%|██████████| 1000/1000 [00:18<00:00, 53.77it/s]\n",
      "/Users/lucacaroselli/miniconda3/envs/fenics/lib/python3.11/site-packages/arviz/data/inference_data.py:157: UserWarning: qoi group is not defined in the InferenceData scheme\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 18.61447958298959    ESS:  5.217153446045959    Time/ESS:  3.5679379139399017\n"
     ]
    }
   ],
   "source": [
    "noise = 0.01\n",
    "scaling = 0.04\n",
    "n_iter = 55000\n",
    "burnin = 5000\n",
    "thin = 50\n",
    "\n",
    "Times = []\n",
    "Time_ESS = []\n",
    "ESS = []\n",
    "i = 1\n",
    "\n",
    "# Define the prior distribution and the proposal (common to all samples)\n",
    "x_distribution = stats.multivariate_normal(mean = np.zeros(64), cov = np.eye(64))\n",
    "my_proposal = tda.CrankNicolson(scaling=scaling, adaptive=False, gamma = 1.01, period=100)\n",
    "\n",
    "for sample in random_samples:\n",
    "    print('Sample = ', sample)\n",
    "    x_true = X_values[sample]\n",
    "    y_true = y_values[sample]\n",
    "\n",
    "    y_observed = y_true + np.random.normal(scale=noise,size=y_true.shape[0])\n",
    "\n",
    "    # LIKELYHOOD\n",
    "    cov_likelihood = noise**2 * np.eye(25)\n",
    "    y_distribution = tda.GaussianLogLike(y_observed, cov_likelihood)  \n",
    "\n",
    "    # initialise the Posterior\n",
    "    my_posterior = tda.Posterior(x_distribution, y_distribution, model_hf)\n",
    "\n",
    "    # RUN THE MCMC\n",
    "    start = timeit.default_timer()\n",
    "    samples = tda.sample(my_posterior, my_proposal, iterations=n_iter, n_chains=1, initial_parameters=np.zeros(64))\n",
    "    end = timeit.default_timer()\n",
    "\n",
    "    # Remove the burnin and sub-sample\n",
    "    idata = tda.to_inference_data(samples, level='fine')\n",
    "    idata = idata.sel(draw=slice(burnin, None, thin), groups=\"posterior\")\n",
    "    ess = az.ess(idata)\n",
    "\n",
    "    #Compute the time\n",
    "    t = end-start\n",
    "    Times.append(t)\n",
    "\n",
    "    # Compute the mean ESS on the 64 parameters\n",
    "    e = np.mean([ess.data_vars['x'+str(i)].values for i in range(64)])\n",
    "    ESS.append(e)\n",
    "\n",
    "    #Compute Time / ESS\n",
    "    Time_ESS.append(t/e)\n",
    "    \n",
    "    print('Time:', t, '   ESS: ', e, '   Time/ESS: ',t/e )\n",
    "\n",
    "# Save the results \n",
    "# Specify the folder path (assuming it already exists)\n",
    "folder_path = './recorded_values'  # Replace with your actual path\n",
    "\n",
    "# Save the file in the specified folder\n",
    "file_path = os.path.join(folder_path, 'FOM_time_ess_01.npy')\n",
    "np.save(file_path, Time_ESS)\n",
    "file_path = os.path.join(folder_path, 'FOM_Times_01.npy')\n",
    "np.save(file_path, Times)\n",
    "file_path = os.path.join(folder_path, 'FOM_ESS_01.npy')\n",
    "np.save(file_path, ESS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fenics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
