{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze the TIME / ESS distribution \n",
    "\n",
    "Randomly choose 25 samples and evaluate the model's Time / ESS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import sys\n",
    "\n",
    "import os\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = '1'\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "\n",
    "# Third-party library imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gaussian_kde\n",
    "import arviz as az\n",
    "import timeit\n",
    "\n",
    "import scipy.stats as stats\n",
    "from keras.models import Model as Model_nn\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Concatenate\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.layers import Input, Dense, Add\n",
    "\n",
    "#Try with TinyDA\n",
    "import tinyDA as tda\n",
    "from scipy.stats import multivariate_normal\n",
    "from scipy.stats import uniform\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "# Local module imports\n",
    "sys.path.append('../../')\n",
    "sys.path.append('../../solver')\n",
    "#sys.path.append('./src/InverseProblems')\n",
    "#sys.path.append('./src/utils')\n",
    "from utils import * \n",
    "from plotting import *\n",
    "from random_process import *\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose the 25 random samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([57, 32, 55, 69,  3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 25\n",
    "np.random.seed(2109)\n",
    "random_samples = np.random.randint(0, 160, n)\n",
    "random_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data and surrogate model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract test data for visualization or further processing\n",
    "n_eig = 64\n",
    "X_values = np.loadtxt('../../data/50-25-10/X_test_50resolution.csv', delimiter = ',')\n",
    "y_values = np.loadtxt('../../data/50-25-10/y_test_50resolution.csv',delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucacaroselli/miniconda3/envs/fenics/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Choose the model parameters \n",
    "n_samples_lf = 64000\n",
    "coeff_lf = 1e-09\n",
    "\n",
    "# Initialize the neural network model\n",
    "model_lf = Sequential([\n",
    "    Dense(256, input_shape=(X_values.shape[1],), activation='gelu'),\n",
    "    Dense(256, activation='gelu'),\n",
    "    Dense(256, activation='gelu'),\n",
    "    Dense(256, activation='gelu'),\n",
    "    Dense(256, activation='gelu'),\n",
    "    Dense(256, activation='gelu'),\n",
    "    Dense(25, activation='linear')\n",
    "])\n",
    "\n",
    "model_lf = load_model(f'../models/model_25resolution_{n_samples_lf}samples_1.keras')\n",
    "\n",
    "# Choose the model parameters \n",
    "n_samples = 16000\n",
    "coeff = 1e-08\n",
    "\n",
    "n_neurons = 256\n",
    "# Initialize the neural network model\n",
    "# Define the three branches of the model\n",
    "input_params = Input(shape=(X_values.shape[1],))\n",
    "input_pod = Input(shape=(y_values.shape[1],))\n",
    "\n",
    "# Define the first branch (parameters)\n",
    "x1 = Dense(n_neurons, activation='gelu')(input_params)\n",
    "x1 = Dense(n_neurons, activation='gelu')(x1)\n",
    "x1 = Dense(n_neurons, activation='gelu')(x1)\n",
    "x1 = Dense(n_neurons, activation='gelu')(x1)\n",
    "x1 = Dense(n_neurons, activation='gelu')(x1)\n",
    "x1 = Dense(n_neurons, activation='gelu')(x1)\n",
    "\n",
    "# Define the second branch (POD)\n",
    "x2 = Dense(n_neurons, activation='gelu')(input_pod)\n",
    "\n",
    "# # Define the second branch (POD)\n",
    "# x3 = Dense(n_neurons, activation='gelu', kernel_regularizer=l2(w))(input_nn)\n",
    "\n",
    "# Combine the outputs of the three branches\n",
    "combined = Add()([x1,x2])\n",
    "combined = Dense(n_neurons, activation='gelu')(combined)\n",
    "output = Dense(25, activation='linear')(combined)\n",
    "\n",
    "# Create the model\n",
    "model_hf = Model_nn(inputs=[input_params,input_pod], outputs=output)\n",
    "model_hf = load_model(f'..//models/model_2step_50-25resolution_{n_samples}samples_1.keras')\n",
    "\n",
    "model_nn = lambda input: np.array(model_hf([input.reshape(1,64), model_lf(input.reshape(1,64)).numpy()])).reshape(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time / ESS noise 0.001 and multiplicative coefficient "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample =  57\n",
      "Sampling chain 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running chain, α = 0.38: 100%|██████████| 1000/1000 [00:12<00:00, 78.10it/s]\n",
      "/Users/lucacaroselli/miniconda3/envs/fenics/lib/python3.11/site-packages/arviz/data/inference_data.py:157: UserWarning: qoi group is not defined in the InferenceData scheme\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 12.829833374998998    ESS:  4.028678647507794    Time/ESS:  3.1846256546016\n",
      "Sample =  32\n",
      "Sampling chain 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running chain, α = 0.42: 100%|██████████| 1000/1000 [00:11<00:00, 86.20it/s]\n",
      "/Users/lucacaroselli/miniconda3/envs/fenics/lib/python3.11/site-packages/arviz/data/inference_data.py:157: UserWarning: qoi group is not defined in the InferenceData scheme\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 11.614287625008728    ESS:  4.77029687976076    Time/ESS:  2.434709603564801\n",
      "Sample =  55\n",
      "Sampling chain 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running chain, α = 0.33: 100%|██████████| 1000/1000 [00:12<00:00, 81.30it/s]\n",
      "/Users/lucacaroselli/miniconda3/envs/fenics/lib/python3.11/site-packages/arviz/data/inference_data.py:157: UserWarning: qoi group is not defined in the InferenceData scheme\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 12.315154000010807    ESS:  4.278714736695965    Time/ESS:  2.878236750487508\n",
      "Sample =  69\n",
      "Sampling chain 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running chain, α = 0.36: 100%|██████████| 1000/1000 [00:12<00:00, 78.55it/s]\n",
      "/Users/lucacaroselli/miniconda3/envs/fenics/lib/python3.11/site-packages/arviz/data/inference_data.py:157: UserWarning: qoi group is not defined in the InferenceData scheme\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 12.746541125001386    ESS:  4.2917839669727105    Time/ESS:  2.9699866589492845\n",
      "Sample =  3\n",
      "Sampling chain 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running chain, α = 0.42: 100%|██████████| 1000/1000 [00:14<00:00, 71.00it/s]\n",
      "/Users/lucacaroselli/miniconda3/envs/fenics/lib/python3.11/site-packages/arviz/data/inference_data.py:157: UserWarning: qoi group is not defined in the InferenceData scheme\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 14.103937458974542    ESS:  4.997559777259492    Time/ESS:  2.8221648339559646\n",
      "Effective Sample Size:  <xarray.Dataset> Size: 512B\n",
      "Dimensions:  ()\n",
      "Data variables: (12/64)\n",
      "    x0       float64 8B 5.681\n",
      "    x1       float64 8B 5.14\n",
      "    x2       float64 8B 2.094\n",
      "    x3       float64 8B 2.071\n",
      "    x4       float64 8B 2.1\n",
      "    x5       float64 8B 2.162\n",
      "    ...       ...\n",
      "    x58      float64 8B 3.579\n",
      "    x59      float64 8B 13.77\n",
      "    x60      float64 8B 10.27\n",
      "    x61      float64 8B 5.43\n",
      "    x62      float64 8B 2.489\n",
      "    x63      float64 8B 2.272 \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "noise = 0.001\n",
    "scaling = 0.015 #0.05\n",
    "n_iter = 55000\n",
    "burnin = 5000\n",
    "thin = 50\n",
    "\n",
    "Times = []\n",
    "Time_ESS = []\n",
    "ESS = []\n",
    "i = 1\n",
    "\n",
    "# Define the prior distribution and the proposal (common to all samples)\n",
    "x_distribution = stats.multivariate_normal(mean = np.zeros(64), cov = np.eye(64))\n",
    "my_proposal = tda.CrankNicolson(scaling=scaling, adaptive=False, gamma = 1.01, period=100)\n",
    "\n",
    "for sample in random_samples:\n",
    "    print('Sample = ', sample)\n",
    "    x_true = X_values[sample]\n",
    "    y_true = y_values[sample]\n",
    "\n",
    "    y_observed = y_true + np.random.normal(scale=noise,size=y_true.shape[0])\n",
    "\n",
    "    # LIKELYHOOD\n",
    "    cov_likelihood = noise**2 * np.eye(25)\n",
    "    y_distribution = tda.GaussianLogLike(y_observed, cov_likelihood*10)  \n",
    "\n",
    "    # initialise the Posterior\n",
    "    my_posterior = tda.Posterior(x_distribution, y_distribution, model_nn)\n",
    "\n",
    "    # RUN THE MCMC\n",
    "    start = timeit.default_timer()\n",
    "    samples = tda.sample(my_posterior, my_proposal, iterations=n_iter, n_chains=1, initial_parameters=np.zeros(64))\n",
    "    end = timeit.default_timer()\n",
    "\n",
    "    # Remove the burnin and sub-sample\n",
    "    idata = tda.to_inference_data(samples, level='fine')\n",
    "    idata = idata.sel(draw=slice(burnin, None, thin), groups=\"posterior\")\n",
    "    ess = az.ess(idata)\n",
    "\n",
    "    #Compute the time\n",
    "    t = end-start\n",
    "    Times.append(t)\n",
    "\n",
    "    # Compute the mean ESS on the 64 parameters\n",
    "    e = np.mean([ess.data_vars['x'+str(i)].values for i in range(64)])\n",
    "    ESS.append(e)\n",
    "\n",
    "    #Compute Time / ESS\n",
    "    Time_ESS.append(t/e)\n",
    "    \n",
    "    print('Time:', t, '   ESS: ', e, '   Time/ESS: ',t/e )\n",
    "\n",
    "# Save the results \n",
    "# Specify the folder path (assuming it already exists)\n",
    "folder_path = './recorded_values'  # Replace with your actual path\n",
    "\n",
    "# Save the file in the specified folder\n",
    "file_path = os.path.join(folder_path, 'MF_2step_time_ess_001.npy')\n",
    "np.save(file_path, Time_ESS)\n",
    "file_path = os.path.join(folder_path, 'MF_2step_Times_001.npy')\n",
    "np.save(file_path, Times)\n",
    "file_path = os.path.join(folder_path, 'MF_2step_ESS_001.npy')\n",
    "np.save(file_path, ESS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time/ESS Higher Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample =  57\n",
      "Sampling chain 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running chain, α = 0.33: 100%|██████████| 1000/1000 [00:15<00:00, 63.94it/s]\n",
      "/Users/lucacaroselli/miniconda3/envs/fenics/lib/python3.11/site-packages/arviz/data/inference_data.py:157: UserWarning: qoi group is not defined in the InferenceData scheme\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 15.717119583016029    ESS:  5.351230111037505    Time/ESS:  2.9371040409190643       1 / 5\n",
      "Sample =  32\n",
      "Sampling chain 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running chain, α = 0.33: 100%|██████████| 1000/1000 [00:14<00:00, 67.00it/s]\n",
      "/Users/lucacaroselli/miniconda3/envs/fenics/lib/python3.11/site-packages/arviz/data/inference_data.py:157: UserWarning: qoi group is not defined in the InferenceData scheme\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 14.94473712501349    ESS:  5.130320605171551    Time/ESS:  2.913022065316668       2 / 5\n",
      "Sample =  55\n",
      "Sampling chain 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running chain, α = 0.35: 100%|██████████| 1000/1000 [00:13<00:00, 73.19it/s]\n",
      "/Users/lucacaroselli/miniconda3/envs/fenics/lib/python3.11/site-packages/arviz/data/inference_data.py:157: UserWarning: qoi group is not defined in the InferenceData scheme\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 13.679101499990793    ESS:  4.399217551777843    Time/ESS:  3.1094396535271818       3 / 5\n",
      "Sample =  69\n",
      "Sampling chain 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running chain, α = 0.35: 100%|██████████| 1000/1000 [00:12<00:00, 77.97it/s]\n",
      "/Users/lucacaroselli/miniconda3/envs/fenics/lib/python3.11/site-packages/arviz/data/inference_data.py:157: UserWarning: qoi group is not defined in the InferenceData scheme\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 12.840962916990975    ESS:  5.400446233897606    Time/ESS:  2.377759607417368       4 / 5\n",
      "Sample =  3\n",
      "Sampling chain 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running chain, α = 0.38: 100%|██████████| 1000/1000 [00:12<00:00, 77.38it/s]\n",
      "/Users/lucacaroselli/miniconda3/envs/fenics/lib/python3.11/site-packages/arviz/data/inference_data.py:157: UserWarning: qoi group is not defined in the InferenceData scheme\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 12.939926541002933    ESS:  5.842866202901444    Time/ESS:  2.2146539201218127       5 / 5\n",
      "Effective Sample Size:  <xarray.Dataset> Size: 512B\n",
      "Dimensions:  ()\n",
      "Data variables: (12/64)\n",
      "    x0       float64 8B 8.679\n",
      "    x1       float64 8B 2.373\n",
      "    x2       float64 8B 10.47\n",
      "    x3       float64 8B 2.562\n",
      "    x4       float64 8B 4.334\n",
      "    x5       float64 8B 5.95\n",
      "    ...       ...\n",
      "    x58      float64 8B 11.17\n",
      "    x59      float64 8B 2.899\n",
      "    x60      float64 8B 11.93\n",
      "    x61      float64 8B 2.114\n",
      "    x62      float64 8B 2.109\n",
      "    x63      float64 8B 2.618 \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "noise = 0.01\n",
    "scaling = 0.04\n",
    "n_iter = 55000\n",
    "burnin = 5000\n",
    "thin = 50\n",
    "\n",
    "Times = []\n",
    "Time_ESS = []\n",
    "ESS = []\n",
    "i = 1\n",
    "\n",
    "# Define the prior distribution and the proposal (common to all samples)\n",
    "x_distribution = stats.multivariate_normal(mean = np.zeros(64), cov = np.eye(64))\n",
    "my_proposal = tda.CrankNicolson(scaling=scaling, adaptive=False, gamma = 1.01, period=100)\n",
    "\n",
    "for sample in random_samples:\n",
    "    print('Sample = ', sample)\n",
    "    x_true = X_values[sample]\n",
    "    y_true = y_values[sample]\n",
    "\n",
    "    y_observed = y_true + np.random.normal(scale=noise,size=y_true.shape[0])\n",
    "\n",
    "    # LIKELYHOOD\n",
    "    cov_likelihood = noise**2 * np.eye(25)\n",
    "    y_distribution = tda.GaussianLogLike(y_observed, cov_likelihood)  \n",
    "\n",
    "    # initialise the Posterior\n",
    "    my_posterior = tda.Posterior(x_distribution, y_distribution, model_nn)\n",
    "\n",
    "    # RUN THE MCMC\n",
    "    start = timeit.default_timer()\n",
    "    samples = tda.sample(my_posterior, my_proposal, iterations=n_iter, n_chains=1, initial_parameters=np.zeros(64))\n",
    "    end = timeit.default_timer()\n",
    "\n",
    "    # Remove the burnin and sub-sample\n",
    "    idata = tda.to_inference_data(samples, level='fine')\n",
    "    idata = idata.sel(draw=slice(burnin, None, thin), groups=\"posterior\")\n",
    "    ess = az.ess(idata)\n",
    "\n",
    "    #Compute the time\n",
    "    t = end-start\n",
    "    Times.append(t)\n",
    "\n",
    "    # Compute the mean ESS on the 64 parameters\n",
    "    e = np.mean([ess.data_vars['x'+str(i)].values for i in range(64)])\n",
    "    ESS.append(e)\n",
    "\n",
    "    #Compute Time / ESS\n",
    "    Time_ESS.append(t/e)\n",
    "    \n",
    "    print('Time:', t, '   ESS: ', e, '   Time/ESS: ',t/e , '     ', i,'/', len(random_samples))\n",
    "\n",
    "    i = i+1\n",
    "\n",
    "# Save the results \n",
    "# Specify the folder path (assuming it already exists)\n",
    "folder_path = './recorded_values'  # Replace with your actual path\n",
    "\n",
    "# Save the file in the specified folder\n",
    "file_path = os.path.join(folder_path, 'MF_2step_time_ess_01.npy')\n",
    "np.save(file_path, Time_ESS)\n",
    "file_path = os.path.join(folder_path, 'MF_2step_Times_01.npy')\n",
    "np.save(file_path, Times)\n",
    "file_path = os.path.join(folder_path, 'MF_2step_ESS_01.npy')\n",
    "np.save(file_path, ESS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fenics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
