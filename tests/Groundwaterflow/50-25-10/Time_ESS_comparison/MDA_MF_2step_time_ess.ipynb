{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze the TIME / ESS distribution \n",
    "\n",
    "Randomly choose 25 samples and evaluate the model's Time / ESS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import sys\n",
    "\n",
    "import os\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = '1'\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "\n",
    "# Third-party library imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gaussian_kde\n",
    "import arviz as az\n",
    "import timeit\n",
    "\n",
    "import scipy.stats as stats\n",
    "from keras.models import Model as Model_nn\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Concatenate\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.layers import Input, Dense, Add\n",
    "\n",
    "#Try with TinyDA\n",
    "import tinyDA as tda\n",
    "from scipy.stats import multivariate_normal\n",
    "from scipy.stats import uniform\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "# Local module imports\n",
    "sys.path.append('../../')\n",
    "sys.path.append('../../solver')\n",
    "#sys.path.append('./src/InverseProblems')\n",
    "#sys.path.append('./src/utils')\n",
    "from utils import * \n",
    "from plotting import *\n",
    "from random_process import *\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose the 25 random samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([57, 32, 55, 69,  3])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 25 \n",
    "np.random.seed(2109)\n",
    "random_samples = np.random.randint(0, 160, n)\n",
    "random_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data and surrogate model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract test data for visualization or further processing\n",
    "n_eig = 64\n",
    "X_values = np.loadtxt('../../data/50-25-10/X_test_50resolution.csv', delimiter = ',')\n",
    "y_values = np.loadtxt('../../data/50-25-10/y_test_50resolution.csv',delimiter = ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Low fidelity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the model parameters \n",
    "n_samples_lf = 16000\n",
    "coeff_lf = 1e-08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucacaroselli/miniconda3/envs/fenics/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Initialize the neural network model\n",
    "model_l = Sequential([\n",
    "    Dense(256, input_shape=(X_values.shape[1],), activation='gelu'),\n",
    "    Dense(256, activation='gelu'),\n",
    "    Dense(256, activation='gelu'),\n",
    "    Dense(256, activation='gelu'),\n",
    "    Dense(256, activation='gelu'),\n",
    "    Dense(256, activation='gelu'),\n",
    "    Dense(25, activation='linear')\n",
    "])\n",
    "\n",
    "model_l = load_model(f'../models/model_50resolution_{n_samples_lf}samples_1.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load High Fidelity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the model parameters \n",
    "n_samples_lf_mf = 64000\n",
    "coeff_lf_mf = 1e-09\n",
    "\n",
    "# Initialize the neural network model\n",
    "model_l_mf = Sequential([\n",
    "    Dense(256, input_shape=(X_values.shape[1],), activation='gelu'),\n",
    "    Dense(256, activation='gelu'),\n",
    "    Dense(256, activation='gelu'),\n",
    "    Dense(256, activation='gelu'),\n",
    "    Dense(256, activation='gelu'),\n",
    "    Dense(256, activation='gelu'),\n",
    "    Dense(25, activation='linear')\n",
    "])\n",
    "\n",
    "model_l_mf = load_model(f'../models/model_25resolution_{n_samples_lf_mf}samples_1.keras')\n",
    "\n",
    "# Choose the model parameters \n",
    "n_samples = 16000\n",
    "coeff = 1e-08\n",
    "\n",
    "n_neurons = 256\n",
    "# Initialize the neural network model\n",
    "# Define the three branches of the model\n",
    "input_params = Input(shape=(X_values.shape[1],))\n",
    "input_pod = Input(shape=(y_values.shape[1],))\n",
    "\n",
    "# Define the first branch (parameters)\n",
    "x1 = Dense(n_neurons, activation='gelu')(input_params)\n",
    "x1 = Dense(n_neurons, activation='gelu')(x1)\n",
    "x1 = Dense(n_neurons, activation='gelu')(x1)\n",
    "x1 = Dense(n_neurons, activation='gelu')(x1)\n",
    "x1 = Dense(n_neurons, activation='gelu')(x1)\n",
    "x1 = Dense(n_neurons, activation='gelu')(x1)\n",
    "\n",
    "# Define the second branch (POD)\n",
    "x2 = Dense(n_neurons, activation='gelu')(input_pod)\n",
    "\n",
    "# # Define the second branch (POD)\n",
    "# x3 = Dense(n_neurons, activation='gelu', kernel_regularizer=l2(w))(input_nn)\n",
    "\n",
    "# Combine the outputs of the three branches\n",
    "combined = Add()([x1,x2])\n",
    "combined = Dense(n_neurons, activation='gelu')(combined)\n",
    "output = Dense(25, activation='linear')(combined)\n",
    "\n",
    "# Create the model\n",
    "model_h = Model_nn(inputs=[input_params,input_pod], outputs=output)\n",
    "model_h = load_model(f'..//models/model_2step_50-25resolution_{n_samples}samples_1.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lf = lambda input : model_l(input.reshape(1,64)).numpy().reshape(25)\n",
    "model_hf = lambda input: model_h([input.reshape(1,64), model_l_mf(input.reshape(1,64)).numpy()]).numpy().reshape(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time / ESS noise 0.001 and multiplicative coefficient "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample =  57\n",
      "Sampling chain 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running chain, α_c = 0.319, α_f = 0.21:   2%|▏         | 19/1000 [00:00<00:11, 86.41it/s]/Users/lucacaroselli/miniconda3/envs/fenics/lib/python3.11/site-packages/tinyDA/proposal.py:340: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(proposal_link.likelihood - previous_link.likelihood)\n",
      "Running chain, α_c = 0.340, α_f = 0.30: 100%|██████████| 1000/1000 [00:11<00:00, 85.32it/s]\n",
      "/Users/lucacaroselli/miniconda3/envs/fenics/lib/python3.11/site-packages/arviz/data/inference_data.py:157: UserWarning: qoi group is not defined in the InferenceData scheme\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 11.86524687500787    ESS:  3.5857771104810974    Time/ESS:  3.3089750169708485\n",
      "Sample =  32\n",
      "Sampling chain 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running chain, α_c = 0.320, α_f = 0.19: 100%|██████████| 1000/1000 [00:11<00:00, 87.45it/s]\n",
      "/Users/lucacaroselli/miniconda3/envs/fenics/lib/python3.11/site-packages/arviz/data/inference_data.py:157: UserWarning: qoi group is not defined in the InferenceData scheme\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 11.45990124999662    ESS:  3.4507273236216887    Time/ESS:  3.32101037701494\n",
      "Sample =  55\n",
      "Sampling chain 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running chain, α_c = 0.400, α_f = 0.25: 100%|██████████| 1000/1000 [00:12<00:00, 83.08it/s]\n",
      "/Users/lucacaroselli/miniconda3/envs/fenics/lib/python3.11/site-packages/arviz/data/inference_data.py:157: UserWarning: qoi group is not defined in the InferenceData scheme\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 12.05845379200764    ESS:  4.168628169231814    Time/ESS:  2.8926671563105004\n",
      "Sample =  69\n",
      "Sampling chain 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running chain, α_c = 0.270, α_f = 0.21: 100%|██████████| 1000/1000 [00:11<00:00, 86.31it/s]\n",
      "/Users/lucacaroselli/miniconda3/envs/fenics/lib/python3.11/site-packages/arviz/data/inference_data.py:157: UserWarning: qoi group is not defined in the InferenceData scheme\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 11.607489916001214    ESS:  3.696851338118835    Time/ESS:  3.139831400931517\n",
      "Sample =  3\n",
      "Sampling chain 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running chain, α_c = 0.350, α_f = 0.29: 100%|██████████| 1000/1000 [00:12<00:00, 82.65it/s]\n",
      "/Users/lucacaroselli/miniconda3/envs/fenics/lib/python3.11/site-packages/arviz/data/inference_data.py:157: UserWarning: qoi group is not defined in the InferenceData scheme\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 12.127233292005258    ESS:  3.875273631961117    Time/ESS:  3.12938761071903\n"
     ]
    }
   ],
   "source": [
    "noise = 0.001\n",
    "scaling = 0.015 # 0.04\n",
    "n_iter =  30000 #55000\n",
    "burnin = 3000 #5000\n",
    "thin = 20\n",
    "sub_sampling = 1\n",
    "\n",
    "Times = []\n",
    "Time_ESS = []\n",
    "ESS = []\n",
    "i = 1\n",
    "\n",
    "# Define the prior distribution and the proposal (common to all samples)\n",
    "x_distribution = stats.multivariate_normal(mean = np.zeros(64), cov = np.eye(64))\n",
    "my_proposal = tda.CrankNicolson(scaling=scaling, adaptive=False, gamma = 1.01, period=100)\n",
    "\n",
    "for sample in random_samples:\n",
    "    print('Sample = ', sample)\n",
    "    x_true = X_values[sample]\n",
    "    y_true = y_values[sample]\n",
    "\n",
    "    y_observed = y_true + np.random.normal(scale=noise,size=y_true.shape[0])\n",
    "\n",
    "    # LIKELYHOOD\n",
    "    cov_likelihood = noise**2 * np.eye(25)\n",
    "    y_distribution_coarse = tda.AdaptiveGaussianLogLike(y_observed, cov_likelihood*10)\n",
    "    y_distribution_fine  = tda.GaussianLogLike(y_observed, cov_likelihood*10)\n",
    "\n",
    "    # initialise the Posterior\n",
    "    my_posterior_coarse = tda.Posterior(x_distribution, y_distribution_coarse, model_lf)\n",
    "    my_posterior_fine = tda.Posterior(x_distribution, y_distribution_fine, model_hf)\n",
    "    my_posteriors = [my_posterior_coarse, my_posterior_fine]\n",
    "\n",
    "    # RUN THE MCMC\n",
    "    start = timeit.default_timer()\n",
    "    samples = tda.sample(my_posteriors, my_proposal, iterations=n_iter, n_chains=1, initial_parameters=np.zeros(64), subsampling_rate= sub_sampling, adaptive_error_model='state-independent')\n",
    "    end = timeit.default_timer()\n",
    "\n",
    "    # Remove the burnin and sub-sample\n",
    "    idata = tda.to_inference_data(samples, level='fine')\n",
    "    idata = idata.sel(draw=slice(burnin, None, thin), groups=\"posterior\")\n",
    "    ess = az.ess(idata)\n",
    "\n",
    "    #Compute the time\n",
    "    t = end-start\n",
    "    Times.append(t)\n",
    "\n",
    "    # Compute the mean ESS on the 64 parameters\n",
    "    e = np.mean([ess.data_vars['x'+str(i)].values for i in range(64)])\n",
    "    ESS.append(e)\n",
    "\n",
    "    #Compute Time / ESS\n",
    "    Time_ESS.append(t/e)\n",
    "    \n",
    "    print('Time:', t, '   ESS: ', e, '   Time/ESS: ',t/e )\n",
    "\n",
    "# Save the results \n",
    "# Specify the folder path (assuming it already exists)\n",
    "folder_path = './recorded_values'  # Replace with your actual path\n",
    "\n",
    "# Save the file in the specified folder\n",
    "file_path = os.path.join(folder_path, 'MDA_MF_2step_time_ess_001.npy')\n",
    "np.save(file_path, Time_ESS)\n",
    "file_path = os.path.join(folder_path, 'MDA_MF_2step_Times_001.npy')\n",
    "np.save(file_path, Times)\n",
    "file_path = os.path.join(folder_path, 'MDA_MF_2step_ESS_001.npy')\n",
    "np.save(file_path, ESS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time/ESS Higher Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample =  57\n",
      "Sampling chain 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running chain, α_c = 0.350, α_f = 0.29: 100%|██████████| 1000/1000 [00:12<00:00, 78.34it/s]\n",
      "/Users/lucacaroselli/miniconda3/envs/fenics/lib/python3.11/site-packages/arviz/data/inference_data.py:157: UserWarning: qoi group is not defined in the InferenceData scheme\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 12.810139042005176    ESS:  4.091444278372272    Time/ESS:  3.1309577182122896       1 / 5\n",
      "Sample =  32\n",
      "Sampling chain 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running chain, α_c = 0.340, α_f = 0.33: 100%|██████████| 1000/1000 [00:13<00:00, 73.71it/s]\n",
      "/Users/lucacaroselli/miniconda3/envs/fenics/lib/python3.11/site-packages/arviz/data/inference_data.py:157: UserWarning: qoi group is not defined in the InferenceData scheme\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 13.59484637499554    ESS:  3.8659825909307868    Time/ESS:  3.516530676285948       2 / 5\n",
      "Sample =  55\n",
      "Sampling chain 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running chain, α_c = 0.290, α_f = 0.18: 100%|██████████| 1000/1000 [00:13<00:00, 71.88it/s]\n",
      "/Users/lucacaroselli/miniconda3/envs/fenics/lib/python3.11/site-packages/arviz/data/inference_data.py:157: UserWarning: qoi group is not defined in the InferenceData scheme\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 13.945761666982435    ESS:  4.786344051762926    Time/ESS:  2.9136563348064946       3 / 5\n",
      "Sample =  69\n",
      "Sampling chain 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running chain, α_c = 0.460, α_f = 0.35: 100%|██████████| 1000/1000 [00:17<00:00, 57.15it/s]\n",
      "/Users/lucacaroselli/miniconda3/envs/fenics/lib/python3.11/site-packages/arviz/data/inference_data.py:157: UserWarning: qoi group is not defined in the InferenceData scheme\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 17.52990912500536    ESS:  4.050691863784756    Time/ESS:  4.327633331414729       4 / 5\n",
      "Sample =  3\n",
      "Sampling chain 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running chain, α_c = 0.390, α_f = 0.32: 100%|██████████| 1000/1000 [00:17<00:00, 56.41it/s]\n",
      "/Users/lucacaroselli/miniconda3/envs/fenics/lib/python3.11/site-packages/arviz/data/inference_data.py:157: UserWarning: qoi group is not defined in the InferenceData scheme\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 17.766493667004397    ESS:  4.2453490689477285    Time/ESS:  4.184931174907622       5 / 5\n"
     ]
    }
   ],
   "source": [
    "noise = 0.01\n",
    "scaling = 0.04\n",
    "n_iter =  30000 #55000\n",
    "burnin = 3000 #5000\n",
    "thin = 20\n",
    "sub_sampling = 1\n",
    "\n",
    "Times = []\n",
    "Time_ESS = []\n",
    "ESS = []\n",
    "i = 1\n",
    "\n",
    "# Define the prior distribution and the proposal (common to all samples)\n",
    "x_distribution = stats.multivariate_normal(mean = np.zeros(64), cov = np.eye(64))\n",
    "my_proposal = tda.CrankNicolson(scaling=scaling, adaptive=False, gamma = 1.01, period=100)\n",
    "\n",
    "for sample in random_samples:\n",
    "    print('Sample = ', sample)\n",
    "    x_true = X_values[sample]\n",
    "    y_true = y_values[sample]\n",
    "\n",
    "    y_observed = y_true + np.random.normal(scale=noise,size=y_true.shape[0])\n",
    "\n",
    "    # LIKELYHOOD\n",
    "    cov_likelihood = noise**2 * np.eye(25)\n",
    "    y_distribution_coarse = tda.AdaptiveGaussianLogLike(y_observed, cov_likelihood)\n",
    "    y_distribution_fine  = tda.GaussianLogLike(y_observed, cov_likelihood)\n",
    "    # initialise the Posterior\n",
    "    my_posterior_coarse = tda.Posterior(x_distribution, y_distribution_coarse, model_lf)\n",
    "    my_posterior_fine = tda.Posterior(x_distribution, y_distribution_fine, model_hf)\n",
    "    my_posteriors = [my_posterior_coarse, my_posterior_fine]\n",
    "\n",
    "    # RUN THE MCMC\n",
    "    start = timeit.default_timer()\n",
    "    samples = tda.sample(my_posteriors, my_proposal, iterations=n_iter, n_chains=1, initial_parameters=np.zeros(64), subsampling_rate= sub_sampling, adaptive_error_model='state-independent')\n",
    "    end = timeit.default_timer()\n",
    "\n",
    "    # Remove the burnin and sub-sample\n",
    "    idata = tda.to_inference_data(samples, level='fine')\n",
    "    idata = idata.sel(draw=slice(burnin, None, thin), groups=\"posterior\")\n",
    "    ess = az.ess(idata)\n",
    "\n",
    "    #Compute the time\n",
    "    t = end-start\n",
    "    Times.append(t)\n",
    "\n",
    "    # Compute the mean ESS on the 64 parameters\n",
    "    e = np.mean([ess.data_vars['x'+str(i)].values for i in range(64)])\n",
    "    ESS.append(e)\n",
    "\n",
    "    #Compute Time / ESS\n",
    "    Time_ESS.append(t/e)\n",
    "    \n",
    "    print('Time:', t, '   ESS: ', e, '   Time/ESS: ',t/e , '     ', i,'/', len(random_samples))\n",
    "\n",
    "    i = i+1\n",
    "\n",
    "# Save the results \n",
    "# Specify the folder path (assuming it already exists)\n",
    "folder_path = './recorded_values'  # Replace with your actual path\n",
    "\n",
    "# Save the file in the specified folder\n",
    "file_path = os.path.join(folder_path, 'MDA_MF_2step_time_ess_01.npy')\n",
    "np.save(file_path, Time_ESS)\n",
    "file_path = os.path.join(folder_path, 'MDA_MF_2step_Times_01.npy')\n",
    "np.save(file_path, Times)\n",
    "file_path = os.path.join(folder_path, 'MDA_MF_2step_ESS_01.npy')\n",
    "np.save(file_path, ESS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fenics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
