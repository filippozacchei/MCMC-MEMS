{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ContiPaolo/Multifidelity-Tutorial/blob/main/MF_POD_Burger's1D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNXEcOy7YdZp"
      },
      "source": [
        "Comparison of the models without fenics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WP3luMxfaY7N"
      },
      "source": [
        "#### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "dUChnEGpNaQE"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "#import matplotlib as plt\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd \n",
        "import timeit\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam,Nadam,Adamax\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, LSTM, Dropout, Add\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.utils import extmath\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "\n",
        "#######################     CONFIGURATIONS     ##########################\n",
        "seed = 29\n",
        "train = True\n",
        "save = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract test data for visualization or further processing\n",
        "n_eig = 64\n",
        "X = np.loadtxt('../../data/50-25-10/X_test_50resolution.csv', delimiter = ',')\n",
        "y = np.loadtxt('../../data/50-25-10/y_test_50resolution.csv',delimiter = ',')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load low fidelity model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Choose the model parameters \n",
        "n_samples_lf = 64000\n",
        "coeff_lf = 1e-09\n",
        "# Choose the model parameters \n",
        "n_samples = 16000\n",
        "coeff = 1e-08\n",
        "# Initialize the neural network model\n",
        "model_l = Sequential([\n",
        "    Dense(256, input_shape=(X.shape[1],), activation='gelu'),\n",
        "    Dense(256, activation='gelu'),\n",
        "    Dense(256, activation='gelu'),\n",
        "    Dense(256, activation='gelu'),\n",
        "    Dense(256, activation='gelu'),\n",
        "    Dense(256, activation='gelu'),\n",
        "    Dense(25, activation='linear')\n",
        "])\n",
        "\n",
        "model_l = load_model(f'models/model_25resolution_{n_samples_lf}samples_1_coeff{coeff_lf}.keras')\n",
        "\n",
        "n_neurons = 256\n",
        "# Initialize the neural network model\n",
        "# Define the three branches of the model\n",
        "input_params = Input(shape=(X.shape[1],))\n",
        "input_pod = Input(shape=(y.shape[1],))\n",
        "\n",
        "# Define the first branch (parameters)\n",
        "x1 = Dense(n_neurons, activation='gelu')(input_params)\n",
        "x1 = Dense(n_neurons, activation='gelu')(x1)\n",
        "x1 = Dense(n_neurons, activation='gelu')(x1)\n",
        "x1 = Dense(n_neurons, activation='gelu')(x1)\n",
        "x1 = Dense(n_neurons, activation='gelu')(x1)\n",
        "x1 = Dense(n_neurons, activation='gelu')(x1)\n",
        "\n",
        "# Define the second branch (POD)\n",
        "x2 = Dense(n_neurons, activation='gelu')(input_pod)\n",
        "\n",
        "# # Define the second branch (POD)\n",
        "# x3 = Dense(n_neurons, activation='gelu', kernel_regularizer=l2(w))(input_nn)\n",
        "\n",
        "# Combine the outputs of the three branches\n",
        "combined = Add()([x1,x2])\n",
        "combined = Dense(n_neurons, activation='gelu')(combined)\n",
        "output = Dense(25, activation='linear')(combined)\n",
        "\n",
        "# Create the model\n",
        "model_h = Model(inputs=[input_params,input_pod], outputs=output)\n",
        "\n",
        "\n",
        "model_h = load_model(f'models/model_2step_50-25resolution_{n_samples}samples_1_coeff{coeff}.keras')\n",
        "\n",
        "model_lf = lambda input : model_l(input.reshape(1,64)).numpy().reshape(25)\n",
        "model_hf = lambda input: model_h([input.reshape(1,64), model_l(input.reshape(1,64)).numpy()]).numpy().reshape(25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time Low Fidelity 0.002644597616700048\n",
            "Time High Fidelity 0.006013955195900053\n",
            "The High/Low :  2.2740530196061806\n"
          ]
        }
      ],
      "source": [
        "start_0 = timeit.default_timer() \n",
        "fine_predictions = [model_lf(X[1]) for i in range(10000)]\n",
        "end_0 = timeit.default_timer()\n",
        "\n",
        "start_1 = timeit.default_timer() \n",
        "fine_predictions = [model_hf(X[1]) for i in range(10000)]\n",
        "end_1= timeit.default_timer()\n",
        "\n",
        "\n",
        "print('Time Low Fidelity', (end_0-start_0)/10000)\n",
        "print('Time High Fidelity', (end_1-start_1)/10000)\n",
        "print('The High/Low : ', (end_1 - start_1)/(end_0 - start_0) )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# FROM HERE ON USE FENICS ENVIRONMENT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Standard library imports\n",
        "import sys\n",
        "\n",
        "import os\n",
        "os.environ['OPENBLAS_NUM_THREADS'] = '1'\n",
        "os.environ['OMP_NUM_THREADS'] = '1'\n",
        "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
        "\n",
        "# Third-party library imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import gaussian_kde\n",
        "import arviz as az\n",
        "import timeit\n",
        "\n",
        "import scipy.stats as stats\n",
        "from keras.models import Model as Model_nn\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, Concatenate\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.layers import Input, Dense, Add\n",
        "\n",
        "#Try with TinyDA\n",
        "import tinyDA as tda\n",
        "from scipy.stats import multivariate_normal\n",
        "from scipy.stats import uniform\n",
        "from itertools import product\n",
        "\n",
        "# Local module imports\n",
        "sys.path.append('../../')\n",
        "sys.path.append('../../solver')\n",
        "#sys.path.append('./src/InverseProblems')\n",
        "#sys.path.append('./src/utils')\n",
        "from utils import * \n",
        "from plotting import *\n",
        "from random_process import *\n",
        "from model import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract test data for visualization or further processing\n",
        "n_eig = 64\n",
        "X = np.loadtxt('../../data/50-25-10/X_test_50resolution.csv', delimiter = ',')\n",
        "y = np.loadtxt('../../data/50-25-10/y_test_50resolution.csv',delimiter = ',')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Resolution parameters\n",
        "resolution_h1 = (50, 50)\n",
        "resolution_h2 = (25, 25)\n",
        "resolution_h3 = (10, 10)\n",
        "\n",
        "# PDE parameters\n",
        "field_mean = 1\n",
        "field_stdev = 1\n",
        "lamb_cov = 0.1\n",
        "mkl = 64\n",
        "\n",
        "# Set up the model(s)\n",
        "solver_h1 = Model(resolution_h1, field_mean, field_stdev, mkl, lamb_cov)\n",
        "solver_h2 = Model(resolution_h2, field_mean, field_stdev, mkl, lamb_cov)\n",
        "solver_h3 = Model(resolution_h3, field_mean, field_stdev, 32, lamb_cov)\n",
        "\n",
        "\n",
        "# Adjust the trasmissivity based on h1\n",
        "list1 = solver_h1.solver.mesh.coordinates()\n",
        "list2 = solver_h2.solver.mesh.coordinates()\n",
        "list3 = solver_h3.solver.mesh.coordinates()\n",
        "\n",
        "# Convert lists to numpy arrays if they are not already\n",
        "array1 = np.array(list1)\n",
        "array2 = np.array(list2)\n",
        "array3 = np.array(list3)\n",
        "\n",
        "# Convert to structured arrays for easy row-wise comparison\n",
        "dtype = {'names': ['f{}'.format(i) for i in range(array1.shape[1])],\n",
        "         'formats': [array1.dtype] * array1.shape[1]}\n",
        "\n",
        "structured_array1 = array1.view(dtype)\n",
        "structured_array2 = array2.view(dtype)\n",
        "structured_array3 = array3.view(dtype)\n",
        "\n",
        "# Create the boolean vector by checking if each row in array1 is in array2\n",
        "bool_vector2 = np.in1d(structured_array1, structured_array2)\n",
        "bool_vector3 = np.in1d(structured_array1, structured_array3)\n",
        "\n",
        "# Set the trasmissivity field\n",
        "solver_h2.random_process.eigenvalues = solver_h1.random_process.eigenvalues\n",
        "solver_h2.random_process.eigenvectors = solver_h1.random_process.eigenvectors[bool_vector2]\n",
        "\n",
        "solver_h3.random_process.eigenvalues = solver_h1.random_process.eigenvalues\n",
        "solver_h3.random_process.eigenvectors = solver_h1.random_process.eigenvectors[bool_vector3]\n",
        "\n",
        "x_data = y_data = np.array([0.1, 0.3, 0.5, 0.7, 0.9])\n",
        "datapoints = np.array(list(product(x_data, y_data)))\n",
        "\n",
        "def solver_h1_data(x):\n",
        "    solver_h1.solve(x)\n",
        "    return solver_h1.get_data(datapoints)\n",
        "\n",
        "def solver_h2_data(x):\n",
        "    solver_h2.solve(x)\n",
        "    return solver_h2.get_data(datapoints)\n",
        "\n",
        "def solver_h3_data(x):\n",
        "    solver_h3.solve(x)\n",
        "    return solver_h3.get_data(datapoints)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time 50x50 resolution 0.011860543991799932\n",
            "Time 25x25 resolution 0.00481061140820093\n",
            "Time 10x10 resolution 0.0038268086416006555\n",
            "The 50/25 :  2.465496167821947\n",
            "Time 50/10: 3.0993303043339457\n",
            "Time 25/10: 1.257081777203465\n"
          ]
        }
      ],
      "source": [
        "n = 5000\n",
        "start_0 = timeit.default_timer() \n",
        "fine_predictions = [solver_h1_data(X[1]) for i in range(n)]\n",
        "end_0 = timeit.default_timer()\n",
        "\n",
        "start_1 = timeit.default_timer() \n",
        "fine_predictions = [solver_h2_data(X[1]) for i in range(n)]\n",
        "end_1= timeit.default_timer()\n",
        "\n",
        "start_2 = timeit.default_timer() \n",
        "fine_predictions = [solver_h3_data(X[1]) for i in range(n)]\n",
        "end_2= timeit.default_timer()\n",
        "\n",
        "\n",
        "print('Time 50x50 resolution', (end_0-start_0)/n)\n",
        "print('Time 25x25 resolution', (end_1-start_1)/n)\n",
        "print('Time 10x10 resolution', (end_2-start_2)/n)\n",
        "print('The 50/25 : ', (end_0 - start_0)/(end_1 - start_1) )\n",
        "print('Time 50/10:',(end_0 - start_0)/(end_2 - start_2) )\n",
        "print('Time 25/10:',(end_1 - start_1)/(end_2 - start_2) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/lucacaroselli/miniconda3/envs/fenics/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "### LOW FIDELITY\n",
        "# Choose the model parameters \n",
        "n_samples_lf = 64000\n",
        "coeff_lf = 1e-09\n",
        "# Choose the model parameters \n",
        "n_samples = 16000\n",
        "coeff = 1e-08\n",
        "# Initialize the neural network model\n",
        "model_l = Sequential([\n",
        "    Dense(256, input_shape=(X.shape[1],), activation='gelu'),\n",
        "    Dense(256, activation='gelu'),\n",
        "    Dense(256, activation='gelu'),\n",
        "    Dense(256, activation='gelu'),\n",
        "    Dense(256, activation='gelu'),\n",
        "    Dense(256, activation='gelu'),\n",
        "    Dense(25, activation='linear')\n",
        "])\n",
        "\n",
        "model_l = load_model(f'models/model_25resolution_{n_samples_lf}samples_1_coeff{coeff_lf}.keras')\n",
        "\n",
        "\n",
        "## MULTIFIDELITY 2STEP \n",
        "n_neurons = 256\n",
        "# Initialize the neural network model\n",
        "# Define the three branches of the model\n",
        "input_params = Input(shape=(X.shape[1],))\n",
        "input_pod = Input(shape=(y.shape[1],))\n",
        "\n",
        "# Define the first branch (parameters)\n",
        "x1 = Dense(n_neurons, activation='gelu')(input_params)\n",
        "x1 = Dense(n_neurons, activation='gelu')(x1)\n",
        "x1 = Dense(n_neurons, activation='gelu')(x1)\n",
        "x1 = Dense(n_neurons, activation='gelu')(x1)\n",
        "x1 = Dense(n_neurons, activation='gelu')(x1)\n",
        "x1 = Dense(n_neurons, activation='gelu')(x1)\n",
        "\n",
        "# Define the second branch (POD)\n",
        "x2 = Dense(n_neurons, activation='gelu')(input_pod)\n",
        "\n",
        "# # Define the second branch (POD)\n",
        "# x3 = Dense(n_neurons, activation='gelu', kernel_regularizer=l2(w))(input_nn)\n",
        "\n",
        "# Combine the outputs of the three branches\n",
        "combined = Add()([x1,x2])\n",
        "combined = Dense(n_neurons, activation='gelu')(combined)\n",
        "output = Dense(25, activation='linear')(combined)\n",
        "\n",
        "# Create the model\n",
        "model_h = Model_nn(inputs=[input_params,input_pod], outputs=output)\n",
        "\n",
        "\n",
        "model_h = load_model(f'models/model_2step_50-25resolution_{n_samples}samples_1_coeff{coeff}.keras')\n",
        "\n",
        "model_lf = lambda input : model_l(input.reshape(1,64)).numpy().reshape(25)\n",
        "model_hf = lambda input: model_h([input.reshape(1,64), model_l(input.reshape(1,64)).numpy()]).numpy().reshape(25)\n",
        "model_hf1step = lambda input: model_h([input.reshape(1,64), solver_h2_data(input).reshape(1,25)]).numpy().reshape(25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time Low Fidelity 0.004166737066699715\n",
            "Time MF 2 step 0.009688190829100494\n",
            "Time MF 1 step 0.011162845854200713\n",
            "The 2Step/Low :  2.325126513628102\n",
            "The 1Step/Low :  2.6790377399652674\n",
            "The 1Step/2Step:  1.1522115997829838\n"
          ]
        }
      ],
      "source": [
        "start_0 = timeit.default_timer() \n",
        "fine_predictions = [model_lf(X[1]) for i in range(10000)]\n",
        "end_0 = timeit.default_timer()\n",
        "\n",
        "start_1 = timeit.default_timer() \n",
        "fine_predictions = [model_hf(X[1]) for i in range(10000)]\n",
        "end_1= timeit.default_timer()\n",
        "\n",
        "start_2 = timeit.default_timer() \n",
        "fine_predictions = [model_hf1step(X[1]) for i in range(10000)]\n",
        "end_2= timeit.default_timer()\n",
        "\n",
        "print('Time Low Fidelity', (end_0-start_0)/10000)\n",
        "print('Time MF 2 step', (end_1-start_1)/10000)\n",
        "print('Time MF 1 step', (end_2-start_2)/10000)\n",
        "print('The 2Step/Low : ', (end_1 - start_1)/(end_0 - start_0) )\n",
        "print('The 1Step/Low : ', (end_2 - start_2)/(end_0 - start_0) )\n",
        "print('The 1Step/2Step: ', (end_2 - start_2)/(end_1 - start_1) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOLKvMRTaykHpCaydJMPm9E",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
