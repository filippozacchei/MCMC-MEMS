{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ContiPaolo/Multifidelity-Tutorial/blob/main/MF_POD_Burger's1D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Creation of the Multilevel dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here we compute for each sample the coarse FEM solution that will then be given as imput to the NN of the fine level"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WP3luMxfaY7N"
      },
      "source": [
        "#### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dUChnEGpNaQE"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-07-04 17:17:56.810671: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: SSE4.1 SSE4.2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "#import matplotlib as plt\n",
        "from matplotlib import pyplot as plt\n",
        "from itertools import product\n",
        "import timeit\n",
        "import pandas as pd \n",
        "from keras.optimizers import Adam,Nadam,Adamax\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, LSTM, Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "from keras.models import load_model\n",
        "from sklearn.utils import extmath\n",
        "from fenics import *\n",
        "\n",
        "import sys\n",
        "sys.path.append('./solver')\n",
        "from model import *\n",
        "#######################     CONFIGURATIONS     ##########################\n",
        "seed = 29\n",
        "train = True\n",
        "save = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import the dataset "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train = np.loadtxt('./data/X_train.csv', delimiter = ',')\n",
        "y_train = np.loadtxt('./data/y_train.csv', delimiter = ',')\n",
        "\n",
        "X_test = np.loadtxt('./data/X_test.csv', delimiter = ',')\n",
        "y_test = np.loadtxt('./data/y_test.csv',delimiter = ',')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set the resolution of the model and the random field parameters.\n",
        "resolution_fine = (50, 50)\n",
        "resolution_coarse = (25, 25)\n",
        "field_mean = 1\n",
        "field_stdev = 1\n",
        "lamb_cov = 0.1\n",
        "mkl = 64\n",
        "\n",
        "# set dataponts\n",
        "x_data = y_data = np.array([0.1, 0.3, 0.5, 0.7, 0.9])\n",
        "#x_data = y_data = np.linspace(0,1,26)\n",
        "datapoints = np.array(list(product(x_data, y_data)))\n",
        "n_datapoints = len(x_data)*len(y_data)\n",
        "\n",
        "# Set up the model(s)\n",
        "solver_c = Model(resolution_coarse, field_mean, field_stdev, mkl, lamb_cov)\n",
        "solver_f = Model(resolution_fine, field_mean, field_stdev, mkl, lamb_cov)\n",
        "\n",
        "\n",
        "def solver_fine(x):\n",
        "    solver_f.solve(x)\n",
        "    return solver_f.get_data(datapoints)\n",
        "\n",
        "\n",
        "def solver_coarse(x):\n",
        "    solver_c.solve(x)\n",
        "    return solver_c.get_data(datapoints)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compare the time for each solver"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time Coarse 0.005402068479099944\n",
            "Time Fine 0.012302980774999923\n",
            "\n",
            "The speedup coefficient is: 2.277457389257265\n"
          ]
        }
      ],
      "source": [
        "start_0 = timeit.default_timer() \n",
        "coarse_predictions = [solver_coarse(X_train[i,:]) for i in range(10000)]\n",
        "end_0 = timeit.default_timer()\n",
        " \n",
        "start_1 = timeit.default_timer() \n",
        "fine_predictions = [solver_fine(X_train[i,:]) for i in range(10000)]\n",
        "end_1= timeit.default_timer()\n",
        "\n",
        "print('Time Coarse', (end_0-start_0)/10000)\n",
        "print('Time Fine', (end_1-start_1)/10000)\n",
        "print('\\nThe speedup coefficient is:', (end_1 - start_1)/(end_0-start_0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Calculate the dataset that will be used to train the multilevel NN "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "coarse_sol = np.zeros((57600, n_datapoints))\n",
        "for i in range( 57600 ):\n",
        "    coarse_sol[i, :] = solver_coarse(X_train[i, :])\n",
        "\n",
        "X_full_train = np.hstack((X_train, coarse_sol))\n",
        "\n",
        "fine_sol = np.zeros((6400, n_datapoints))\n",
        "for i in range( 6400 ):\n",
        "    fine_sol[i, :] = solver_coarse(X_test[i, :])\n",
        "\n",
        "X_full_test = np.hstack((X_test, fine_sol))\n",
        "\n",
        "np.savetxt(\"./data/X_full_train.csv\",X_full_train , delimiter = \",\")\n",
        "np.savetxt(\"./data/X_full_test.csv\",X_full_test , delimiter = \",\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Time comparison with high fidelity NN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load medium level "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/lucacaroselli/miniconda3/envs/fenics/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "model_m = Sequential()\n",
        "\n",
        "model_m.add(Dense(256, input_shape=(89,), activation='gelu'))\n",
        "model_m.add(Dense(256, activation='gelu'))\n",
        "model_m.add(Dense(128, activation='gelu'))\n",
        "model_m.add(Dense(25, activation='exponential'))\n",
        "\n",
        "model = load_model('./models/model_HF_25_2.keras')\n",
        "\n",
        "def model_mf(x):\n",
        "    x_c = np.hstack([x,solver_coarse(x)]).reshape((1,89))\n",
        "    return model(x_c)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load model low fidelity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_l = Sequential()\n",
        "model_l.add(Dense(64, input_shape=(64,), activation='sigmoid'))\n",
        "model_l.add(Dense(128, activation='sigmoid'))\n",
        "model_l.add(Dense(25, activation='exponential'))\n",
        "model_l = load_model('./models/model_NN_64_sigmoid3.keras')\n",
        "\n",
        "def model_lf (input):\n",
        "    return np.array(model_l(input.reshape((1,64)))).reshape(25)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compare different speed "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time High Fidelity 0.012173732491700139\n",
            "Time Medium Fidelity 0.00817087467500005\n",
            "Time Low Fidelity 0.00817087467500005\n",
            "\n",
            "The speedup coefficient High / Medium is: 1.4898934295183108\n",
            "\n",
            "The speedup coefficient High / Low is: 7.475379334120851\n",
            "\n",
            "The speedup coefficient Medium / Low is: 5.017391973154533\n"
          ]
        }
      ],
      "source": [
        "start_0 = timeit.default_timer() \n",
        "fine_predictions = [solver_fine(X_train[i,:]) for i in range(10000)]\n",
        "end_0= timeit.default_timer()\n",
        "\n",
        "start_1 = timeit.default_timer() \n",
        "coarse_predictions = [model_mf(X_train[i,:]) for i in range(10000)]\n",
        "end_1 = timeit.default_timer()\n",
        " \n",
        "start_2 = timeit.default_timer() \n",
        "fine_predictions = [model_lf(X_train[i,:]) for i in range(10000)]\n",
        "end_2= timeit.default_timer()\n",
        "\n",
        "\n",
        "print('Time High Fidelity', (end_0-start_0)/10000)\n",
        "print('Time Medium Fidelity', (end_1-start_1)/10000)\n",
        "print('Time Low Fidelity', (end_1-start_1)/10000)\n",
        "print('\\nThe speedup coefficient High / Medium is:', (end_0 - start_0)/(end_1-start_1))\n",
        "print('\\nThe speedup coefficient High / Low is:', (end_0 - start_0)/(end_2-start_2))\n",
        "print('\\nThe speedup coefficient Medium / Low is:', (end_1 - start_1)/(end_2-start_2))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOLKvMRTaykHpCaydJMPm9E",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
