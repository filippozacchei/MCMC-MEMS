{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ContiPaolo/Multifidelity-Tutorial/blob/main/MF_POD_Burger's1D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXejdLL8NbTY"
      },
      "source": [
        "# **Multi-fidelity reduced-order modeling on Groundwater's flow - Darcy equation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNXEcOy7YdZp"
      },
      "source": [
        "As seen in the identification with the FOM model the nature of the problem poses a limitation on the accuracy of recontruction.\n",
        "It is shown that any model with an accuracy higher that 0.01 will be masked by the noise and, more importantly, by the likelyhood. This is due to the need to explore a high dimentional space (n = 64)\n",
        "\n",
        "We put ourself in the context of a FOM model that is extremely expensive. It would be therefore usefull to be able to retrieve the needed accuracy of the model using the least possibile training data. \n",
        "\n",
        "We aim to create a system with two levels of fidelity using 16000 data fine. \n",
        "\n",
        "The first level will be a Neural Network that, recieving as inputs the 64 coefficients of the trasmissivity field, tries to predict the 25 output values \n",
        "\n",
        "The second level of fidelity is intended as a refinement of the first model. Indeed it recieved as inputs the paramaters and the 25 coarse solution to predict the fine 25 solution "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNpr9aLtZ8bU"
      },
      "source": [
        "#### (1) **Importing libraries and Loading data** \n",
        "#### (2) **Training of Coarse level surrogate model**\n",
        "#### (3) **Generation of multi-fidelity dataset**\n",
        "#### (4) **Training Fine level neural network surrogate model**\n",
        "#### (5) **Evaluation of different models**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WP3luMxfaY7N"
      },
      "source": [
        "### 1 ) Libraries and Data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dUChnEGpNaQE"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "#import matplotlib as plt\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd \n",
        "from tensorflow.keras.optimizers import Adam,Nadam,Adamax\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, LSTM, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "from tensorflow.keras.models import load_model\n",
        "from keras.regularizers import l2\n",
        "from sklearn.utils import extmath\n",
        "\n",
        "#######################     CONFIGURATIONS     ##########################\n",
        "seed = 29\n",
        "train = True\n",
        "save = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Choose the number of data used to train the models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "N = 16000\n",
        "n_t = 1000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "64"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_test = np.loadtxt(\"./data/X_test_64000.csv\" , delimiter = \",\")[:n_t]\n",
        "y_test = np.loadtxt(\"./data/y_test_64000.csv\" , delimiter = \",\")[:n_t]\n",
        "\n",
        "X_train =np.loadtxt(\"./data/X_train_64000.csv\" , delimiter = \",\")[:N]\n",
        "y_train =np.loadtxt(\"./data/y_train_64000.csv\" , delimiter = \",\")[:N]\n",
        "\n",
        "n_c = X_train.shape[1]\n",
        "n_c"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The dataset has been developed using fenics library, it is composed of 64000 samples divided in 90% training and 10% testing.\\\n",
        "The input (or X) are the 64 first component of the Karhunen-Loève (KL) decompositions. \\\n",
        "These eigenmodes allow to paratetrize a random field in the most accurate way."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The output: 25 sensors are used to record the hydraulic pressure in the domain $\\Omega$ = [ 0 , 1 ] x [ 0 , 1 ]  \\\n",
        "The sensors are distributed on a grid with positions [0.1, 0.3, 0.5, 0.7, 0.9]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2 ) Training Fully connected neural network surrogate model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let us try to create a map $T(x) \\rightarrow u(x)$ \n",
        "\n",
        "Create a NN that takes in inuput the 64 eigenvalues of the transittivity field and returns the hydraulic pressure in the 25 points where the sensors are located \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 995us/step - loss: 0.0862 - val_loss: 0.0063 - learning_rate: 0.0010\n",
            "Epoch 2/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 719us/step - loss: 0.0053 - val_loss: 0.0038 - learning_rate: 0.0010\n",
            "Epoch 3/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705us/step - loss: 0.0034 - val_loss: 0.0027 - learning_rate: 0.0010\n",
            "Epoch 4/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 708us/step - loss: 0.0025 - val_loss: 0.0022 - learning_rate: 0.0010\n",
            "Epoch 5/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705us/step - loss: 0.0020 - val_loss: 0.0018 - learning_rate: 0.0010\n",
            "Epoch 6/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - loss: 0.0016 - val_loss: 0.0016 - learning_rate: 0.0010\n",
            "Epoch 7/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step - loss: 0.0014 - val_loss: 0.0014 - learning_rate: 0.0010\n",
            "Epoch 8/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 706us/step - loss: 0.0012 - val_loss: 0.0012 - learning_rate: 0.0010\n",
            "Epoch 9/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 708us/step - loss: 0.0011 - val_loss: 0.0011 - learning_rate: 0.0010\n",
            "Epoch 10/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - loss: 9.2572e-04 - val_loss: 9.2963e-04 - learning_rate: 0.0010\n",
            "Epoch 11/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - loss: 8.3495e-04 - val_loss: 8.5037e-04 - learning_rate: 9.9000e-04\n",
            "Epoch 12/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 724us/step - loss: 7.5631e-04 - val_loss: 7.5317e-04 - learning_rate: 9.8010e-04\n",
            "Epoch 13/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709us/step - loss: 6.7191e-04 - val_loss: 6.9632e-04 - learning_rate: 9.7030e-04\n",
            "Epoch 14/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 706us/step - loss: 6.2165e-04 - val_loss: 6.4630e-04 - learning_rate: 9.6060e-04\n",
            "Epoch 15/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 704us/step - loss: 5.6883e-04 - val_loss: 5.9600e-04 - learning_rate: 9.5099e-04\n",
            "Epoch 16/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 723us/step - loss: 5.2320e-04 - val_loss: 5.5229e-04 - learning_rate: 9.4148e-04\n",
            "Epoch 17/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - loss: 4.8807e-04 - val_loss: 5.2549e-04 - learning_rate: 9.3207e-04\n",
            "Epoch 18/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - loss: 4.5805e-04 - val_loss: 5.0250e-04 - learning_rate: 9.2274e-04\n",
            "Epoch 19/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step - loss: 4.2373e-04 - val_loss: 4.6472e-04 - learning_rate: 9.1352e-04\n",
            "Epoch 20/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step - loss: 3.9987e-04 - val_loss: 4.4547e-04 - learning_rate: 9.0438e-04\n",
            "Epoch 21/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step - loss: 3.8428e-04 - val_loss: 4.1337e-04 - learning_rate: 8.9534e-04\n",
            "Epoch 22/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step - loss: 3.6177e-04 - val_loss: 3.9799e-04 - learning_rate: 8.8638e-04\n",
            "Epoch 23/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 721us/step - loss: 3.4452e-04 - val_loss: 3.8505e-04 - learning_rate: 8.7752e-04\n",
            "Epoch 24/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 726us/step - loss: 3.3608e-04 - val_loss: 3.7893e-04 - learning_rate: 8.6875e-04\n",
            "Epoch 25/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.1654e-04 - val_loss: 3.4751e-04 - learning_rate: 8.6006e-04\n",
            "Epoch 26/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 716us/step - loss: 3.0642e-04 - val_loss: 3.4412e-04 - learning_rate: 8.5146e-04\n",
            "Epoch 27/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 716us/step - loss: 2.9699e-04 - val_loss: 3.3248e-04 - learning_rate: 8.4294e-04\n",
            "Epoch 28/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 759us/step - loss: 2.8574e-04 - val_loss: 3.2641e-04 - learning_rate: 8.3451e-04\n",
            "Epoch 29/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step - loss: 2.7792e-04 - val_loss: 3.0692e-04 - learning_rate: 8.2617e-04\n",
            "Epoch 30/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712us/step - loss: 2.6865e-04 - val_loss: 3.0774e-04 - learning_rate: 8.1791e-04\n",
            "Epoch 31/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 708us/step - loss: 2.5583e-04 - val_loss: 2.9213e-04 - learning_rate: 8.0973e-04\n",
            "Epoch 32/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 755us/step - loss: 2.4953e-04 - val_loss: 2.8888e-04 - learning_rate: 8.0163e-04\n",
            "Epoch 33/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 791us/step - loss: 2.4615e-04 - val_loss: 2.7505e-04 - learning_rate: 7.9361e-04\n",
            "Epoch 34/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - loss: 2.3644e-04 - val_loss: 2.7156e-04 - learning_rate: 7.8568e-04\n",
            "Epoch 35/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747us/step - loss: 2.2811e-04 - val_loss: 2.5891e-04 - learning_rate: 7.7782e-04\n",
            "Epoch 36/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750us/step - loss: 2.2340e-04 - val_loss: 2.5525e-04 - learning_rate: 7.7004e-04\n",
            "Epoch 37/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - loss: 2.1585e-04 - val_loss: 2.4993e-04 - learning_rate: 7.6234e-04\n",
            "Epoch 38/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 754us/step - loss: 2.1296e-04 - val_loss: 2.5746e-04 - learning_rate: 7.5472e-04\n",
            "Epoch 39/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - loss: 2.1198e-04 - val_loss: 2.4190e-04 - learning_rate: 7.4717e-04\n",
            "Epoch 40/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - loss: 2.0129e-04 - val_loss: 2.4428e-04 - learning_rate: 7.3970e-04\n",
            "Epoch 41/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 706us/step - loss: 1.9642e-04 - val_loss: 2.3101e-04 - learning_rate: 7.3230e-04\n",
            "Epoch 42/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712us/step - loss: 1.9296e-04 - val_loss: 2.4219e-04 - learning_rate: 7.2498e-04\n",
            "Epoch 43/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711us/step - loss: 1.9136e-04 - val_loss: 2.1843e-04 - learning_rate: 7.1773e-04\n",
            "Epoch 44/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781us/step - loss: 1.8760e-04 - val_loss: 2.3141e-04 - learning_rate: 7.1055e-04\n",
            "Epoch 45/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705us/step - loss: 1.8077e-04 - val_loss: 2.2581e-04 - learning_rate: 7.0345e-04\n",
            "Epoch 46/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - loss: 1.8097e-04 - val_loss: 2.1238e-04 - learning_rate: 6.9641e-04\n",
            "Epoch 47/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - loss: 1.7732e-04 - val_loss: 2.0951e-04 - learning_rate: 6.8945e-04\n",
            "Epoch 48/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - loss: 1.7611e-04 - val_loss: 2.1473e-04 - learning_rate: 6.8255e-04\n",
            "Epoch 49/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 704us/step - loss: 1.6869e-04 - val_loss: 2.1276e-04 - learning_rate: 6.7573e-04\n",
            "Epoch 50/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - loss: 1.6659e-04 - val_loss: 2.0354e-04 - learning_rate: 6.6897e-04\n",
            "Epoch 51/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - loss: 1.6602e-04 - val_loss: 1.9803e-04 - learning_rate: 6.6228e-04\n",
            "Epoch 52/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - loss: 1.5760e-04 - val_loss: 2.0376e-04 - learning_rate: 6.5566e-04\n",
            "Epoch 53/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692us/step - loss: 1.5690e-04 - val_loss: 1.9273e-04 - learning_rate: 6.4910e-04\n",
            "Epoch 54/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 1.5578e-04 - val_loss: 1.8983e-04 - learning_rate: 6.4261e-04\n",
            "Epoch 55/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - loss: 1.5628e-04 - val_loss: 1.9045e-04 - learning_rate: 6.3619e-04\n",
            "Epoch 56/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - loss: 1.5265e-04 - val_loss: 1.9037e-04 - learning_rate: 6.2982e-04\n",
            "Epoch 57/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - loss: 1.5288e-04 - val_loss: 1.8385e-04 - learning_rate: 6.2353e-04\n",
            "Epoch 58/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 706us/step - loss: 1.4892e-04 - val_loss: 1.8971e-04 - learning_rate: 6.1729e-04\n",
            "Epoch 59/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - loss: 1.4600e-04 - val_loss: 1.8210e-04 - learning_rate: 6.1112e-04\n",
            "Epoch 60/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - loss: 1.4673e-04 - val_loss: 1.8599e-04 - learning_rate: 6.0501e-04\n",
            "Epoch 61/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - loss: 1.4191e-04 - val_loss: 1.8637e-04 - learning_rate: 5.9896e-04\n",
            "Epoch 62/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 769us/step - loss: 1.4078e-04 - val_loss: 1.7783e-04 - learning_rate: 5.9297e-04\n",
            "Epoch 63/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - loss: 1.3944e-04 - val_loss: 1.8318e-04 - learning_rate: 5.8704e-04\n",
            "Epoch 64/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 706us/step - loss: 1.3882e-04 - val_loss: 1.7789e-04 - learning_rate: 5.8117e-04\n",
            "Epoch 65/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 718us/step - loss: 1.3586e-04 - val_loss: 1.7293e-04 - learning_rate: 5.7535e-04\n",
            "Epoch 66/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - loss: 1.3405e-04 - val_loss: 1.6716e-04 - learning_rate: 5.6960e-04\n",
            "Epoch 67/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - loss: 1.3189e-04 - val_loss: 1.7211e-04 - learning_rate: 5.6391e-04\n",
            "Epoch 68/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step - loss: 1.3069e-04 - val_loss: 1.7151e-04 - learning_rate: 5.5827e-04\n",
            "Epoch 69/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 771us/step - loss: 1.3055e-04 - val_loss: 1.6744e-04 - learning_rate: 5.5268e-04\n",
            "Epoch 70/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - loss: 1.2981e-04 - val_loss: 1.6269e-04 - learning_rate: 5.4716e-04\n",
            "Epoch 71/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - loss: 1.2823e-04 - val_loss: 1.6174e-04 - learning_rate: 5.4169e-04\n",
            "Epoch 72/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - loss: 1.2572e-04 - val_loss: 1.6207e-04 - learning_rate: 5.3627e-04\n",
            "Epoch 73/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 704us/step - loss: 1.2639e-04 - val_loss: 1.6324e-04 - learning_rate: 5.3091e-04\n",
            "Epoch 74/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687us/step - loss: 1.2430e-04 - val_loss: 1.6576e-04 - learning_rate: 5.2560e-04\n",
            "Epoch 75/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - loss: 1.2398e-04 - val_loss: 1.5792e-04 - learning_rate: 5.2034e-04\n",
            "Epoch 76/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688us/step - loss: 1.2237e-04 - val_loss: 1.5883e-04 - learning_rate: 5.1514e-04\n",
            "Epoch 77/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - loss: 1.2077e-04 - val_loss: 1.5617e-04 - learning_rate: 5.0999e-04\n",
            "Epoch 78/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 773us/step - loss: 1.1973e-04 - val_loss: 1.5292e-04 - learning_rate: 5.0489e-04\n",
            "Epoch 79/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - loss: 1.2008e-04 - val_loss: 1.5543e-04 - learning_rate: 4.9984e-04\n",
            "Epoch 80/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step - loss: 1.1738e-04 - val_loss: 1.5689e-04 - learning_rate: 4.9484e-04\n",
            "Epoch 81/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705us/step - loss: 1.1820e-04 - val_loss: 1.5865e-04 - learning_rate: 4.8989e-04\n",
            "Epoch 82/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - loss: 1.1403e-04 - val_loss: 1.5631e-04 - learning_rate: 4.8499e-04\n",
            "Epoch 83/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - loss: 1.1834e-04 - val_loss: 1.4789e-04 - learning_rate: 4.8014e-04\n",
            "Epoch 84/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - loss: 1.1375e-04 - val_loss: 1.4817e-04 - learning_rate: 4.7534e-04\n",
            "Epoch 85/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770us/step - loss: 1.1374e-04 - val_loss: 1.4820e-04 - learning_rate: 4.7059e-04\n",
            "Epoch 86/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - loss: 1.1343e-04 - val_loss: 1.5158e-04 - learning_rate: 4.6588e-04\n",
            "Epoch 87/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705us/step - loss: 1.1239e-04 - val_loss: 1.4830e-04 - learning_rate: 4.6122e-04\n",
            "Epoch 88/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - loss: 1.1020e-04 - val_loss: 1.4710e-04 - learning_rate: 4.5661e-04\n",
            "Epoch 89/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - loss: 1.0960e-04 - val_loss: 1.4367e-04 - learning_rate: 4.5204e-04\n",
            "Epoch 90/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step - loss: 1.0971e-04 - val_loss: 1.5447e-04 - learning_rate: 4.4752e-04\n",
            "Epoch 91/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step - loss: 1.0895e-04 - val_loss: 1.4655e-04 - learning_rate: 4.4305e-04\n",
            "Epoch 92/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - loss: 1.0806e-04 - val_loss: 1.4289e-04 - learning_rate: 4.3862e-04\n",
            "Epoch 93/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765us/step - loss: 1.0812e-04 - val_loss: 1.4165e-04 - learning_rate: 4.3423e-04\n",
            "Epoch 94/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - loss: 1.0830e-04 - val_loss: 1.3871e-04 - learning_rate: 4.2989e-04\n",
            "Epoch 95/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - loss: 1.0508e-04 - val_loss: 1.4270e-04 - learning_rate: 4.2559e-04\n",
            "Epoch 96/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - loss: 1.0536e-04 - val_loss: 1.3841e-04 - learning_rate: 4.2133e-04\n",
            "Epoch 97/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 718us/step - loss: 1.0377e-04 - val_loss: 1.3744e-04 - learning_rate: 4.1712e-04\n",
            "Epoch 98/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688us/step - loss: 1.0292e-04 - val_loss: 1.3602e-04 - learning_rate: 4.1295e-04\n",
            "Epoch 99/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 704us/step - loss: 1.0269e-04 - val_loss: 1.3799e-04 - learning_rate: 4.0882e-04\n",
            "Epoch 100/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - loss: 1.0376e-04 - val_loss: 1.3799e-04 - learning_rate: 4.0473e-04\n",
            "Epoch 101/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687us/step - loss: 1.0022e-04 - val_loss: 1.3970e-04 - learning_rate: 4.0068e-04\n",
            "Epoch 102/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 977us/step - loss: 1.0050e-04 - val_loss: 1.3350e-04 - learning_rate: 3.9668e-04\n",
            "Epoch 103/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - loss: 1.0089e-04 - val_loss: 1.3370e-04 - learning_rate: 3.9271e-04\n",
            "Epoch 104/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - loss: 9.8600e-05 - val_loss: 1.3727e-04 - learning_rate: 3.8878e-04\n",
            "Epoch 105/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - loss: 9.9514e-05 - val_loss: 1.3517e-04 - learning_rate: 3.8490e-04\n",
            "Epoch 106/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - loss: 9.7366e-05 - val_loss: 1.3211e-04 - learning_rate: 3.8105e-04\n",
            "Epoch 107/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 713us/step - loss: 9.8700e-05 - val_loss: 1.3058e-04 - learning_rate: 3.7724e-04\n",
            "Epoch 108/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - loss: 9.7687e-05 - val_loss: 1.3095e-04 - learning_rate: 3.7346e-04\n",
            "Epoch 109/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - loss: 9.6122e-05 - val_loss: 1.2840e-04 - learning_rate: 3.6973e-04\n",
            "Epoch 110/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - loss: 9.6407e-05 - val_loss: 1.3156e-04 - learning_rate: 3.6603e-04\n",
            "Epoch 111/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step - loss: 9.5629e-05 - val_loss: 1.2822e-04 - learning_rate: 3.6237e-04\n",
            "Epoch 112/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - loss: 9.6217e-05 - val_loss: 1.2929e-04 - learning_rate: 3.5875e-04\n",
            "Epoch 113/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767us/step - loss: 9.4306e-05 - val_loss: 1.3093e-04 - learning_rate: 3.5516e-04\n",
            "Epoch 114/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907us/step - loss: 9.4007e-05 - val_loss: 1.2541e-04 - learning_rate: 3.5161e-04\n",
            "Epoch 115/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - loss: 9.4529e-05 - val_loss: 1.2540e-04 - learning_rate: 3.4809e-04\n",
            "Epoch 116/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - loss: 9.3600e-05 - val_loss: 1.2826e-04 - learning_rate: 3.4461e-04\n",
            "Epoch 117/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - loss: 9.3719e-05 - val_loss: 1.2496e-04 - learning_rate: 3.4117e-04\n",
            "Epoch 118/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711us/step - loss: 9.1810e-05 - val_loss: 1.2563e-04 - learning_rate: 3.3775e-04\n",
            "Epoch 119/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - loss: 9.1166e-05 - val_loss: 1.2835e-04 - learning_rate: 3.3438e-04\n",
            "Epoch 120/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - loss: 9.2909e-05 - val_loss: 1.2588e-04 - learning_rate: 3.3103e-04\n",
            "Epoch 121/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - loss: 9.0900e-05 - val_loss: 1.2571e-04 - learning_rate: 3.2772e-04\n",
            "Epoch 122/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705us/step - loss: 9.0943e-05 - val_loss: 1.2677e-04 - learning_rate: 3.2445e-04\n",
            "Epoch 123/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 773us/step - loss: 9.0489e-05 - val_loss: 1.2571e-04 - learning_rate: 3.2120e-04\n",
            "Epoch 124/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step - loss: 9.0892e-05 - val_loss: 1.2090e-04 - learning_rate: 3.1799e-04\n",
            "Epoch 125/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - loss: 8.9670e-05 - val_loss: 1.3075e-04 - learning_rate: 3.1481e-04\n",
            "Epoch 126/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - loss: 8.8830e-05 - val_loss: 1.2402e-04 - learning_rate: 3.1166e-04\n",
            "Epoch 127/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - loss: 8.8870e-05 - val_loss: 1.2132e-04 - learning_rate: 3.0854e-04\n",
            "Epoch 128/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 921us/step - loss: 8.7772e-05 - val_loss: 1.2098e-04 - learning_rate: 3.0546e-04\n",
            "Epoch 129/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 704us/step - loss: 8.7597e-05 - val_loss: 1.2021e-04 - learning_rate: 3.0240e-04\n",
            "Epoch 130/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - loss: 8.8301e-05 - val_loss: 1.2268e-04 - learning_rate: 2.9938e-04\n",
            "Epoch 131/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - loss: 8.7559e-05 - val_loss: 1.2044e-04 - learning_rate: 2.9639e-04\n",
            "Epoch 132/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 773us/step - loss: 8.6578e-05 - val_loss: 1.1880e-04 - learning_rate: 2.9342e-04\n",
            "Epoch 133/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - loss: 8.6981e-05 - val_loss: 1.2028e-04 - learning_rate: 2.9049e-04\n",
            "Epoch 134/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - loss: 8.6365e-05 - val_loss: 1.1803e-04 - learning_rate: 2.8758e-04\n",
            "Epoch 135/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - loss: 8.5767e-05 - val_loss: 1.1650e-04 - learning_rate: 2.8471e-04\n",
            "Epoch 136/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - loss: 8.5571e-05 - val_loss: 1.1912e-04 - learning_rate: 2.8186e-04\n",
            "Epoch 137/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692us/step - loss: 8.4858e-05 - val_loss: 1.1890e-04 - learning_rate: 2.7904e-04\n",
            "Epoch 138/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - loss: 8.4312e-05 - val_loss: 1.1654e-04 - learning_rate: 2.7625e-04\n",
            "Epoch 139/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711us/step - loss: 8.5275e-05 - val_loss: 1.1676e-04 - learning_rate: 2.7349e-04\n",
            "Epoch 140/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 708us/step - loss: 8.6135e-05 - val_loss: 1.1559e-04 - learning_rate: 2.7075e-04\n",
            "Epoch 141/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step - loss: 8.3123e-05 - val_loss: 1.1685e-04 - learning_rate: 2.6805e-04\n",
            "Epoch 142/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 771us/step - loss: 8.4548e-05 - val_loss: 1.1545e-04 - learning_rate: 2.6537e-04\n",
            "Epoch 143/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - loss: 8.3220e-05 - val_loss: 1.1499e-04 - learning_rate: 2.6271e-04\n",
            "Epoch 144/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - loss: 8.4097e-05 - val_loss: 1.1193e-04 - learning_rate: 2.6009e-04\n",
            "Epoch 145/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step - loss: 8.2376e-05 - val_loss: 1.1526e-04 - learning_rate: 2.5748e-04\n",
            "Epoch 146/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - loss: 8.2782e-05 - val_loss: 1.1639e-04 - learning_rate: 2.5491e-04\n",
            "Epoch 147/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - loss: 8.1722e-05 - val_loss: 1.1244e-04 - learning_rate: 2.5236e-04\n",
            "Epoch 148/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - loss: 8.1622e-05 - val_loss: 1.1309e-04 - learning_rate: 2.4984e-04\n",
            "Epoch 149/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - loss: 8.3115e-05 - val_loss: 1.1582e-04 - learning_rate: 2.4734e-04\n",
            "Epoch 150/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 707us/step - loss: 8.1370e-05 - val_loss: 1.1222e-04 - learning_rate: 2.4487e-04\n",
            "Epoch 151/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - loss: 8.1598e-05 - val_loss: 1.1216e-04 - learning_rate: 2.4242e-04\n",
            "Epoch 152/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 777us/step - loss: 8.0483e-05 - val_loss: 1.1321e-04 - learning_rate: 2.3999e-04\n",
            "Epoch 153/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - loss: 8.0646e-05 - val_loss: 1.1115e-04 - learning_rate: 2.3759e-04\n",
            "Epoch 154/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 890us/step - loss: 7.9488e-05 - val_loss: 1.1259e-04 - learning_rate: 2.3522e-04\n",
            "Epoch 155/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - loss: 8.1149e-05 - val_loss: 1.1071e-04 - learning_rate: 2.3286e-04\n",
            "Epoch 156/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - loss: 7.9741e-05 - val_loss: 1.1243e-04 - learning_rate: 2.3054e-04\n",
            "Epoch 157/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - loss: 7.9431e-05 - val_loss: 1.1078e-04 - learning_rate: 2.2823e-04\n",
            "Epoch 158/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - loss: 8.0305e-05 - val_loss: 1.1117e-04 - learning_rate: 2.2595e-04\n",
            "Epoch 159/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - loss: 7.8446e-05 - val_loss: 1.1351e-04 - learning_rate: 2.2369e-04\n",
            "Epoch 160/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687us/step - loss: 7.9480e-05 - val_loss: 1.1084e-04 - learning_rate: 2.2145e-04\n",
            "Epoch 161/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step - loss: 7.8179e-05 - val_loss: 1.0848e-04 - learning_rate: 2.1924e-04\n",
            "Epoch 162/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 707us/step - loss: 7.8408e-05 - val_loss: 1.1041e-04 - learning_rate: 2.1705e-04\n",
            "Epoch 163/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - loss: 7.8430e-05 - val_loss: 1.0787e-04 - learning_rate: 2.1487e-04\n",
            "Epoch 164/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - loss: 7.7726e-05 - val_loss: 1.0946e-04 - learning_rate: 2.1273e-04\n",
            "Epoch 165/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684us/step - loss: 7.7075e-05 - val_loss: 1.0856e-04 - learning_rate: 2.1060e-04\n",
            "Epoch 166/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - loss: 7.7232e-05 - val_loss: 1.0829e-04 - learning_rate: 2.0849e-04\n",
            "Epoch 167/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - loss: 7.7777e-05 - val_loss: 1.0704e-04 - learning_rate: 2.0641e-04\n",
            "Epoch 168/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - loss: 7.6965e-05 - val_loss: 1.0755e-04 - learning_rate: 2.0434e-04\n",
            "Epoch 169/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705us/step - loss: 7.7095e-05 - val_loss: 1.0818e-04 - learning_rate: 2.0230e-04\n",
            "Epoch 170/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - loss: 7.7000e-05 - val_loss: 1.0848e-04 - learning_rate: 2.0028e-04\n",
            "Epoch 171/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705us/step - loss: 7.7396e-05 - val_loss: 1.0691e-04 - learning_rate: 1.9827e-04\n",
            "Epoch 172/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - loss: 7.6151e-05 - val_loss: 1.0686e-04 - learning_rate: 1.9629e-04\n",
            "Epoch 173/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - loss: 7.5747e-05 - val_loss: 1.0535e-04 - learning_rate: 1.9433e-04\n",
            "Epoch 174/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - loss: 7.5594e-05 - val_loss: 1.0576e-04 - learning_rate: 1.9239e-04\n",
            "Epoch 175/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692us/step - loss: 7.4618e-05 - val_loss: 1.0629e-04 - learning_rate: 1.9046e-04\n",
            "Epoch 176/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - loss: 7.5136e-05 - val_loss: 1.0827e-04 - learning_rate: 1.8856e-04\n",
            "Epoch 177/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step - loss: 7.4645e-05 - val_loss: 1.0530e-04 - learning_rate: 1.8667e-04\n",
            "Epoch 178/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 775us/step - loss: 7.5207e-05 - val_loss: 1.1225e-04 - learning_rate: 1.8480e-04\n",
            "Epoch 179/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step - loss: 7.4786e-05 - val_loss: 1.0688e-04 - learning_rate: 1.8296e-04\n",
            "Epoch 180/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - loss: 7.5095e-05 - val_loss: 1.0399e-04 - learning_rate: 1.8113e-04\n",
            "Epoch 181/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - loss: 7.4936e-05 - val_loss: 1.0611e-04 - learning_rate: 1.7932e-04\n",
            "Epoch 182/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 708us/step - loss: 7.4249e-05 - val_loss: 1.0469e-04 - learning_rate: 1.7752e-04\n",
            "Epoch 183/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - loss: 7.4050e-05 - val_loss: 1.0431e-04 - learning_rate: 1.7575e-04\n",
            "Epoch 184/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - loss: 7.3987e-05 - val_loss: 1.0312e-04 - learning_rate: 1.7399e-04\n",
            "Epoch 185/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - loss: 7.4233e-05 - val_loss: 1.0564e-04 - learning_rate: 1.7225e-04\n",
            "Epoch 186/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762us/step - loss: 7.3870e-05 - val_loss: 1.0351e-04 - learning_rate: 1.7053e-04\n",
            "Epoch 187/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - loss: 7.2904e-05 - val_loss: 1.0254e-04 - learning_rate: 1.6882e-04\n",
            "Epoch 188/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 733us/step - loss: 7.2662e-05 - val_loss: 1.0236e-04 - learning_rate: 1.6713e-04\n",
            "Epoch 189/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - loss: 7.3266e-05 - val_loss: 1.0246e-04 - learning_rate: 1.6546e-04\n",
            "Epoch 190/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - loss: 7.2223e-05 - val_loss: 1.0275e-04 - learning_rate: 1.6381e-04\n",
            "Epoch 191/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step - loss: 7.2335e-05 - val_loss: 1.0287e-04 - learning_rate: 1.6217e-04\n",
            "Epoch 192/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step - loss: 7.2005e-05 - val_loss: 1.0240e-04 - learning_rate: 1.6055e-04\n",
            "Epoch 193/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 713us/step - loss: 7.3122e-05 - val_loss: 1.0357e-04 - learning_rate: 1.5894e-04\n",
            "Epoch 194/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767us/step - loss: 7.2716e-05 - val_loss: 1.0379e-04 - learning_rate: 1.5735e-04\n",
            "Epoch 195/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - loss: 7.2074e-05 - val_loss: 1.0252e-04 - learning_rate: 1.5578e-04\n",
            "Epoch 196/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - loss: 7.1740e-05 - val_loss: 1.0151e-04 - learning_rate: 1.5422e-04\n",
            "Epoch 197/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687us/step - loss: 7.1465e-05 - val_loss: 1.0305e-04 - learning_rate: 1.5268e-04\n",
            "Epoch 198/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 896us/step - loss: 7.1728e-05 - val_loss: 1.0213e-04 - learning_rate: 1.5115e-04\n",
            "Epoch 199/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - loss: 7.1987e-05 - val_loss: 1.0417e-04 - learning_rate: 1.4964e-04\n",
            "Epoch 200/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - loss: 7.1778e-05 - val_loss: 1.0005e-04 - learning_rate: 1.4815e-04\n",
            "Epoch 201/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - loss: 7.0734e-05 - val_loss: 1.0094e-04 - learning_rate: 1.4666e-04\n",
            "Epoch 202/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 766us/step - loss: 7.0293e-05 - val_loss: 1.0042e-04 - learning_rate: 1.4520e-04\n",
            "Epoch 203/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 704us/step - loss: 7.0998e-05 - val_loss: 1.0084e-04 - learning_rate: 1.4374e-04\n",
            "Epoch 204/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - loss: 7.0435e-05 - val_loss: 1.0095e-04 - learning_rate: 1.4231e-04\n",
            "Epoch 205/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - loss: 7.1051e-05 - val_loss: 1.0086e-04 - learning_rate: 1.4088e-04\n",
            "Epoch 206/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - loss: 7.0108e-05 - val_loss: 9.8995e-05 - learning_rate: 1.3948e-04\n",
            "Epoch 207/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684us/step - loss: 7.0332e-05 - val_loss: 9.9356e-05 - learning_rate: 1.3808e-04\n",
            "Epoch 208/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - loss: 6.9960e-05 - val_loss: 1.0254e-04 - learning_rate: 1.3670e-04\n",
            "Epoch 209/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 766us/step - loss: 6.9775e-05 - val_loss: 1.0147e-04 - learning_rate: 1.3533e-04\n",
            "Epoch 210/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - loss: 6.9815e-05 - val_loss: 1.0060e-04 - learning_rate: 1.3398e-04\n",
            "Epoch 211/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - loss: 6.9311e-05 - val_loss: 9.9395e-05 - learning_rate: 1.3264e-04\n",
            "Epoch 212/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688us/step - loss: 7.0097e-05 - val_loss: 9.8756e-05 - learning_rate: 1.3131e-04\n",
            "Epoch 213/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 752us/step - loss: 6.9458e-05 - val_loss: 1.0006e-04 - learning_rate: 1.3000e-04\n",
            "Epoch 214/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 742us/step - loss: 7.0016e-05 - val_loss: 9.9211e-05 - learning_rate: 1.2870e-04\n",
            "Epoch 215/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684us/step - loss: 6.9164e-05 - val_loss: 9.9902e-05 - learning_rate: 1.2741e-04\n",
            "Epoch 216/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - loss: 6.9518e-05 - val_loss: 9.9518e-05 - learning_rate: 1.2614e-04\n",
            "Epoch 217/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 973us/step - loss: 6.9377e-05 - val_loss: 9.8262e-05 - learning_rate: 1.2488e-04\n",
            "Epoch 218/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692us/step - loss: 6.8738e-05 - val_loss: 9.9684e-05 - learning_rate: 1.2363e-04\n",
            "Epoch 219/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - loss: 6.8772e-05 - val_loss: 9.8800e-05 - learning_rate: 1.2239e-04\n",
            "Epoch 220/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - loss: 6.7856e-05 - val_loss: 9.9507e-05 - learning_rate: 1.2117e-04\n",
            "Epoch 221/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - loss: 6.8859e-05 - val_loss: 9.8274e-05 - learning_rate: 1.1996e-04\n",
            "Epoch 222/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - loss: 6.7471e-05 - val_loss: 9.7835e-05 - learning_rate: 1.1876e-04\n",
            "Epoch 223/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - loss: 6.8284e-05 - val_loss: 9.8179e-05 - learning_rate: 1.1757e-04\n",
            "Epoch 224/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774us/step - loss: 6.7298e-05 - val_loss: 9.8404e-05 - learning_rate: 1.1639e-04\n",
            "Epoch 225/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - loss: 6.8463e-05 - val_loss: 9.8291e-05 - learning_rate: 1.1523e-04\n",
            "Epoch 226/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - loss: 6.7695e-05 - val_loss: 9.7739e-05 - learning_rate: 1.1408e-04\n",
            "Epoch 227/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - loss: 6.8266e-05 - val_loss: 9.7738e-05 - learning_rate: 1.1294e-04\n",
            "Epoch 228/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - loss: 6.7408e-05 - val_loss: 9.9291e-05 - learning_rate: 1.1181e-04\n",
            "Epoch 229/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - loss: 6.8224e-05 - val_loss: 9.6170e-05 - learning_rate: 1.1069e-04\n",
            "Epoch 230/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - loss: 6.7539e-05 - val_loss: 9.7072e-05 - learning_rate: 1.0958e-04\n",
            "Epoch 231/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 759us/step - loss: 6.7805e-05 - val_loss: 9.6183e-05 - learning_rate: 1.0849e-04\n",
            "Epoch 232/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - loss: 6.7863e-05 - val_loss: 9.6498e-05 - learning_rate: 1.0740e-04\n",
            "Epoch 233/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - loss: 6.7163e-05 - val_loss: 9.6424e-05 - learning_rate: 1.0633e-04\n",
            "Epoch 234/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692us/step - loss: 6.7099e-05 - val_loss: 9.6512e-05 - learning_rate: 1.0526e-04\n",
            "Epoch 235/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913us/step - loss: 6.7135e-05 - val_loss: 9.6198e-05 - learning_rate: 1.0421e-04\n",
            "Epoch 236/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - loss: 6.6473e-05 - val_loss: 9.7625e-05 - learning_rate: 1.0317e-04\n",
            "Epoch 237/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - loss: 6.6693e-05 - val_loss: 9.6135e-05 - learning_rate: 1.0214e-04\n",
            "Epoch 238/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770us/step - loss: 6.6017e-05 - val_loss: 9.6018e-05 - learning_rate: 1.0112e-04\n",
            "Epoch 239/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step - loss: 6.6573e-05 - val_loss: 9.7923e-05 - learning_rate: 1.0011e-04\n",
            "Epoch 240/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 733us/step - loss: 6.6741e-05 - val_loss: 9.5024e-05 - learning_rate: 9.9105e-05\n",
            "Epoch 241/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - loss: 6.7248e-05 - val_loss: 9.5609e-05 - learning_rate: 9.8114e-05\n",
            "Epoch 242/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692us/step - loss: 6.6827e-05 - val_loss: 9.5616e-05 - learning_rate: 9.7133e-05\n",
            "Epoch 243/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - loss: 6.5996e-05 - val_loss: 9.5418e-05 - learning_rate: 9.6161e-05\n",
            "Epoch 244/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 974us/step - loss: 6.5783e-05 - val_loss: 9.6212e-05 - learning_rate: 9.5200e-05\n",
            "Epoch 245/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - loss: 6.5612e-05 - val_loss: 9.5058e-05 - learning_rate: 9.4248e-05\n",
            "Epoch 246/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - loss: 6.6235e-05 - val_loss: 9.5684e-05 - learning_rate: 9.3305e-05\n",
            "Epoch 247/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712us/step - loss: 6.6073e-05 - val_loss: 9.4716e-05 - learning_rate: 9.2372e-05\n",
            "Epoch 248/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705us/step - loss: 6.6031e-05 - val_loss: 9.4424e-05 - learning_rate: 9.1448e-05\n",
            "Epoch 249/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - loss: 6.6327e-05 - val_loss: 9.4875e-05 - learning_rate: 9.0534e-05\n",
            "Epoch 250/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 766us/step - loss: 6.5552e-05 - val_loss: 9.4406e-05 - learning_rate: 8.9629e-05\n",
            "Epoch 251/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - loss: 6.5878e-05 - val_loss: 9.4290e-05 - learning_rate: 8.8732e-05\n",
            "Epoch 252/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - loss: 6.5041e-05 - val_loss: 9.5726e-05 - learning_rate: 8.7845e-05\n",
            "Epoch 253/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705us/step - loss: 6.5570e-05 - val_loss: 9.4721e-05 - learning_rate: 8.6967e-05\n",
            "Epoch 254/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - loss: 6.5318e-05 - val_loss: 9.4295e-05 - learning_rate: 8.6097e-05\n",
            "Epoch 255/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - loss: 6.6143e-05 - val_loss: 9.4092e-05 - learning_rate: 8.5236e-05\n",
            "Epoch 256/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step - loss: 6.5253e-05 - val_loss: 9.4440e-05 - learning_rate: 8.4384e-05\n",
            "Epoch 257/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - loss: 6.4942e-05 - val_loss: 9.3634e-05 - learning_rate: 8.3540e-05\n",
            "Epoch 258/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - loss: 6.4805e-05 - val_loss: 9.4629e-05 - learning_rate: 8.2704e-05\n",
            "Epoch 259/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - loss: 6.4514e-05 - val_loss: 9.3560e-05 - learning_rate: 8.1877e-05\n",
            "Epoch 260/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - loss: 6.5014e-05 - val_loss: 9.4322e-05 - learning_rate: 8.1059e-05\n",
            "Epoch 261/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907us/step - loss: 6.4940e-05 - val_loss: 9.4151e-05 - learning_rate: 8.0248e-05\n",
            "Epoch 262/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 771us/step - loss: 6.5044e-05 - val_loss: 9.3028e-05 - learning_rate: 7.9445e-05\n",
            "Epoch 263/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - loss: 6.4529e-05 - val_loss: 9.3855e-05 - learning_rate: 7.8651e-05\n",
            "Epoch 264/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - loss: 6.4781e-05 - val_loss: 9.4819e-05 - learning_rate: 7.7865e-05\n",
            "Epoch 265/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - loss: 6.4942e-05 - val_loss: 9.3156e-05 - learning_rate: 7.7086e-05\n",
            "Epoch 266/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - loss: 6.4300e-05 - val_loss: 9.3576e-05 - learning_rate: 7.6315e-05\n",
            "Epoch 267/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 704us/step - loss: 6.4543e-05 - val_loss: 9.3545e-05 - learning_rate: 7.5552e-05\n",
            "Epoch 268/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757us/step - loss: 6.3938e-05 - val_loss: 9.3286e-05 - learning_rate: 7.4796e-05\n",
            "Epoch 269/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - loss: 6.4133e-05 - val_loss: 9.3323e-05 - learning_rate: 7.4048e-05\n",
            "Epoch 270/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - loss: 6.4533e-05 - val_loss: 9.2792e-05 - learning_rate: 7.3308e-05\n",
            "Epoch 271/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - loss: 6.3791e-05 - val_loss: 9.2718e-05 - learning_rate: 7.2575e-05\n",
            "Epoch 272/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - loss: 6.4429e-05 - val_loss: 9.3499e-05 - learning_rate: 7.1849e-05\n",
            "Epoch 273/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - loss: 6.3307e-05 - val_loss: 9.3078e-05 - learning_rate: 7.1131e-05\n",
            "Epoch 274/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692us/step - loss: 6.3892e-05 - val_loss: 9.2512e-05 - learning_rate: 7.0419e-05\n",
            "Epoch 275/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 672us/step - loss: 6.4322e-05 - val_loss: 9.3051e-05 - learning_rate: 6.9715e-05\n",
            "Epoch 276/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - loss: 6.3851e-05 - val_loss: 9.2472e-05 - learning_rate: 6.9018e-05\n",
            "Epoch 277/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - loss: 6.4096e-05 - val_loss: 9.2664e-05 - learning_rate: 6.8328e-05\n",
            "Epoch 278/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - loss: 6.4294e-05 - val_loss: 9.3310e-05 - learning_rate: 6.7644e-05\n",
            "Epoch 279/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - loss: 6.3707e-05 - val_loss: 9.2121e-05 - learning_rate: 6.6968e-05\n",
            "Epoch 280/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step - loss: 6.3190e-05 - val_loss: 9.1664e-05 - learning_rate: 6.6298e-05\n",
            "Epoch 281/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step - loss: 6.3075e-05 - val_loss: 9.1790e-05 - learning_rate: 6.5635e-05\n",
            "Epoch 282/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705us/step - loss: 6.3656e-05 - val_loss: 9.1753e-05 - learning_rate: 6.4979e-05\n",
            "Epoch 283/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - loss: 6.3879e-05 - val_loss: 9.2056e-05 - learning_rate: 6.4329e-05\n",
            "Epoch 284/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - loss: 6.3674e-05 - val_loss: 9.2742e-05 - learning_rate: 6.3686e-05\n",
            "Epoch 285/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 980us/step - loss: 6.3152e-05 - val_loss: 9.2359e-05 - learning_rate: 6.3049e-05\n",
            "Epoch 286/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - loss: 6.2827e-05 - val_loss: 9.2442e-05 - learning_rate: 6.2419e-05\n",
            "Epoch 287/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 706us/step - loss: 6.3561e-05 - val_loss: 9.1654e-05 - learning_rate: 6.1794e-05\n",
            "Epoch 288/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705us/step - loss: 6.3392e-05 - val_loss: 9.1083e-05 - learning_rate: 6.1176e-05\n",
            "Epoch 289/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step - loss: 6.3205e-05 - val_loss: 9.1759e-05 - learning_rate: 6.0565e-05\n",
            "Epoch 290/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 756us/step - loss: 6.2595e-05 - val_loss: 9.1769e-05 - learning_rate: 5.9959e-05\n",
            "Epoch 291/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - loss: 6.2448e-05 - val_loss: 9.2195e-05 - learning_rate: 5.9359e-05\n",
            "Epoch 292/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - loss: 6.2807e-05 - val_loss: 9.1991e-05 - learning_rate: 5.8766e-05\n",
            "Epoch 293/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - loss: 6.2940e-05 - val_loss: 9.1913e-05 - learning_rate: 5.8178e-05\n",
            "Epoch 294/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - loss: 6.2753e-05 - val_loss: 9.1558e-05 - learning_rate: 5.7596e-05\n",
            "Epoch 295/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692us/step - loss: 6.2958e-05 - val_loss: 9.1089e-05 - learning_rate: 5.7020e-05\n",
            "Epoch 296/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760us/step - loss: 6.3342e-05 - val_loss: 9.2383e-05 - learning_rate: 5.6450e-05\n",
            "Epoch 297/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - loss: 6.2931e-05 - val_loss: 9.1502e-05 - learning_rate: 5.5886e-05\n",
            "Epoch 298/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 717us/step - loss: 6.2567e-05 - val_loss: 9.0341e-05 - learning_rate: 5.5327e-05\n",
            "Epoch 299/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - loss: 6.2582e-05 - val_loss: 9.1170e-05 - learning_rate: 5.4774e-05\n",
            "Epoch 300/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - loss: 6.3113e-05 - val_loss: 9.1509e-05 - learning_rate: 5.4226e-05\n",
            "Epoch 301/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 756us/step - loss: 6.3031e-05 - val_loss: 9.0717e-05 - learning_rate: 5.3684e-05\n",
            "Epoch 302/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 676us/step - loss: 6.1955e-05 - val_loss: 9.0987e-05 - learning_rate: 5.3147e-05\n",
            "Epoch 303/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 704us/step - loss: 6.2636e-05 - val_loss: 9.1316e-05 - learning_rate: 5.2615e-05\n",
            "Epoch 304/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 674us/step - loss: 6.2232e-05 - val_loss: 9.0984e-05 - learning_rate: 5.2089e-05\n",
            "Epoch 305/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 680us/step - loss: 6.2532e-05 - val_loss: 9.1154e-05 - learning_rate: 5.1568e-05\n",
            "Epoch 306/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - loss: 6.2078e-05 - val_loss: 9.1078e-05 - learning_rate: 5.1053e-05\n",
            "Epoch 307/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step - loss: 6.1615e-05 - val_loss: 9.0245e-05 - learning_rate: 5.0542e-05\n",
            "Epoch 308/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688us/step - loss: 6.1437e-05 - val_loss: 9.0894e-05 - learning_rate: 5.0037e-05\n",
            "Epoch 309/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 716us/step - loss: 6.1995e-05 - val_loss: 9.1404e-05 - learning_rate: 4.9536e-05\n",
            "Epoch 310/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - loss: 6.1980e-05 - val_loss: 9.0004e-05 - learning_rate: 4.9041e-05\n",
            "Epoch 311/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - loss: 6.2032e-05 - val_loss: 9.0217e-05 - learning_rate: 4.8550e-05\n",
            "Epoch 312/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 769us/step - loss: 6.2762e-05 - val_loss: 9.0584e-05 - learning_rate: 4.8065e-05\n",
            "Epoch 313/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684us/step - loss: 6.1814e-05 - val_loss: 9.0135e-05 - learning_rate: 4.7584e-05\n",
            "Epoch 314/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692us/step - loss: 6.1084e-05 - val_loss: 9.0391e-05 - learning_rate: 4.7108e-05\n",
            "Epoch 315/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step - loss: 6.1474e-05 - val_loss: 9.0590e-05 - learning_rate: 4.6637e-05\n",
            "Epoch 316/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - loss: 6.1962e-05 - val_loss: 9.1690e-05 - learning_rate: 4.6171e-05\n",
            "Epoch 317/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770us/step - loss: 6.1202e-05 - val_loss: 9.0491e-05 - learning_rate: 4.5709e-05\n",
            "Epoch 318/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - loss: 6.1569e-05 - val_loss: 9.0372e-05 - learning_rate: 4.5252e-05\n",
            "Epoch 319/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711us/step - loss: 6.1503e-05 - val_loss: 8.9936e-05 - learning_rate: 4.4800e-05\n",
            "Epoch 320/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - loss: 6.1710e-05 - val_loss: 9.0692e-05 - learning_rate: 4.4352e-05\n",
            "Epoch 321/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - loss: 6.1308e-05 - val_loss: 9.0260e-05 - learning_rate: 4.3908e-05\n",
            "Epoch 322/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970us/step - loss: 6.0923e-05 - val_loss: 9.0475e-05 - learning_rate: 4.3469e-05\n",
            "Epoch 323/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - loss: 6.1077e-05 - val_loss: 8.9996e-05 - learning_rate: 4.3034e-05\n",
            "Epoch 324/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 682us/step - loss: 6.1285e-05 - val_loss: 8.9791e-05 - learning_rate: 4.2604e-05\n",
            "Epoch 325/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - loss: 6.0783e-05 - val_loss: 9.0215e-05 - learning_rate: 4.2178e-05\n",
            "Epoch 326/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - loss: 6.1379e-05 - val_loss: 8.9769e-05 - learning_rate: 4.1756e-05\n",
            "Epoch 327/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757us/step - loss: 6.1256e-05 - val_loss: 8.9884e-05 - learning_rate: 4.1339e-05\n",
            "Epoch 328/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858us/step - loss: 6.1848e-05 - val_loss: 8.9748e-05 - learning_rate: 4.0925e-05\n",
            "Epoch 329/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - loss: 6.1331e-05 - val_loss: 8.9435e-05 - learning_rate: 4.0516e-05\n",
            "Epoch 330/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 716us/step - loss: 6.1379e-05 - val_loss: 8.9495e-05 - learning_rate: 4.0111e-05\n",
            "Epoch 331/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 6.1257e-05 - val_loss: 8.9947e-05 - learning_rate: 3.9710e-05\n",
            "Epoch 332/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - loss: 6.1027e-05 - val_loss: 8.9284e-05 - learning_rate: 3.9313e-05\n",
            "Epoch 333/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - loss: 6.1717e-05 - val_loss: 8.9926e-05 - learning_rate: 3.8920e-05\n",
            "Epoch 334/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - loss: 6.1240e-05 - val_loss: 8.9436e-05 - learning_rate: 3.8530e-05\n",
            "Epoch 335/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900us/step - loss: 6.0999e-05 - val_loss: 8.9056e-05 - learning_rate: 3.8145e-05\n",
            "Epoch 336/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765us/step - loss: 6.0818e-05 - val_loss: 8.9703e-05 - learning_rate: 3.7764e-05\n",
            "Epoch 337/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - loss: 6.0920e-05 - val_loss: 8.9677e-05 - learning_rate: 3.7386e-05\n",
            "Epoch 338/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - loss: 6.1121e-05 - val_loss: 8.9937e-05 - learning_rate: 3.7012e-05\n",
            "Epoch 339/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - loss: 6.1223e-05 - val_loss: 9.0036e-05 - learning_rate: 3.6642e-05\n",
            "Epoch 340/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 771us/step - loss: 6.0880e-05 - val_loss: 8.9774e-05 - learning_rate: 3.6276e-05\n",
            "Epoch 341/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 894us/step - loss: 6.0496e-05 - val_loss: 8.9529e-05 - learning_rate: 3.5913e-05\n",
            "Epoch 342/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - loss: 6.0903e-05 - val_loss: 8.9299e-05 - learning_rate: 3.5554e-05\n",
            "Epoch 343/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - loss: 6.1054e-05 - val_loss: 8.9359e-05 - learning_rate: 3.5198e-05\n",
            "Epoch 344/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688us/step - loss: 6.0687e-05 - val_loss: 8.9002e-05 - learning_rate: 3.4846e-05\n",
            "Epoch 345/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770us/step - loss: 6.0612e-05 - val_loss: 8.9362e-05 - learning_rate: 3.4498e-05\n",
            "Epoch 346/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687us/step - loss: 6.0779e-05 - val_loss: 8.9346e-05 - learning_rate: 3.4153e-05\n",
            "Epoch 347/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - loss: 6.0855e-05 - val_loss: 8.9154e-05 - learning_rate: 3.3811e-05\n",
            "Epoch 348/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - loss: 6.0812e-05 - val_loss: 8.9221e-05 - learning_rate: 3.3473e-05\n",
            "Epoch 349/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 6.0617e-05 - val_loss: 8.8787e-05 - learning_rate: 3.3138e-05\n",
            "Epoch 350/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692us/step - loss: 6.0593e-05 - val_loss: 8.9988e-05 - learning_rate: 3.2807e-05\n",
            "Epoch 351/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 704us/step - loss: 6.0247e-05 - val_loss: 8.9708e-05 - learning_rate: 3.2479e-05\n",
            "Epoch 352/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - loss: 6.0421e-05 - val_loss: 8.9175e-05 - learning_rate: 3.2154e-05\n",
            "Epoch 353/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - loss: 6.0832e-05 - val_loss: 8.9560e-05 - learning_rate: 3.1833e-05\n",
            "Epoch 354/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 976us/step - loss: 6.0357e-05 - val_loss: 8.8590e-05 - learning_rate: 3.1514e-05\n",
            "Epoch 355/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - loss: 6.0781e-05 - val_loss: 8.8841e-05 - learning_rate: 3.1199e-05\n",
            "Epoch 356/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - loss: 6.0965e-05 - val_loss: 8.8924e-05 - learning_rate: 3.0887e-05\n",
            "Epoch 357/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - loss: 5.9897e-05 - val_loss: 8.8886e-05 - learning_rate: 3.0578e-05\n",
            "Epoch 358/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770us/step - loss: 6.0588e-05 - val_loss: 8.8850e-05 - learning_rate: 3.0272e-05\n",
            "Epoch 359/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - loss: 6.0179e-05 - val_loss: 8.8545e-05 - learning_rate: 2.9970e-05\n",
            "Epoch 360/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - loss: 6.0043e-05 - val_loss: 8.8422e-05 - learning_rate: 2.9670e-05\n",
            "Epoch 361/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - loss: 5.9854e-05 - val_loss: 8.8723e-05 - learning_rate: 2.9373e-05\n",
            "Epoch 362/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767us/step - loss: 6.0402e-05 - val_loss: 8.8946e-05 - learning_rate: 2.9080e-05\n",
            "Epoch 363/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692us/step - loss: 6.0417e-05 - val_loss: 8.8513e-05 - learning_rate: 2.8789e-05\n",
            "Epoch 364/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - loss: 5.9988e-05 - val_loss: 8.8702e-05 - learning_rate: 2.8501e-05\n",
            "Epoch 365/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - loss: 5.9764e-05 - val_loss: 8.8526e-05 - learning_rate: 2.8216e-05\n",
            "Epoch 366/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - loss: 5.9771e-05 - val_loss: 8.8691e-05 - learning_rate: 2.7934e-05\n",
            "Epoch 367/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 972us/step - loss: 6.0234e-05 - val_loss: 8.8428e-05 - learning_rate: 2.7654e-05\n",
            "Epoch 368/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 717us/step - loss: 5.9939e-05 - val_loss: 8.8031e-05 - learning_rate: 2.7378e-05\n",
            "Epoch 369/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - loss: 5.9977e-05 - val_loss: 8.8469e-05 - learning_rate: 2.7104e-05\n",
            "Epoch 370/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - loss: 6.0488e-05 - val_loss: 8.8473e-05 - learning_rate: 2.6833e-05\n",
            "Epoch 371/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - loss: 5.9637e-05 - val_loss: 8.8053e-05 - learning_rate: 2.6565e-05\n",
            "Epoch 372/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772us/step - loss: 5.9978e-05 - val_loss: 8.8071e-05 - learning_rate: 2.6299e-05\n",
            "Epoch 373/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step - loss: 6.0050e-05 - val_loss: 8.8467e-05 - learning_rate: 2.6036e-05\n",
            "Epoch 374/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - loss: 5.9783e-05 - val_loss: 8.8544e-05 - learning_rate: 2.5776e-05\n",
            "Epoch 375/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - loss: 6.0141e-05 - val_loss: 8.7996e-05 - learning_rate: 2.5518e-05\n",
            "Epoch 376/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762us/step - loss: 5.9936e-05 - val_loss: 8.8817e-05 - learning_rate: 2.5263e-05\n",
            "Epoch 377/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - loss: 6.0264e-05 - val_loss: 8.8354e-05 - learning_rate: 2.5010e-05\n",
            "Epoch 378/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - loss: 6.0041e-05 - val_loss: 8.8103e-05 - learning_rate: 2.4760e-05\n",
            "Epoch 379/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897us/step - loss: 5.9887e-05 - val_loss: 8.8301e-05 - learning_rate: 2.4512e-05\n",
            "Epoch 380/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767us/step - loss: 5.8908e-05 - val_loss: 8.8339e-05 - learning_rate: 2.4267e-05\n",
            "Epoch 381/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - loss: 5.9818e-05 - val_loss: 8.8117e-05 - learning_rate: 2.4025e-05\n",
            "Epoch 382/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 720us/step - loss: 6.0027e-05 - val_loss: 8.8299e-05 - learning_rate: 2.3784e-05\n",
            "Epoch 383/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - loss: 5.9793e-05 - val_loss: 8.8201e-05 - learning_rate: 2.3547e-05\n",
            "Epoch 384/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - loss: 6.0164e-05 - val_loss: 8.8072e-05 - learning_rate: 2.3311e-05\n",
            "Epoch 385/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 889us/step - loss: 5.9874e-05 - val_loss: 8.8171e-05 - learning_rate: 2.3078e-05\n",
            "Epoch 386/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step - loss: 5.8715e-05 - val_loss: 8.8175e-05 - learning_rate: 2.2847e-05\n",
            "Epoch 387/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - loss: 6.0265e-05 - val_loss: 8.7889e-05 - learning_rate: 2.2619e-05\n",
            "Epoch 388/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - loss: 5.9739e-05 - val_loss: 8.8198e-05 - learning_rate: 2.2393e-05\n",
            "Epoch 389/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767us/step - loss: 5.9823e-05 - val_loss: 8.7960e-05 - learning_rate: 2.2169e-05\n",
            "Epoch 390/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - loss: 5.9793e-05 - val_loss: 8.8218e-05 - learning_rate: 2.1947e-05\n",
            "Epoch 391/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907us/step - loss: 5.9787e-05 - val_loss: 8.8291e-05 - learning_rate: 2.1727e-05\n",
            "Epoch 392/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 718us/step - loss: 5.9951e-05 - val_loss: 8.7875e-05 - learning_rate: 2.1510e-05\n",
            "Epoch 393/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 771us/step - loss: 5.9530e-05 - val_loss: 8.8065e-05 - learning_rate: 2.1295e-05\n",
            "Epoch 394/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - loss: 5.9643e-05 - val_loss: 8.7896e-05 - learning_rate: 2.1082e-05\n",
            "Epoch 395/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - loss: 5.9445e-05 - val_loss: 8.8183e-05 - learning_rate: 2.0871e-05\n",
            "Epoch 396/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - loss: 5.9733e-05 - val_loss: 8.7739e-05 - learning_rate: 2.0663e-05\n",
            "Epoch 397/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 980us/step - loss: 5.9999e-05 - val_loss: 8.7838e-05 - learning_rate: 2.0456e-05\n",
            "Epoch 398/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - loss: 5.9441e-05 - val_loss: 8.8054e-05 - learning_rate: 2.0251e-05\n",
            "Epoch 399/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - loss: 5.9362e-05 - val_loss: 8.8343e-05 - learning_rate: 2.0049e-05\n",
            "Epoch 400/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step - loss: 5.9226e-05 - val_loss: 8.8054e-05 - learning_rate: 1.9848e-05\n",
            "Epoch 401/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757us/step - loss: 5.9336e-05 - val_loss: 8.7821e-05 - learning_rate: 1.9650e-05\n",
            "Epoch 402/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - loss: 5.9788e-05 - val_loss: 8.7705e-05 - learning_rate: 1.9453e-05\n",
            "Epoch 403/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 884us/step - loss: 5.9023e-05 - val_loss: 8.7716e-05 - learning_rate: 1.9259e-05\n",
            "Epoch 404/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step - loss: 5.9257e-05 - val_loss: 8.7778e-05 - learning_rate: 1.9066e-05\n",
            "Epoch 405/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767us/step - loss: 5.8973e-05 - val_loss: 8.7528e-05 - learning_rate: 1.8876e-05\n",
            "Epoch 406/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - loss: 5.9253e-05 - val_loss: 8.8128e-05 - learning_rate: 1.8687e-05\n",
            "Epoch 407/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - loss: 5.9136e-05 - val_loss: 8.7989e-05 - learning_rate: 1.8500e-05\n",
            "Epoch 408/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - loss: 5.9650e-05 - val_loss: 8.7883e-05 - learning_rate: 1.8315e-05\n",
            "Epoch 409/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 974us/step - loss: 5.9569e-05 - val_loss: 8.7619e-05 - learning_rate: 1.8132e-05\n",
            "Epoch 410/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - loss: 5.8697e-05 - val_loss: 8.7450e-05 - learning_rate: 1.7951e-05\n",
            "Epoch 411/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687us/step - loss: 5.9206e-05 - val_loss: 8.7540e-05 - learning_rate: 1.7771e-05\n",
            "Epoch 412/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step - loss: 5.9759e-05 - val_loss: 8.7419e-05 - learning_rate: 1.7593e-05\n",
            "Epoch 413/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772us/step - loss: 5.9096e-05 - val_loss: 8.7430e-05 - learning_rate: 1.7417e-05\n",
            "Epoch 414/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 676us/step - loss: 5.9390e-05 - val_loss: 8.7871e-05 - learning_rate: 1.7243e-05\n",
            "Epoch 415/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705us/step - loss: 5.9604e-05 - val_loss: 8.7702e-05 - learning_rate: 1.7071e-05\n",
            "Epoch 416/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684us/step - loss: 5.8921e-05 - val_loss: 8.7569e-05 - learning_rate: 1.6900e-05\n",
            "Epoch 417/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - loss: 5.9176e-05 - val_loss: 8.7420e-05 - learning_rate: 1.6731e-05\n",
            "Epoch 418/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762us/step - loss: 5.9410e-05 - val_loss: 8.7585e-05 - learning_rate: 1.6564e-05\n",
            "Epoch 419/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 704us/step - loss: 5.8954e-05 - val_loss: 8.7330e-05 - learning_rate: 1.6398e-05\n",
            "Epoch 420/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - loss: 5.8906e-05 - val_loss: 8.7628e-05 - learning_rate: 1.6234e-05\n",
            "Epoch 421/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 976us/step - loss: 5.9418e-05 - val_loss: 8.7552e-05 - learning_rate: 1.6072e-05\n",
            "Epoch 422/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - loss: 5.9393e-05 - val_loss: 8.7838e-05 - learning_rate: 1.5911e-05\n",
            "Epoch 423/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709us/step - loss: 5.8992e-05 - val_loss: 8.7627e-05 - learning_rate: 1.5752e-05\n",
            "Epoch 424/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - loss: 5.9100e-05 - val_loss: 8.7615e-05 - learning_rate: 1.5594e-05\n",
            "Epoch 425/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 766us/step - loss: 5.8772e-05 - val_loss: 8.7532e-05 - learning_rate: 1.5439e-05\n",
            "Epoch 426/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - loss: 5.8816e-05 - val_loss: 8.7171e-05 - learning_rate: 1.5284e-05\n",
            "Epoch 427/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 896us/step - loss: 5.8531e-05 - val_loss: 8.7266e-05 - learning_rate: 1.5131e-05\n",
            "Epoch 428/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - loss: 5.9241e-05 - val_loss: 8.7256e-05 - learning_rate: 1.4980e-05\n",
            "Epoch 429/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 766us/step - loss: 5.8770e-05 - val_loss: 8.7713e-05 - learning_rate: 1.4830e-05\n",
            "Epoch 430/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - loss: 5.8790e-05 - val_loss: 8.7402e-05 - learning_rate: 1.4682e-05\n",
            "Epoch 431/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - loss: 5.9015e-05 - val_loss: 8.7309e-05 - learning_rate: 1.4535e-05\n",
            "Epoch 432/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 704us/step - loss: 5.9007e-05 - val_loss: 8.7503e-05 - learning_rate: 1.4390e-05\n",
            "Epoch 433/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 987us/step - loss: 5.8775e-05 - val_loss: 8.7284e-05 - learning_rate: 1.4246e-05\n",
            "Epoch 434/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - loss: 5.8937e-05 - val_loss: 8.7321e-05 - learning_rate: 1.4103e-05\n",
            "Epoch 435/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - loss: 5.8818e-05 - val_loss: 8.7462e-05 - learning_rate: 1.3962e-05\n",
            "Epoch 436/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688us/step - loss: 5.8875e-05 - val_loss: 8.7319e-05 - learning_rate: 1.3823e-05\n",
            "Epoch 437/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 766us/step - loss: 5.8640e-05 - val_loss: 8.7508e-05 - learning_rate: 1.3684e-05\n",
            "Epoch 438/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step - loss: 5.8910e-05 - val_loss: 8.7495e-05 - learning_rate: 1.3548e-05\n",
            "Epoch 439/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 704us/step - loss: 5.9291e-05 - val_loss: 8.7201e-05 - learning_rate: 1.3412e-05\n",
            "Epoch 440/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - loss: 5.8989e-05 - val_loss: 8.7328e-05 - learning_rate: 1.3278e-05\n",
            "Epoch 441/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 5.9440e-05 - val_loss: 8.7662e-05 - learning_rate: 1.3145e-05\n",
            "Epoch 442/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692us/step - loss: 5.9285e-05 - val_loss: 8.7060e-05 - learning_rate: 1.3014e-05\n",
            "Epoch 443/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step - loss: 5.8700e-05 - val_loss: 8.7403e-05 - learning_rate: 1.2884e-05\n",
            "Epoch 444/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 785us/step - loss: 5.9087e-05 - val_loss: 8.7498e-05 - learning_rate: 1.2755e-05\n",
            "Epoch 445/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - loss: 5.8282e-05 - val_loss: 8.7332e-05 - learning_rate: 1.2627e-05\n",
            "Epoch 446/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - loss: 5.8626e-05 - val_loss: 8.7285e-05 - learning_rate: 1.2501e-05\n",
            "Epoch 447/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - loss: 5.8303e-05 - val_loss: 8.7107e-05 - learning_rate: 1.2376e-05\n",
            "Epoch 448/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 766us/step - loss: 5.8305e-05 - val_loss: 8.7312e-05 - learning_rate: 1.2252e-05\n",
            "Epoch 449/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - loss: 5.8953e-05 - val_loss: 8.7245e-05 - learning_rate: 1.2130e-05\n",
            "Epoch 450/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - loss: 5.8981e-05 - val_loss: 8.7403e-05 - learning_rate: 1.2008e-05\n",
            "Epoch 451/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767us/step - loss: 5.8666e-05 - val_loss: 8.7160e-05 - learning_rate: 1.1888e-05\n",
            "Epoch 452/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - loss: 5.8672e-05 - val_loss: 8.7659e-05 - learning_rate: 1.1769e-05\n",
            "Epoch 453/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - loss: 5.8603e-05 - val_loss: 8.7263e-05 - learning_rate: 1.1652e-05\n",
            "Epoch 454/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - loss: 5.9100e-05 - val_loss: 8.7261e-05 - learning_rate: 1.1535e-05\n",
            "Epoch 455/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - loss: 5.8083e-05 - val_loss: 8.7099e-05 - learning_rate: 1.1420e-05\n",
            "Epoch 456/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - loss: 5.8946e-05 - val_loss: 8.7197e-05 - learning_rate: 1.1306e-05\n",
            "Epoch 457/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - loss: 5.8803e-05 - val_loss: 8.7099e-05 - learning_rate: 1.1193e-05\n",
            "Epoch 458/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763us/step - loss: 5.8597e-05 - val_loss: 8.7218e-05 - learning_rate: 1.1081e-05\n",
            "Epoch 459/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901us/step - loss: 5.8586e-05 - val_loss: 8.7049e-05 - learning_rate: 1.0970e-05\n",
            "Epoch 460/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688us/step - loss: 5.8672e-05 - val_loss: 8.7012e-05 - learning_rate: 1.0860e-05\n",
            "Epoch 461/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692us/step - loss: 5.8179e-05 - val_loss: 8.7017e-05 - learning_rate: 1.0752e-05\n",
            "Epoch 462/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758us/step - loss: 5.8271e-05 - val_loss: 8.7065e-05 - learning_rate: 1.0644e-05\n",
            "Epoch 463/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688us/step - loss: 5.8822e-05 - val_loss: 8.6936e-05 - learning_rate: 1.0538e-05\n",
            "Epoch 464/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 874us/step - loss: 5.8614e-05 - val_loss: 8.7238e-05 - learning_rate: 1.0432e-05\n",
            "Epoch 465/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - loss: 5.8955e-05 - val_loss: 8.6908e-05 - learning_rate: 1.0328e-05\n",
            "Epoch 466/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758us/step - loss: 5.8913e-05 - val_loss: 8.6808e-05 - learning_rate: 1.0225e-05\n",
            "Epoch 467/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - loss: 5.8463e-05 - val_loss: 8.7092e-05 - learning_rate: 1.0122e-05\n",
            "Epoch 468/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 707us/step - loss: 5.8340e-05 - val_loss: 8.6896e-05 - learning_rate: 1.0021e-05\n",
            "Epoch 469/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - loss: 5.8380e-05 - val_loss: 8.7008e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 470/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 737us/step - loss: 5.8018e-05 - val_loss: 8.6990e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 471/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - loss: 5.8555e-05 - val_loss: 8.7158e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 472/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - loss: 5.8632e-05 - val_loss: 8.7023e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 473/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 766us/step - loss: 5.8120e-05 - val_loss: 8.7148e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 474/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step - loss: 5.7999e-05 - val_loss: 8.6977e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 475/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step - loss: 5.8853e-05 - val_loss: 8.6879e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 476/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 761us/step - loss: 5.8366e-05 - val_loss: 8.6831e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 477/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - loss: 5.8975e-05 - val_loss: 8.6685e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 478/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - loss: 5.8528e-05 - val_loss: 8.6934e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 479/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - loss: 5.8661e-05 - val_loss: 8.6932e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 480/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 769us/step - loss: 5.8519e-05 - val_loss: 8.6958e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 481/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - loss: 5.8652e-05 - val_loss: 8.6873e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 482/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 888us/step - loss: 5.8389e-05 - val_loss: 8.6837e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 483/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770us/step - loss: 5.8379e-05 - val_loss: 8.7174e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 484/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687us/step - loss: 5.8674e-05 - val_loss: 8.6859e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 485/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 708us/step - loss: 5.8486e-05 - val_loss: 8.6885e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 486/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - loss: 5.8343e-05 - val_loss: 8.6774e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 487/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - loss: 5.8201e-05 - val_loss: 8.6772e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 488/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - loss: 5.8745e-05 - val_loss: 8.7247e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 489/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688us/step - loss: 5.8078e-05 - val_loss: 8.6947e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 490/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760us/step - loss: 5.8069e-05 - val_loss: 8.6677e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 491/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - loss: 5.8736e-05 - val_loss: 8.7070e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 492/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 899us/step - loss: 5.8364e-05 - val_loss: 8.6743e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 493/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 769us/step - loss: 5.8926e-05 - val_loss: 8.6904e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 494/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688us/step - loss: 5.8708e-05 - val_loss: 8.6819e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 495/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 714us/step - loss: 5.8613e-05 - val_loss: 8.6756e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 496/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - loss: 5.8127e-05 - val_loss: 8.6830e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 497/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770us/step - loss: 5.8583e-05 - val_loss: 8.6910e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 498/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - loss: 5.8513e-05 - val_loss: 8.6837e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 499/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - loss: 5.8532e-05 - val_loss: 8.6754e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 500/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 766us/step - loss: 5.8186e-05 - val_loss: 8.6666e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 501/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step - loss: 5.8217e-05 - val_loss: 8.6845e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 502/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - loss: 5.8195e-05 - val_loss: 8.6781e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 503/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - loss: 5.9198e-05 - val_loss: 8.6665e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 504/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - loss: 5.8814e-05 - val_loss: 8.7049e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 505/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 708us/step - loss: 5.8576e-05 - val_loss: 8.6642e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 506/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 923us/step - loss: 5.7996e-05 - val_loss: 8.6536e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 507/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - loss: 5.8843e-05 - val_loss: 8.6675e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 508/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step - loss: 5.8281e-05 - val_loss: 8.6645e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 509/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step - loss: 5.8535e-05 - val_loss: 8.6762e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 510/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 5.8482e-05 - val_loss: 8.6909e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 511/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 895us/step - loss: 5.8436e-05 - val_loss: 8.6876e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 512/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - loss: 5.8839e-05 - val_loss: 8.6817e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 513/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 759us/step - loss: 5.8222e-05 - val_loss: 8.6735e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 514/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - loss: 5.8283e-05 - val_loss: 8.6568e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 515/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - loss: 5.8428e-05 - val_loss: 8.6681e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 516/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 982us/step - loss: 5.8370e-05 - val_loss: 8.6910e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 517/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - loss: 5.8248e-05 - val_loss: 8.6585e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 518/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684us/step - loss: 5.8128e-05 - val_loss: 8.6913e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 519/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - loss: 5.8586e-05 - val_loss: 8.6651e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 520/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 771us/step - loss: 5.8607e-05 - val_loss: 8.6674e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 521/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898us/step - loss: 5.8688e-05 - val_loss: 8.6698e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 522/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - loss: 5.7987e-05 - val_loss: 8.6700e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 523/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 766us/step - loss: 5.7930e-05 - val_loss: 8.6701e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 524/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - loss: 5.8153e-05 - val_loss: 8.6820e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 525/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - loss: 5.8053e-05 - val_loss: 8.6606e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 526/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996us/step - loss: 5.7897e-05 - val_loss: 8.6856e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 527/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step - loss: 5.8634e-05 - val_loss: 8.6720e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 528/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 706us/step - loss: 5.7739e-05 - val_loss: 8.6485e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 529/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - loss: 5.8004e-05 - val_loss: 8.6571e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 530/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684us/step - loss: 5.7986e-05 - val_loss: 8.6504e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 531/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - loss: 5.8259e-05 - val_loss: 8.6449e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 532/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - loss: 5.8520e-05 - val_loss: 8.6551e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 533/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step - loss: 5.8116e-05 - val_loss: 8.6650e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 534/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - loss: 5.8577e-05 - val_loss: 8.6640e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 535/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 5.7979e-05 - val_loss: 8.6485e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 536/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - loss: 5.8215e-05 - val_loss: 8.6600e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 537/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - loss: 5.7874e-05 - val_loss: 8.6791e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 538/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 751us/step - loss: 5.7668e-05 - val_loss: 8.6534e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 539/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - loss: 5.8248e-05 - val_loss: 8.6396e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 540/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - loss: 5.8617e-05 - val_loss: 8.6463e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 541/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970us/step - loss: 5.8403e-05 - val_loss: 8.6486e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 542/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - loss: 5.8095e-05 - val_loss: 8.6451e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 543/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - loss: 5.7528e-05 - val_loss: 8.6524e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 544/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 780us/step - loss: 5.8645e-05 - val_loss: 8.6572e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 545/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900us/step - loss: 5.8115e-05 - val_loss: 8.6467e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 546/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 718us/step - loss: 5.8460e-05 - val_loss: 8.6554e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 547/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757us/step - loss: 5.8106e-05 - val_loss: 8.6561e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 548/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - loss: 5.8420e-05 - val_loss: 8.6411e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 549/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - loss: 5.9002e-05 - val_loss: 8.6648e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 550/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 761us/step - loss: 5.8123e-05 - val_loss: 8.6482e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 551/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687us/step - loss: 5.8543e-05 - val_loss: 8.6437e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 552/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688us/step - loss: 5.8546e-05 - val_loss: 8.6353e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 553/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763us/step - loss: 5.8646e-05 - val_loss: 8.6461e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 554/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898us/step - loss: 5.7917e-05 - val_loss: 8.6574e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 555/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - loss: 5.7934e-05 - val_loss: 8.6406e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 556/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772us/step - loss: 5.7463e-05 - val_loss: 8.6523e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 557/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - loss: 5.7591e-05 - val_loss: 8.6312e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 558/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step - loss: 5.8776e-05 - val_loss: 8.6626e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 559/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765us/step - loss: 5.8009e-05 - val_loss: 8.6517e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 560/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - loss: 5.8239e-05 - val_loss: 8.6352e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 561/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - loss: 5.8316e-05 - val_loss: 8.6449e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 562/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 5.8105e-05 - val_loss: 8.6432e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 563/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907us/step - loss: 5.8073e-05 - val_loss: 8.6298e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 564/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - loss: 5.8456e-05 - val_loss: 8.6969e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 565/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767us/step - loss: 5.8120e-05 - val_loss: 8.6445e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 566/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - loss: 5.8069e-05 - val_loss: 8.6305e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 567/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - loss: 5.7601e-05 - val_loss: 8.6225e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 568/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 754us/step - loss: 5.8548e-05 - val_loss: 8.6390e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 569/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684us/step - loss: 5.7808e-05 - val_loss: 8.6406e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 570/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - loss: 5.7796e-05 - val_loss: 8.6382e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 571/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 766us/step - loss: 5.7193e-05 - val_loss: 8.6243e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 572/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 890us/step - loss: 5.8280e-05 - val_loss: 8.6830e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 573/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - loss: 5.8056e-05 - val_loss: 8.6209e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 574/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 759us/step - loss: 5.8414e-05 - val_loss: 8.6061e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 575/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 724us/step - loss: 5.8159e-05 - val_loss: 8.6207e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 576/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 676us/step - loss: 5.7897e-05 - val_loss: 8.6182e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 577/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.8335e-05 - val_loss: 8.6285e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 578/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 675us/step - loss: 5.8187e-05 - val_loss: 8.6369e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 579/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 5.7676e-05 - val_loss: 8.6430e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 580/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684us/step - loss: 5.7964e-05 - val_loss: 8.6349e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 581/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897us/step - loss: 5.8256e-05 - val_loss: 8.6363e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 582/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767us/step - loss: 5.7872e-05 - val_loss: 8.6185e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 583/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 677us/step - loss: 5.7884e-05 - val_loss: 8.6158e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 584/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - loss: 5.7448e-05 - val_loss: 8.6212e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 585/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 954us/step - loss: 5.8082e-05 - val_loss: 8.6181e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 586/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 682us/step - loss: 5.8440e-05 - val_loss: 8.6556e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 587/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 713us/step - loss: 5.7762e-05 - val_loss: 8.6241e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 588/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 5.7597e-05 - val_loss: 8.6109e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 589/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 890us/step - loss: 5.7465e-05 - val_loss: 8.6269e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 590/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step - loss: 5.7955e-05 - val_loss: 8.6104e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 591/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 5.7858e-05 - val_loss: 8.6187e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 592/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step - loss: 5.8021e-05 - val_loss: 8.6090e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 593/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - loss: 5.7914e-05 - val_loss: 8.6169e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 594/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 965us/step - loss: 5.8324e-05 - val_loss: 8.6438e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 595/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - loss: 5.7878e-05 - val_loss: 8.6277e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 596/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 678us/step - loss: 5.7914e-05 - val_loss: 8.6167e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 597/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 5.8478e-05 - val_loss: 8.6194e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 598/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 896us/step - loss: 5.7796e-05 - val_loss: 8.6109e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 599/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688us/step - loss: 5.7897e-05 - val_loss: 8.6343e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 600/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763us/step - loss: 5.7819e-05 - val_loss: 8.6253e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 601/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688us/step - loss: 5.8328e-05 - val_loss: 8.6107e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 602/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900us/step - loss: 5.7695e-05 - val_loss: 8.6107e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 603/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step - loss: 5.7830e-05 - val_loss: 8.6328e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 604/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - loss: 5.8238e-05 - val_loss: 8.6148e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 605/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765us/step - loss: 5.8462e-05 - val_loss: 8.6332e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 606/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step - loss: 5.7620e-05 - val_loss: 8.6117e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 607/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - loss: 5.7916e-05 - val_loss: 8.6205e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 608/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 5.7868e-05 - val_loss: 8.6560e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 609/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - loss: 5.7439e-05 - val_loss: 8.6203e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 610/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692us/step - loss: 5.7804e-05 - val_loss: 8.6085e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 611/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971us/step - loss: 5.8275e-05 - val_loss: 8.5955e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 612/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - loss: 5.7903e-05 - val_loss: 8.6464e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 613/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767us/step - loss: 5.7633e-05 - val_loss: 8.6007e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 614/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - loss: 5.7951e-05 - val_loss: 8.5942e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 615/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step - loss: 5.7867e-05 - val_loss: 8.6084e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 616/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 976us/step - loss: 5.8620e-05 - val_loss: 8.6261e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 617/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709us/step - loss: 5.7929e-05 - val_loss: 8.6131e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 618/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688us/step - loss: 5.8405e-05 - val_loss: 8.6091e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 619/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 769us/step - loss: 5.7871e-05 - val_loss: 8.6181e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 620/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - loss: 5.7965e-05 - val_loss: 8.5987e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 621/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913us/step - loss: 5.7239e-05 - val_loss: 8.6008e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 622/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 761us/step - loss: 5.8351e-05 - val_loss: 8.5890e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 623/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687us/step - loss: 5.7826e-05 - val_loss: 8.6107e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 624/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 744us/step - loss: 5.7926e-05 - val_loss: 8.6250e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 625/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - loss: 5.8277e-05 - val_loss: 8.6068e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 626/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - loss: 5.7748e-05 - val_loss: 8.5943e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 627/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763us/step - loss: 5.8034e-05 - val_loss: 8.5966e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 628/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - loss: 5.7804e-05 - val_loss: 8.6099e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 629/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - loss: 5.8290e-05 - val_loss: 8.6015e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 630/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - loss: 5.7640e-05 - val_loss: 8.6139e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 631/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - loss: 5.7700e-05 - val_loss: 8.6012e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 632/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 775us/step - loss: 5.7914e-05 - val_loss: 8.5916e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 633/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step - loss: 5.7287e-05 - val_loss: 8.5939e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 634/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901us/step - loss: 5.7891e-05 - val_loss: 8.5941e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 635/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767us/step - loss: 5.7684e-05 - val_loss: 8.5912e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 636/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692us/step - loss: 5.8168e-05 - val_loss: 8.5832e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 637/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - loss: 5.8036e-05 - val_loss: 8.6010e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 638/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - loss: 5.7179e-05 - val_loss: 8.5842e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 639/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - loss: 5.7696e-05 - val_loss: 8.5849e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 640/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772us/step - loss: 5.7642e-05 - val_loss: 8.6040e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 641/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688us/step - loss: 5.7510e-05 - val_loss: 8.5738e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 642/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 771us/step - loss: 5.7775e-05 - val_loss: 8.5855e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 643/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - loss: 5.7474e-05 - val_loss: 8.5892e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 644/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step - loss: 5.7860e-05 - val_loss: 8.5988e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 645/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 766us/step - loss: 5.7225e-05 - val_loss: 8.6008e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 646/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684us/step - loss: 5.7581e-05 - val_loss: 8.5781e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 647/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 899us/step - loss: 5.7838e-05 - val_loss: 8.5849e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 648/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 775us/step - loss: 5.7510e-05 - val_loss: 8.6266e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 649/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - loss: 5.7696e-05 - val_loss: 8.5775e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 650/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767us/step - loss: 5.7409e-05 - val_loss: 8.6319e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 651/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 908us/step - loss: 5.7466e-05 - val_loss: 8.6186e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 652/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - loss: 5.7291e-05 - val_loss: 8.5879e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 653/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767us/step - loss: 5.7489e-05 - val_loss: 8.6036e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 654/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - loss: 5.8051e-05 - val_loss: 8.5659e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 655/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 987us/step - loss: 5.7300e-05 - val_loss: 8.5609e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 656/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687us/step - loss: 5.7659e-05 - val_loss: 8.5887e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 657/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - loss: 5.7743e-05 - val_loss: 8.5808e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 658/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 775us/step - loss: 5.7976e-05 - val_loss: 8.5897e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 659/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - loss: 5.7998e-05 - val_loss: 8.6075e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 660/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - loss: 5.7861e-05 - val_loss: 8.5996e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 661/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 761us/step - loss: 5.7794e-05 - val_loss: 8.5892e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 662/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step - loss: 5.7974e-05 - val_loss: 8.5810e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 663/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 5.8153e-05 - val_loss: 8.5687e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 664/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - loss: 5.7256e-05 - val_loss: 8.5637e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 665/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 769us/step - loss: 5.7483e-05 - val_loss: 8.5783e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 666/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907us/step - loss: 5.7696e-05 - val_loss: 8.5978e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 667/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - loss: 5.7254e-05 - val_loss: 8.5726e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 668/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770us/step - loss: 5.7826e-05 - val_loss: 8.5786e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 669/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - loss: 5.7482e-05 - val_loss: 8.5819e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 670/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - loss: 5.7986e-05 - val_loss: 8.5742e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 671/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684us/step - loss: 5.7528e-05 - val_loss: 8.5677e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 672/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688us/step - loss: 5.7564e-05 - val_loss: 8.5965e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 673/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 5.7805e-05 - val_loss: 8.5880e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 674/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 890us/step - loss: 5.7753e-05 - val_loss: 8.5746e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 675/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760us/step - loss: 5.7916e-05 - val_loss: 8.5690e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 676/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - loss: 5.7737e-05 - val_loss: 8.5622e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 677/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692us/step - loss: 5.7505e-05 - val_loss: 8.5782e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 678/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 987us/step - loss: 5.7473e-05 - val_loss: 8.5943e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 679/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - loss: 5.7554e-05 - val_loss: 8.5653e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 680/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - loss: 5.7662e-05 - val_loss: 8.5472e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 681/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - loss: 5.7794e-05 - val_loss: 8.5553e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 682/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907us/step - loss: 5.7751e-05 - val_loss: 8.5713e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 683/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763us/step - loss: 5.7843e-05 - val_loss: 8.5641e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 684/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step - loss: 5.7239e-05 - val_loss: 8.5866e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 685/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762us/step - loss: 5.7727e-05 - val_loss: 8.5550e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 686/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - loss: 5.7319e-05 - val_loss: 8.5636e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 687/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 746us/step - loss: 5.7233e-05 - val_loss: 8.5564e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 688/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - loss: 5.6809e-05 - val_loss: 8.5451e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 689/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - loss: 5.7965e-05 - val_loss: 8.5608e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 690/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 974us/step - loss: 5.7877e-05 - val_loss: 8.5682e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 691/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - loss: 5.7705e-05 - val_loss: 8.5604e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 692/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760us/step - loss: 5.7630e-05 - val_loss: 8.5563e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 693/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 852us/step - loss: 5.7029e-05 - val_loss: 8.5667e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 694/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688us/step - loss: 5.7837e-05 - val_loss: 8.5653e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 695/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762us/step - loss: 5.7538e-05 - val_loss: 8.5510e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 696/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - loss: 5.7315e-05 - val_loss: 8.5538e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 697/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 987us/step - loss: 5.7714e-05 - val_loss: 8.5502e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 698/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - loss: 5.7612e-05 - val_loss: 8.5675e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 699/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763us/step - loss: 5.7543e-05 - val_loss: 8.5669e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 700/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 672us/step - loss: 5.7909e-05 - val_loss: 8.5622e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 701/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step - loss: 5.7550e-05 - val_loss: 8.5476e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 702/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 963us/step - loss: 5.7874e-05 - val_loss: 8.5606e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 703/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692us/step - loss: 5.7822e-05 - val_loss: 8.5507e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 704/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767us/step - loss: 5.7839e-05 - val_loss: 8.5506e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 705/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - loss: 5.7534e-05 - val_loss: 8.5654e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 706/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762us/step - loss: 5.7332e-05 - val_loss: 8.5491e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 707/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 673us/step - loss: 5.7700e-05 - val_loss: 8.5451e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 708/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715us/step - loss: 5.7202e-05 - val_loss: 8.5639e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 709/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 977us/step - loss: 5.7768e-05 - val_loss: 8.5281e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 710/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692us/step - loss: 5.7337e-05 - val_loss: 8.5603e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 711/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774us/step - loss: 5.7505e-05 - val_loss: 8.5475e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 712/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - loss: 5.7805e-05 - val_loss: 8.5504e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 713/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740us/step - loss: 5.7793e-05 - val_loss: 8.5536e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 714/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - loss: 5.7153e-05 - val_loss: 8.5515e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 715/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692us/step - loss: 5.7917e-05 - val_loss: 8.5391e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 716/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 953us/step - loss: 5.7396e-05 - val_loss: 8.5459e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 717/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step - loss: 5.7438e-05 - val_loss: 8.5474e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 718/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 792us/step - loss: 5.7014e-05 - val_loss: 8.5678e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 719/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step - loss: 5.7336e-05 - val_loss: 8.5327e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 720/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - loss: 5.7846e-05 - val_loss: 8.5374e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 721/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 5.7428e-05 - val_loss: 8.5310e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 722/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - loss: 5.7889e-05 - val_loss: 8.5535e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 723/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - loss: 5.7314e-05 - val_loss: 8.5498e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 724/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step - loss: 5.7546e-05 - val_loss: 8.5258e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 725/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 965us/step - loss: 5.7604e-05 - val_loss: 8.5271e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 726/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688us/step - loss: 5.7373e-05 - val_loss: 8.5358e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 727/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687us/step - loss: 5.7122e-05 - val_loss: 8.5388e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 728/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 5.7293e-05 - val_loss: 8.5271e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 729/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898us/step - loss: 5.7680e-05 - val_loss: 8.5339e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 730/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 777us/step - loss: 5.6952e-05 - val_loss: 8.5298e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 731/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - loss: 5.7380e-05 - val_loss: 8.5553e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 732/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 5.7081e-05 - val_loss: 8.5312e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 733/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step - loss: 5.7187e-05 - val_loss: 8.5224e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 734/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - loss: 5.7381e-05 - val_loss: 8.5251e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 735/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762us/step - loss: 5.6542e-05 - val_loss: 8.5358e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 736/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step - loss: 5.7176e-05 - val_loss: 8.5073e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 737/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 973us/step - loss: 5.7639e-05 - val_loss: 8.5350e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 738/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 706us/step - loss: 5.7689e-05 - val_loss: 8.5421e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 739/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762us/step - loss: 5.7239e-05 - val_loss: 8.5291e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 740/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 704us/step - loss: 5.7850e-05 - val_loss: 8.5327e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 741/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970us/step - loss: 5.7640e-05 - val_loss: 8.5427e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 742/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step - loss: 5.7192e-05 - val_loss: 8.5274e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 743/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692us/step - loss: 5.7134e-05 - val_loss: 8.5079e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 744/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step - loss: 5.6926e-05 - val_loss: 8.5350e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 745/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - loss: 5.7246e-05 - val_loss: 8.5299e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 746/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 795us/step - loss: 5.7116e-05 - val_loss: 8.5481e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 747/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.7389e-05 - val_loss: 8.5175e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 748/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817us/step - loss: 5.6430e-05 - val_loss: 8.5303e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 749/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - loss: 5.7274e-05 - val_loss: 8.5507e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 750/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 968us/step - loss: 5.7986e-05 - val_loss: 8.5178e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 751/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step - loss: 5.7425e-05 - val_loss: 8.5304e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 752/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 5.6885e-05 - val_loss: 8.5133e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 753/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 894us/step - loss: 5.7079e-05 - val_loss: 8.5184e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 754/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767us/step - loss: 5.7077e-05 - val_loss: 8.5244e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 755/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687us/step - loss: 5.7059e-05 - val_loss: 8.5350e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 756/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - loss: 5.6878e-05 - val_loss: 8.5231e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 757/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 990us/step - loss: 5.7305e-05 - val_loss: 8.5410e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 758/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687us/step - loss: 5.6883e-05 - val_loss: 8.5401e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 759/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 756us/step - loss: 5.7071e-05 - val_loss: 8.5243e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 760/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - loss: 5.7648e-05 - val_loss: 8.4949e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 761/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 973us/step - loss: 5.7122e-05 - val_loss: 8.5376e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 762/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - loss: 5.6987e-05 - val_loss: 8.5100e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 763/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762us/step - loss: 5.6979e-05 - val_loss: 8.5093e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 764/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 889us/step - loss: 5.6932e-05 - val_loss: 8.5337e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 765/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774us/step - loss: 5.7437e-05 - val_loss: 8.5200e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 766/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - loss: 5.7087e-05 - val_loss: 8.5338e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 767/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 961us/step - loss: 5.7135e-05 - val_loss: 8.5227e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 768/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - loss: 5.7500e-05 - val_loss: 8.5581e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 769/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step - loss: 5.7104e-05 - val_loss: 8.5180e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 770/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 754us/step - loss: 5.7630e-05 - val_loss: 8.5338e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 771/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step - loss: 5.7148e-05 - val_loss: 8.5284e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 772/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765us/step - loss: 5.7171e-05 - val_loss: 8.5295e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 773/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687us/step - loss: 5.7391e-05 - val_loss: 8.5345e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 774/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - loss: 5.7458e-05 - val_loss: 8.5279e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 775/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 899us/step - loss: 5.7229e-05 - val_loss: 8.5119e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 776/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 756us/step - loss: 5.7436e-05 - val_loss: 8.5154e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 777/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 704us/step - loss: 5.6818e-05 - val_loss: 8.4985e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 778/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 972us/step - loss: 5.7211e-05 - val_loss: 8.5097e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 779/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - loss: 5.7314e-05 - val_loss: 8.5335e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 780/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 771us/step - loss: 5.6939e-05 - val_loss: 8.5280e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 781/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688us/step - loss: 5.7311e-05 - val_loss: 8.5240e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 782/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 795us/step - loss: 5.7353e-05 - val_loss: 8.5451e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 783/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - loss: 5.7391e-05 - val_loss: 8.5076e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 784/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760us/step - loss: 5.6605e-05 - val_loss: 8.5164e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 785/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897us/step - loss: 5.7690e-05 - val_loss: 8.5357e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 786/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step - loss: 5.7209e-05 - val_loss: 8.5169e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 787/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 786us/step - loss: 5.7161e-05 - val_loss: 8.4986e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 788/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - loss: 5.7093e-05 - val_loss: 8.5018e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 789/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 769us/step - loss: 5.7134e-05 - val_loss: 8.5017e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 790/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688us/step - loss: 5.6888e-05 - val_loss: 8.4918e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 791/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760us/step - loss: 5.7197e-05 - val_loss: 8.4992e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 792/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897us/step - loss: 5.6732e-05 - val_loss: 8.5518e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 793/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740us/step - loss: 5.7496e-05 - val_loss: 8.5001e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 794/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - loss: 5.6854e-05 - val_loss: 8.5173e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 795/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - loss: 5.7259e-05 - val_loss: 8.5083e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 796/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 741us/step - loss: 5.7596e-05 - val_loss: 8.4947e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 797/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 721us/step - loss: 5.7168e-05 - val_loss: 8.4968e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 798/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 754us/step - loss: 5.7322e-05 - val_loss: 8.4914e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 799/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 894us/step - loss: 5.6801e-05 - val_loss: 8.5012e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 800/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 756us/step - loss: 5.6892e-05 - val_loss: 8.5295e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 801/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - loss: 5.7496e-05 - val_loss: 8.5062e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 802/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971us/step - loss: 5.6970e-05 - val_loss: 8.5032e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 803/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684us/step - loss: 5.7032e-05 - val_loss: 8.4995e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 804/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762us/step - loss: 5.7103e-05 - val_loss: 8.5028e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 805/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907us/step - loss: 5.6913e-05 - val_loss: 8.5177e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 806/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781us/step - loss: 5.7627e-05 - val_loss: 8.4774e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 807/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687us/step - loss: 5.6714e-05 - val_loss: 8.4873e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 808/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 973us/step - loss: 5.6093e-05 - val_loss: 8.5029e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 809/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step - loss: 5.7291e-05 - val_loss: 8.5018e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 810/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 771us/step - loss: 5.7174e-05 - val_loss: 8.4965e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 811/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step - loss: 5.6786e-05 - val_loss: 8.4823e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 812/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 776us/step - loss: 5.7018e-05 - val_loss: 8.5127e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 813/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684us/step - loss: 5.6974e-05 - val_loss: 8.5009e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 814/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step - loss: 5.6521e-05 - val_loss: 8.5080e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 815/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765us/step - loss: 5.6881e-05 - val_loss: 8.4974e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 816/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 714us/step - loss: 5.6996e-05 - val_loss: 8.4751e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 817/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - loss: 5.7013e-05 - val_loss: 8.4787e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 818/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - loss: 5.7583e-05 - val_loss: 8.4969e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 819/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 950us/step - loss: 5.6901e-05 - val_loss: 8.4862e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 820/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688us/step - loss: 5.6945e-05 - val_loss: 8.4935e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 821/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 759us/step - loss: 5.6903e-05 - val_loss: 8.4892e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 822/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684us/step - loss: 5.7137e-05 - val_loss: 8.4894e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 823/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 980us/step - loss: 5.7210e-05 - val_loss: 8.5063e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 824/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688us/step - loss: 5.6786e-05 - val_loss: 8.5273e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 825/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765us/step - loss: 5.7350e-05 - val_loss: 8.4845e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 826/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step - loss: 5.6748e-05 - val_loss: 8.5017e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 827/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758us/step - loss: 5.6700e-05 - val_loss: 8.4793e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 828/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step - loss: 5.6837e-05 - val_loss: 8.4868e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 829/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - loss: 5.7375e-05 - val_loss: 8.5067e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 830/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971us/step - loss: 5.6906e-05 - val_loss: 8.4802e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 831/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - loss: 5.7017e-05 - val_loss: 8.4683e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 832/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765us/step - loss: 5.7309e-05 - val_loss: 8.4861e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 833/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - loss: 5.6838e-05 - val_loss: 8.4713e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 834/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step - loss: 5.6316e-05 - val_loss: 8.5047e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 835/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687us/step - loss: 5.6828e-05 - val_loss: 8.5005e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 836/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 995us/step - loss: 5.6705e-05 - val_loss: 8.5232e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 837/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - loss: 5.6531e-05 - val_loss: 8.4877e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 838/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 769us/step - loss: 5.6748e-05 - val_loss: 8.4706e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 839/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 676us/step - loss: 5.7226e-05 - val_loss: 8.4829e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 840/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 965us/step - loss: 5.6907e-05 - val_loss: 8.4675e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 841/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 743us/step - loss: 5.7075e-05 - val_loss: 8.4562e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 842/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - loss: 5.7020e-05 - val_loss: 8.4901e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 843/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step - loss: 5.7001e-05 - val_loss: 8.4660e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 844/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - loss: 5.6878e-05 - val_loss: 8.4868e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 845/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 754us/step - loss: 5.7145e-05 - val_loss: 8.4763e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 846/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 704us/step - loss: 5.7222e-05 - val_loss: 8.4742e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 847/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 972us/step - loss: 5.6184e-05 - val_loss: 8.4815e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 848/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687us/step - loss: 5.7233e-05 - val_loss: 8.4717e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 849/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 766us/step - loss: 5.6684e-05 - val_loss: 8.5005e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 850/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 889us/step - loss: 5.7423e-05 - val_loss: 8.4791e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 851/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 5.7231e-05 - val_loss: 8.4587e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 852/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705us/step - loss: 5.7124e-05 - val_loss: 8.4745e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 853/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - loss: 5.6962e-05 - val_loss: 8.4769e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 854/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 972us/step - loss: 5.6869e-05 - val_loss: 8.4888e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 855/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - loss: 5.7020e-05 - val_loss: 8.4662e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 856/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 934us/step - loss: 5.7111e-05 - val_loss: 8.4723e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 857/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - loss: 5.6732e-05 - val_loss: 8.4735e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 858/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760us/step - loss: 5.7224e-05 - val_loss: 8.4825e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 859/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - loss: 5.6501e-05 - val_loss: 8.4732e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 860/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 975us/step - loss: 5.7449e-05 - val_loss: 8.4535e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 861/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - loss: 5.7428e-05 - val_loss: 8.4651e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 862/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 776us/step - loss: 5.6751e-05 - val_loss: 8.4768e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 863/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step - loss: 5.6527e-05 - val_loss: 8.4535e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 864/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 977us/step - loss: 5.7090e-05 - val_loss: 8.4693e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 865/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - loss: 5.7228e-05 - val_loss: 8.4524e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 866/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 780us/step - loss: 5.6365e-05 - val_loss: 8.4602e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 867/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900us/step - loss: 5.7147e-05 - val_loss: 8.4739e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 868/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757us/step - loss: 5.6873e-05 - val_loss: 8.4613e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 869/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - loss: 5.6520e-05 - val_loss: 8.4566e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 870/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 976us/step - loss: 5.6867e-05 - val_loss: 8.4949e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 871/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step - loss: 5.6768e-05 - val_loss: 8.4707e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 872/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 771us/step - loss: 5.6605e-05 - val_loss: 8.4803e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 873/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 890us/step - loss: 5.6864e-05 - val_loss: 8.4643e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 874/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687us/step - loss: 5.6568e-05 - val_loss: 8.4550e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 875/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 706us/step - loss: 5.6735e-05 - val_loss: 8.4853e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 876/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 975us/step - loss: 5.6536e-05 - val_loss: 8.4555e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 877/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - loss: 5.7069e-05 - val_loss: 8.4404e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 878/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 751us/step - loss: 5.6624e-05 - val_loss: 8.4414e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 879/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - loss: 5.6588e-05 - val_loss: 8.4700e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 880/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 974us/step - loss: 5.6694e-05 - val_loss: 8.4776e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 881/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step - loss: 5.6623e-05 - val_loss: 8.4819e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 882/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 766us/step - loss: 5.6693e-05 - val_loss: 8.4473e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 883/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - loss: 5.6861e-05 - val_loss: 8.4575e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 884/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 766us/step - loss: 5.7085e-05 - val_loss: 8.4438e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 885/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705us/step - loss: 5.6784e-05 - val_loss: 8.4436e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 886/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 981us/step - loss: 5.6594e-05 - val_loss: 8.4604e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 887/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step - loss: 5.6761e-05 - val_loss: 8.4572e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 888/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 981us/step - loss: 5.6398e-05 - val_loss: 8.4366e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 889/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - loss: 5.6419e-05 - val_loss: 8.4349e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 890/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770us/step - loss: 5.7133e-05 - val_loss: 8.4593e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 891/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - loss: 5.6612e-05 - val_loss: 8.4367e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 892/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 965us/step - loss: 5.6937e-05 - val_loss: 8.4659e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 893/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - loss: 5.6767e-05 - val_loss: 8.4683e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 894/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767us/step - loss: 5.5898e-05 - val_loss: 8.4446e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 895/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step - loss: 5.6699e-05 - val_loss: 8.4588e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 896/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - loss: 5.6488e-05 - val_loss: 8.4348e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 897/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688us/step - loss: 5.6990e-05 - val_loss: 8.4605e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 898/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 981us/step - loss: 5.6871e-05 - val_loss: 8.4358e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 899/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 741us/step - loss: 5.6715e-05 - val_loss: 8.4656e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 900/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - loss: 5.6816e-05 - val_loss: 8.4346e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 901/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 969us/step - loss: 5.6884e-05 - val_loss: 8.4539e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 902/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - loss: 5.6997e-05 - val_loss: 8.4413e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 903/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 773us/step - loss: 5.6371e-05 - val_loss: 8.4377e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 904/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688us/step - loss: 5.6563e-05 - val_loss: 8.4352e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 905/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 993us/step - loss: 5.6776e-05 - val_loss: 8.4368e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 906/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step - loss: 5.6888e-05 - val_loss: 8.4359e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 907/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763us/step - loss: 5.6779e-05 - val_loss: 8.4556e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 908/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 893us/step - loss: 5.6556e-05 - val_loss: 8.4463e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 909/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 759us/step - loss: 5.7004e-05 - val_loss: 8.4445e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 910/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688us/step - loss: 5.6529e-05 - val_loss: 8.4396e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 911/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 974us/step - loss: 5.6809e-05 - val_loss: 8.4395e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 912/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692us/step - loss: 5.6787e-05 - val_loss: 8.4316e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 913/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767us/step - loss: 5.6596e-05 - val_loss: 8.4593e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 914/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.6768e-05 - val_loss: 8.4465e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 915/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 791us/step - loss: 5.6535e-05 - val_loss: 8.4599e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 916/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 720us/step - loss: 5.6315e-05 - val_loss: 8.4374e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 917/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.6748e-05 - val_loss: 8.4247e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 918/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 773us/step - loss: 5.6407e-05 - val_loss: 8.4220e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 919/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - loss: 5.6588e-05 - val_loss: 8.4336e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 920/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 972us/step - loss: 5.6509e-05 - val_loss: 8.4306e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 921/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692us/step - loss: 5.6733e-05 - val_loss: 8.4252e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 922/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770us/step - loss: 5.6729e-05 - val_loss: 8.4435e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 923/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897us/step - loss: 5.6610e-05 - val_loss: 8.4419e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 924/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 786us/step - loss: 5.6877e-05 - val_loss: 8.4522e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 925/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687us/step - loss: 5.6250e-05 - val_loss: 8.4313e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 926/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - loss: 5.6544e-05 - val_loss: 8.4302e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 927/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898us/step - loss: 5.6609e-05 - val_loss: 8.4439e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 928/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762us/step - loss: 5.6795e-05 - val_loss: 8.4486e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 929/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - loss: 5.6932e-05 - val_loss: 8.4204e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 930/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 979us/step - loss: 5.5980e-05 - val_loss: 8.4220e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 931/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - loss: 5.6168e-05 - val_loss: 8.4363e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 932/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765us/step - loss: 5.6167e-05 - val_loss: 8.4387e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 933/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - loss: 5.6120e-05 - val_loss: 8.4430e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 934/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 773us/step - loss: 5.6712e-05 - val_loss: 8.4357e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 935/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step - loss: 5.6337e-05 - val_loss: 8.4351e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 936/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772us/step - loss: 5.6959e-05 - val_loss: 8.4174e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 937/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - loss: 5.6164e-05 - val_loss: 8.4354e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 938/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762us/step - loss: 5.6891e-05 - val_loss: 8.4366e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 939/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - loss: 5.6819e-05 - val_loss: 8.4316e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 940/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767us/step - loss: 5.6515e-05 - val_loss: 8.4262e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 941/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 890us/step - loss: 5.6298e-05 - val_loss: 8.4275e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 942/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757us/step - loss: 5.5981e-05 - val_loss: 8.4585e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 943/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687us/step - loss: 5.6900e-05 - val_loss: 8.4377e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 944/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 994us/step - loss: 5.5949e-05 - val_loss: 8.4436e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 945/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765us/step - loss: 5.6438e-05 - val_loss: 8.4384e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 946/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692us/step - loss: 5.6539e-05 - val_loss: 8.4318e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 947/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970us/step - loss: 5.6406e-05 - val_loss: 8.4130e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 948/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687us/step - loss: 5.6013e-05 - val_loss: 8.4525e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 949/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - loss: 5.6328e-05 - val_loss: 8.4170e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 950/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770us/step - loss: 5.6522e-05 - val_loss: 8.4202e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 951/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - loss: 5.6762e-05 - val_loss: 8.4070e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 952/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 962us/step - loss: 5.6777e-05 - val_loss: 8.4172e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 953/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - loss: 5.7198e-05 - val_loss: 8.4147e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 954/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770us/step - loss: 5.6259e-05 - val_loss: 8.4339e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 955/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 746us/step - loss: 5.6696e-05 - val_loss: 8.4019e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 956/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - loss: 5.7014e-05 - val_loss: 8.3974e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 957/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765us/step - loss: 5.6579e-05 - val_loss: 8.3994e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 958/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - loss: 5.6345e-05 - val_loss: 8.4151e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 959/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 990us/step - loss: 5.5834e-05 - val_loss: 8.4084e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 960/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774us/step - loss: 5.6070e-05 - val_loss: 8.4117e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 961/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - loss: 5.6668e-05 - val_loss: 8.4261e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 962/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 968us/step - loss: 5.6399e-05 - val_loss: 8.4031e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 963/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - loss: 5.6349e-05 - val_loss: 8.4154e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 964/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 977us/step - loss: 5.6276e-05 - val_loss: 8.3963e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 965/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687us/step - loss: 5.6134e-05 - val_loss: 8.4041e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 966/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - loss: 5.6252e-05 - val_loss: 8.4140e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 967/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 755us/step - loss: 5.6638e-05 - val_loss: 8.3848e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 968/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step - loss: 5.6736e-05 - val_loss: 8.4031e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 969/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 766us/step - loss: 5.5889e-05 - val_loss: 8.4107e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 970/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - loss: 5.6513e-05 - val_loss: 8.3977e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 971/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 974us/step - loss: 5.6464e-05 - val_loss: 8.4295e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 972/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 5.6211e-05 - val_loss: 8.4152e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 973/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705us/step - loss: 5.6109e-05 - val_loss: 8.4440e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 974/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 944us/step - loss: 5.6446e-05 - val_loss: 8.4137e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 975/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - loss: 5.6452e-05 - val_loss: 8.4095e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 976/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 729us/step - loss: 5.6304e-05 - val_loss: 8.3955e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 977/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 954us/step - loss: 5.6210e-05 - val_loss: 8.4044e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 978/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 658us/step - loss: 5.5962e-05 - val_loss: 8.4128e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 979/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 719us/step - loss: 5.5851e-05 - val_loss: 8.3940e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 980/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 980us/step - loss: 5.6485e-05 - val_loss: 8.4094e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 981/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 672us/step - loss: 5.6950e-05 - val_loss: 8.4152e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 982/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 717us/step - loss: 5.6433e-05 - val_loss: 8.3913e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 983/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 961us/step - loss: 5.6202e-05 - val_loss: 8.4194e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 984/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 752us/step - loss: 5.6814e-05 - val_loss: 8.3982e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 985/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634us/step - loss: 5.6876e-05 - val_loss: 8.4187e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 986/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 995us/step - loss: 5.6476e-05 - val_loss: 8.4182e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 987/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 752us/step - loss: 5.6236e-05 - val_loss: 8.4228e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 988/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - loss: 5.6472e-05 - val_loss: 8.4150e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 989/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 895us/step - loss: 5.6539e-05 - val_loss: 8.4099e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 990/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 713us/step - loss: 5.6397e-05 - val_loss: 8.3971e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 991/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - loss: 5.5791e-05 - val_loss: 8.3782e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 992/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 890us/step - loss: 5.5960e-05 - val_loss: 8.3946e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 993/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step - loss: 5.6427e-05 - val_loss: 8.4175e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 994/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 653us/step - loss: 5.6567e-05 - val_loss: 8.3886e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 995/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 886us/step - loss: 5.6131e-05 - val_loss: 8.3747e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 996/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 777us/step - loss: 5.6478e-05 - val_loss: 8.3898e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 997/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 675us/step - loss: 5.6470e-05 - val_loss: 8.3947e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 998/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749us/step - loss: 5.6349e-05 - val_loss: 8.3957e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 999/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 995us/step - loss: 5.6425e-05 - val_loss: 8.3927e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1000/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - loss: 5.6271e-05 - val_loss: 8.3951e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1001/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736us/step - loss: 5.6318e-05 - val_loss: 8.4023e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1002/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 729us/step - loss: 5.6076e-05 - val_loss: 8.3842e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1003/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - loss: 5.6048e-05 - val_loss: 8.3933e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1004/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634us/step - loss: 5.5963e-05 - val_loss: 8.3779e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1005/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 981us/step - loss: 5.6327e-05 - val_loss: 8.3740e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1006/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749us/step - loss: 5.5934e-05 - val_loss: 8.3855e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1007/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 662us/step - loss: 5.6138e-05 - val_loss: 8.3803e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1008/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 972us/step - loss: 5.6577e-05 - val_loss: 8.3821e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1009/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - loss: 5.6485e-05 - val_loss: 8.3849e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1010/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758us/step - loss: 5.5934e-05 - val_loss: 8.3874e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1011/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5881e-05 - val_loss: 8.4041e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1012/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 719us/step - loss: 5.5978e-05 - val_loss: 8.3973e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1013/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 980us/step - loss: 5.5768e-05 - val_loss: 8.3918e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1014/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - loss: 5.6467e-05 - val_loss: 8.3835e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1015/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 761us/step - loss: 5.6546e-05 - val_loss: 8.3963e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1016/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5793e-05 - val_loss: 8.3794e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1017/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step - loss: 5.6278e-05 - val_loss: 8.3720e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1018/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 756us/step - loss: 5.6285e-05 - val_loss: 8.4041e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1019/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 982us/step - loss: 5.6317e-05 - val_loss: 8.3923e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1020/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - loss: 5.6429e-05 - val_loss: 8.3998e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1021/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 742us/step - loss: 5.6526e-05 - val_loss: 8.4022e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1022/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 967us/step - loss: 5.6261e-05 - val_loss: 8.3867e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1023/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793us/step - loss: 5.6315e-05 - val_loss: 8.3958e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1024/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 640us/step - loss: 5.5699e-05 - val_loss: 8.3966e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1025/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989us/step - loss: 5.6198e-05 - val_loss: 8.3891e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1026/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779us/step - loss: 5.6004e-05 - val_loss: 8.3775e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1027/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step - loss: 5.5919e-05 - val_loss: 8.4318e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1028/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.6402e-05 - val_loss: 8.3776e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1029/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 674us/step - loss: 5.6509e-05 - val_loss: 8.3870e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1030/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 674us/step - loss: 5.6373e-05 - val_loss: 8.3791e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1031/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.6087e-05 - val_loss: 8.3929e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1032/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692us/step - loss: 5.6046e-05 - val_loss: 8.3819e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1033/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 759us/step - loss: 5.5907e-05 - val_loss: 8.3870e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1034/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 893us/step - loss: 5.5847e-05 - val_loss: 8.3698e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1035/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 784us/step - loss: 5.6096e-05 - val_loss: 8.3913e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1036/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659us/step - loss: 5.6131e-05 - val_loss: 8.3930e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1037/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749us/step - loss: 5.6482e-05 - val_loss: 8.3867e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1038/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.6152e-05 - val_loss: 8.3627e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1039/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - loss: 5.6334e-05 - val_loss: 8.3846e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1040/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765us/step - loss: 5.6333e-05 - val_loss: 8.3810e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1041/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.6033e-05 - val_loss: 8.3886e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1042/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709us/step - loss: 5.6163e-05 - val_loss: 8.3899e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1043/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758us/step - loss: 5.5887e-05 - val_loss: 8.3537e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1044/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 934us/step - loss: 5.6302e-05 - val_loss: 8.4091e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1045/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 780us/step - loss: 5.6052e-05 - val_loss: 8.3763e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1046/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - loss: 5.5742e-05 - val_loss: 8.3747e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1047/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 714us/step - loss: 5.5745e-05 - val_loss: 8.4096e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1048/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781us/step - loss: 5.6380e-05 - val_loss: 8.3560e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1049/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5493e-05 - val_loss: 8.3795e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1050/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 724us/step - loss: 5.6099e-05 - val_loss: 8.3778e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1051/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.6103e-05 - val_loss: 8.3636e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1052/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 5.6195e-05 - val_loss: 8.3640e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1053/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - loss: 5.5774e-05 - val_loss: 8.3663e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1054/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step - loss: 5.5550e-05 - val_loss: 8.3642e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1055/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778us/step - loss: 5.6227e-05 - val_loss: 8.3668e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1056/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692us/step - loss: 5.6116e-05 - val_loss: 8.3660e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1057/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5786e-05 - val_loss: 8.3730e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1058/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778us/step - loss: 5.6099e-05 - val_loss: 8.3769e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1059/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705us/step - loss: 5.6444e-05 - val_loss: 8.4062e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1060/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5849e-05 - val_loss: 8.3533e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1061/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781us/step - loss: 5.5942e-05 - val_loss: 8.3984e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1062/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 680us/step - loss: 5.6058e-05 - val_loss: 8.3652e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1063/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 973us/step - loss: 5.5962e-05 - val_loss: 8.3600e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1064/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715us/step - loss: 5.5408e-05 - val_loss: 8.3647e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1065/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 5.6250e-05 - val_loss: 8.3631e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1066/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900us/step - loss: 5.5445e-05 - val_loss: 8.3675e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1067/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 792us/step - loss: 5.5709e-05 - val_loss: 8.3572e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1068/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 670us/step - loss: 5.6280e-05 - val_loss: 8.3685e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1069/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 986us/step - loss: 5.6682e-05 - val_loss: 8.3607e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1070/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 5.6253e-05 - val_loss: 8.3630e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1071/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - loss: 5.6047e-05 - val_loss: 8.3715e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1072/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5931e-05 - val_loss: 8.3872e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1073/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 676us/step - loss: 5.5975e-05 - val_loss: 8.3490e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1074/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 923us/step - loss: 5.5777e-05 - val_loss: 8.3781e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1075/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 792us/step - loss: 5.6209e-05 - val_loss: 8.3765e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1076/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step - loss: 5.6214e-05 - val_loss: 8.3635e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1077/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5719e-05 - val_loss: 8.3504e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1078/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step - loss: 5.6047e-05 - val_loss: 8.3657e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1079/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - loss: 5.6298e-05 - val_loss: 8.3672e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1080/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.6494e-05 - val_loss: 8.3546e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1081/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step - loss: 5.6824e-05 - val_loss: 8.3499e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1082/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - loss: 5.5572e-05 - val_loss: 8.3488e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1083/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.6863e-05 - val_loss: 8.3630e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1084/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 786us/step - loss: 5.6006e-05 - val_loss: 8.3592e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1085/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 680us/step - loss: 5.5510e-05 - val_loss: 8.3848e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1086/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 954us/step - loss: 5.5874e-05 - val_loss: 8.3510e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1087/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 791us/step - loss: 5.5737e-05 - val_loss: 8.3704e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1088/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.6282e-05 - val_loss: 8.3535e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1089/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 785us/step - loss: 5.6245e-05 - val_loss: 8.3457e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1090/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 707us/step - loss: 5.5221e-05 - val_loss: 8.3347e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1091/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5751e-05 - val_loss: 8.3653e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1092/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772us/step - loss: 5.5770e-05 - val_loss: 8.3554e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1093/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - loss: 5.5939e-05 - val_loss: 8.3754e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1094/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798us/step - loss: 5.6046e-05 - val_loss: 8.3356e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1095/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 761us/step - loss: 5.6393e-05 - val_loss: 8.3311e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1096/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - loss: 5.5284e-05 - val_loss: 8.3280e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1097/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834us/step - loss: 5.5676e-05 - val_loss: 8.3442e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1098/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 733us/step - loss: 5.6052e-05 - val_loss: 8.3366e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1099/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 961us/step - loss: 5.6341e-05 - val_loss: 8.3408e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1100/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793us/step - loss: 5.5686e-05 - val_loss: 8.3547e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1101/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5703e-05 - val_loss: 8.3438e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1102/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781us/step - loss: 5.5942e-05 - val_loss: 8.3577e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1103/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - loss: 5.5950e-05 - val_loss: 8.3519e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1104/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5966e-05 - val_loss: 8.3416e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1105/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781us/step - loss: 5.5801e-05 - val_loss: 8.3513e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1106/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 997us/step - loss: 5.6216e-05 - val_loss: 8.3552e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1107/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - loss: 5.5535e-05 - val_loss: 8.3329e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1108/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767us/step - loss: 5.5586e-05 - val_loss: 8.3405e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1109/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5805e-05 - val_loss: 8.3498e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1110/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 708us/step - loss: 5.6031e-05 - val_loss: 8.3471e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1111/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5999e-05 - val_loss: 8.3249e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1112/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step - loss: 5.6048e-05 - val_loss: 8.3306e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1113/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760us/step - loss: 5.5755e-05 - val_loss: 8.3346e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1114/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 951us/step - loss: 5.5897e-05 - val_loss: 8.3175e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1115/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833us/step - loss: 5.5625e-05 - val_loss: 8.3220e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1116/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step - loss: 5.5615e-05 - val_loss: 8.3262e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1117/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.6321e-05 - val_loss: 8.3365e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1118/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 714us/step - loss: 5.5979e-05 - val_loss: 8.3536e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1119/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.6312e-05 - val_loss: 8.3917e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1120/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step - loss: 5.5436e-05 - val_loss: 8.3326e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1121/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 751us/step - loss: 5.5783e-05 - val_loss: 8.3423e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1122/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 952us/step - loss: 5.5729e-05 - val_loss: 8.3385e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1123/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793us/step - loss: 5.5707e-05 - val_loss: 8.3440e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1124/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5745e-05 - val_loss: 8.3375e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1125/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 716us/step - loss: 5.5935e-05 - val_loss: 8.3371e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1126/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5424e-05 - val_loss: 8.3232e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1127/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798us/step - loss: 5.5456e-05 - val_loss: 8.3289e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1128/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 999us/step - loss: 5.5746e-05 - val_loss: 8.3734e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1129/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 717us/step - loss: 5.5739e-05 - val_loss: 8.3486e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1130/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step - loss: 5.5914e-05 - val_loss: 8.3667e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1131/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5221e-05 - val_loss: 8.3315e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1132/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step - loss: 5.5848e-05 - val_loss: 8.3319e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1133/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5489e-05 - val_loss: 8.3652e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1134/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step - loss: 5.6069e-05 - val_loss: 8.3253e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1135/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763us/step - loss: 5.5469e-05 - val_loss: 8.3278e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1136/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 969us/step - loss: 5.5557e-05 - val_loss: 8.3156e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1137/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 792us/step - loss: 5.6147e-05 - val_loss: 8.3340e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1138/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 677us/step - loss: 5.5738e-05 - val_loss: 8.3174e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1139/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762us/step - loss: 5.6073e-05 - val_loss: 8.3257e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1140/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 785us/step - loss: 5.5798e-05 - val_loss: 8.3265e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1141/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 939us/step - loss: 5.5524e-05 - val_loss: 8.3320e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1142/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 761us/step - loss: 5.5665e-05 - val_loss: 8.3400e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1143/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5689e-05 - val_loss: 8.3158e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1144/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step - loss: 5.5949e-05 - val_loss: 8.3452e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1145/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 784us/step - loss: 5.6264e-05 - val_loss: 8.3190e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1146/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 958us/step - loss: 5.5938e-05 - val_loss: 8.3219e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1147/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step - loss: 5.5443e-05 - val_loss: 8.3157e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1148/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - loss: 5.5586e-05 - val_loss: 8.2932e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1149/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 966us/step - loss: 5.5620e-05 - val_loss: 8.3164e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1150/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 786us/step - loss: 5.5661e-05 - val_loss: 8.3231e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1151/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5986e-05 - val_loss: 8.3159e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1152/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step - loss: 5.5770e-05 - val_loss: 8.3603e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1153/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 708us/step - loss: 5.5934e-05 - val_loss: 8.3108e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1154/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875us/step - loss: 5.5366e-05 - val_loss: 8.3167e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1155/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 780us/step - loss: 5.5364e-05 - val_loss: 8.3378e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1156/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 924us/step - loss: 5.5914e-05 - val_loss: 8.3332e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1157/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 5.5291e-05 - val_loss: 8.3741e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1158/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 755us/step - loss: 5.5867e-05 - val_loss: 8.3628e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1159/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - loss: 5.5567e-05 - val_loss: 8.3167e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1160/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - loss: 5.5590e-05 - val_loss: 8.3131e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1161/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step - loss: 5.6159e-05 - val_loss: 8.2971e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1162/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5915e-05 - val_loss: 8.3035e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1163/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 714us/step - loss: 5.5388e-05 - val_loss: 8.3063e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1164/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5646e-05 - val_loss: 8.3080e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1165/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step - loss: 5.6149e-05 - val_loss: 8.3292e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1166/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778us/step - loss: 5.4890e-05 - val_loss: 8.3099e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1167/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 963us/step - loss: 5.5935e-05 - val_loss: 8.3299e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1168/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - loss: 5.6052e-05 - val_loss: 8.3255e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1169/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5583e-05 - val_loss: 8.2954e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1170/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 741us/step - loss: 5.5154e-05 - val_loss: 8.3153e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1171/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793us/step - loss: 5.5673e-05 - val_loss: 8.2997e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1172/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.5581e-05 - val_loss: 8.3077e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1173/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 979us/step - loss: 5.5841e-05 - val_loss: 8.3270e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1174/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5767e-05 - val_loss: 8.3262e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1175/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 725us/step - loss: 5.5259e-05 - val_loss: 8.3161e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1176/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5523e-05 - val_loss: 8.2983e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1177/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - loss: 5.5752e-05 - val_loss: 8.2946e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1178/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5332e-05 - val_loss: 8.3199e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1179/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 729us/step - loss: 5.5317e-05 - val_loss: 8.3241e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1180/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step - loss: 5.5515e-05 - val_loss: 8.2908e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1181/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5330e-05 - val_loss: 8.3078e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1182/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 713us/step - loss: 5.5928e-05 - val_loss: 8.3130e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1183/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5724e-05 - val_loss: 8.3021e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1184/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 795us/step - loss: 5.6017e-05 - val_loss: 8.3034e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1185/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.6175e-05 - val_loss: 8.3050e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1186/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 742us/step - loss: 5.5235e-05 - val_loss: 8.3222e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1187/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5554e-05 - val_loss: 8.2822e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1188/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step - loss: 5.6222e-05 - val_loss: 8.3167e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1189/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - loss: 5.5755e-05 - val_loss: 8.2938e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1190/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5981e-05 - val_loss: 8.2905e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1191/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 784us/step - loss: 5.5246e-05 - val_loss: 8.3314e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1192/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5346e-05 - val_loss: 8.3216e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1193/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 730us/step - loss: 5.5476e-05 - val_loss: 8.2979e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1194/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 786us/step - loss: 5.5517e-05 - val_loss: 8.2996e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1195/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5653e-05 - val_loss: 8.3051e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1196/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 721us/step - loss: 5.5781e-05 - val_loss: 8.2884e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1197/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5833e-05 - val_loss: 8.2884e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1198/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step - loss: 5.5313e-05 - val_loss: 8.3028e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1199/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 5.5481e-05 - val_loss: 8.3019e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1200/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 974us/step - loss: 5.5652e-05 - val_loss: 8.2916e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1201/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798us/step - loss: 5.5667e-05 - val_loss: 8.3068e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1202/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5064e-05 - val_loss: 8.3236e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1203/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 791us/step - loss: 5.5737e-05 - val_loss: 8.2937e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1204/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740us/step - loss: 5.5497e-05 - val_loss: 8.2863e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1205/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step - loss: 5.5743e-05 - val_loss: 8.3108e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1206/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798us/step - loss: 5.5797e-05 - val_loss: 8.2919e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1207/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.6338e-05 - val_loss: 8.2817e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1208/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 722us/step - loss: 5.5071e-05 - val_loss: 8.3015e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1209/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5581e-05 - val_loss: 8.3008e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1210/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step - loss: 5.5405e-05 - val_loss: 8.2911e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1211/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781us/step - loss: 5.6059e-05 - val_loss: 8.2938e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1212/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971us/step - loss: 5.5514e-05 - val_loss: 8.2852e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1213/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step - loss: 5.5814e-05 - val_loss: 8.2772e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1214/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5384e-05 - val_loss: 8.3055e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1215/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step - loss: 5.5006e-05 - val_loss: 8.2933e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1216/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step - loss: 5.5549e-05 - val_loss: 8.3038e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1217/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step - loss: 5.5721e-05 - val_loss: 8.2905e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1218/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 784us/step - loss: 5.5147e-05 - val_loss: 8.2918e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1219/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - loss: 5.5696e-05 - val_loss: 8.3036e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1220/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - loss: 5.5348e-05 - val_loss: 8.2904e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1221/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 785us/step - loss: 5.5574e-05 - val_loss: 8.2980e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1222/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5337e-05 - val_loss: 8.3040e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1223/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 718us/step - loss: 5.5044e-05 - val_loss: 8.2906e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1224/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5643e-05 - val_loss: 8.2833e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1225/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step - loss: 5.5559e-05 - val_loss: 8.2721e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1226/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 720us/step - loss: 5.5676e-05 - val_loss: 8.3009e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1227/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5569e-05 - val_loss: 8.2888e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1228/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 5.5532e-05 - val_loss: 8.2882e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1229/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5322e-05 - val_loss: 8.3106e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1230/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 726us/step - loss: 5.5739e-05 - val_loss: 8.2925e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1231/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833us/step - loss: 5.5427e-05 - val_loss: 8.2802e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1232/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5283e-05 - val_loss: 8.3278e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1233/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779us/step - loss: 5.4737e-05 - val_loss: 8.2733e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1234/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 961us/step - loss: 5.4702e-05 - val_loss: 8.2737e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1235/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step - loss: 5.5543e-05 - val_loss: 8.2854e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1236/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.6058e-05 - val_loss: 8.2757e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1237/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - loss: 5.5421e-05 - val_loss: 8.2833e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1238/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5240e-05 - val_loss: 8.2791e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1239/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - loss: 5.5956e-05 - val_loss: 8.2622e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1240/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5449e-05 - val_loss: 8.2737e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1241/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 742us/step - loss: 5.4936e-05 - val_loss: 8.2848e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1242/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5551e-05 - val_loss: 8.2687e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1243/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - loss: 5.5522e-05 - val_loss: 8.2765e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1244/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 780us/step - loss: 5.5200e-05 - val_loss: 8.2906e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1245/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 981us/step - loss: 5.4691e-05 - val_loss: 8.2873e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1246/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - loss: 5.5107e-05 - val_loss: 8.2919e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1247/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5317e-05 - val_loss: 8.2742e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1248/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step - loss: 5.5512e-05 - val_loss: 8.2806e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1249/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 972us/step - loss: 5.5827e-05 - val_loss: 8.2739e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1250/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - loss: 5.5587e-05 - val_loss: 8.2698e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1251/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5555e-05 - val_loss: 8.2941e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1252/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - loss: 5.5074e-05 - val_loss: 8.2622e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1253/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 967us/step - loss: 5.5346e-05 - val_loss: 8.2703e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1254/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - loss: 5.5386e-05 - val_loss: 8.2831e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1255/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5271e-05 - val_loss: 8.2637e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1256/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - loss: 5.5612e-05 - val_loss: 8.2722e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1257/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5466e-05 - val_loss: 8.2848e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1258/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step - loss: 5.5212e-05 - val_loss: 8.2574e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1259/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5678e-05 - val_loss: 8.2652e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1260/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 725us/step - loss: 5.5216e-05 - val_loss: 8.2841e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1261/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5160e-05 - val_loss: 8.2571e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1262/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step - loss: 5.5197e-05 - val_loss: 8.2537e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1263/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5624e-05 - val_loss: 8.2921e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1264/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 727us/step - loss: 5.4910e-05 - val_loss: 8.2791e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1265/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4909e-05 - val_loss: 8.2724e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1266/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 823us/step - loss: 5.5168e-05 - val_loss: 8.2854e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1267/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5237e-05 - val_loss: 8.2801e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1268/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712us/step - loss: 5.5189e-05 - val_loss: 8.2675e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1269/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5274e-05 - val_loss: 8.2460e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1270/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step - loss: 5.5041e-05 - val_loss: 8.2719e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1271/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5531e-05 - val_loss: 8.2629e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1272/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step - loss: 5.5110e-05 - val_loss: 8.2780e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1273/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5702e-05 - val_loss: 8.2725e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1274/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851us/step - loss: 5.5139e-05 - val_loss: 8.2516e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1275/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5535e-05 - val_loss: 8.2559e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1276/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 720us/step - loss: 5.5379e-05 - val_loss: 8.2669e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1277/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5072e-05 - val_loss: 8.3221e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1278/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step - loss: 5.5098e-05 - val_loss: 8.2438e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1279/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5765e-05 - val_loss: 8.2808e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1280/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820us/step - loss: 5.5270e-05 - val_loss: 8.2624e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1281/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5119e-05 - val_loss: 8.2623e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1282/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step - loss: 5.5103e-05 - val_loss: 8.2703e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1283/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5127e-05 - val_loss: 8.2599e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1284/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 734us/step - loss: 5.5594e-05 - val_loss: 8.2618e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1285/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5560e-05 - val_loss: 8.2664e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1286/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 795us/step - loss: 5.5110e-05 - val_loss: 8.2543e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1287/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5257e-05 - val_loss: 8.2573e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1288/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step - loss: 5.5075e-05 - val_loss: 8.2658e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1289/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5443e-05 - val_loss: 8.2505e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1290/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715us/step - loss: 5.4922e-05 - val_loss: 8.2598e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1291/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5468e-05 - val_loss: 8.2488e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1292/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - loss: 5.4999e-05 - val_loss: 8.2484e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1293/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5624e-05 - val_loss: 8.2601e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1294/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step - loss: 5.5094e-05 - val_loss: 8.2533e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1295/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5011e-05 - val_loss: 8.2344e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1296/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798us/step - loss: 5.5057e-05 - val_loss: 8.2774e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1297/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5369e-05 - val_loss: 8.2585e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1298/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736us/step - loss: 5.5112e-05 - val_loss: 8.2479e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1299/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5521e-05 - val_loss: 8.2505e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1300/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829us/step - loss: 5.5148e-05 - val_loss: 8.2571e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1301/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5258e-05 - val_loss: 8.2617e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1302/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step - loss: 5.5246e-05 - val_loss: 8.2370e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1303/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5188e-05 - val_loss: 8.2500e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1304/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step - loss: 5.5257e-05 - val_loss: 8.2418e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1305/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 725us/step - loss: 5.5381e-05 - val_loss: 8.2656e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1306/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4828e-05 - val_loss: 8.2853e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1307/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step - loss: 5.4670e-05 - val_loss: 8.2568e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1308/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5420e-05 - val_loss: 8.2513e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1309/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 822us/step - loss: 5.5089e-05 - val_loss: 8.2619e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1310/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 939us/step - loss: 5.5023e-05 - val_loss: 8.2632e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1311/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762us/step - loss: 5.5207e-05 - val_loss: 8.2758e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1312/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step - loss: 5.5561e-05 - val_loss: 8.2434e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1313/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4921e-05 - val_loss: 8.2526e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1314/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 5.4956e-05 - val_loss: 8.2514e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1315/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5272e-05 - val_loss: 8.2179e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1316/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 5.4986e-05 - val_loss: 8.2523e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1317/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5041e-05 - val_loss: 8.2320e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1318/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715us/step - loss: 5.5388e-05 - val_loss: 8.2794e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1319/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5020e-05 - val_loss: 8.2636e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1320/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step - loss: 5.5509e-05 - val_loss: 8.2420e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1321/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4847e-05 - val_loss: 8.2245e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1322/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step - loss: 5.5046e-05 - val_loss: 8.2303e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1323/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step - loss: 5.5364e-05 - val_loss: 8.2220e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1324/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 761us/step - loss: 5.5276e-05 - val_loss: 8.2601e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1325/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5284e-05 - val_loss: 8.2506e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1326/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 871us/step - loss: 5.4714e-05 - val_loss: 8.2631e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1327/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - loss: 5.5147e-05 - val_loss: 8.2528e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1328/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 759us/step - loss: 5.5278e-05 - val_loss: 8.2550e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1329/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 974us/step - loss: 5.5320e-05 - val_loss: 8.2442e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1330/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - loss: 5.5096e-05 - val_loss: 8.2410e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1331/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4645e-05 - val_loss: 8.2259e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1332/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819us/step - loss: 5.5178e-05 - val_loss: 8.2270e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1333/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798us/step - loss: 5.5277e-05 - val_loss: 8.2221e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1334/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5190e-05 - val_loss: 8.2427e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1335/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798us/step - loss: 5.5176e-05 - val_loss: 8.2795e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1336/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5019e-05 - val_loss: 8.2338e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1337/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 733us/step - loss: 5.5246e-05 - val_loss: 8.2148e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1338/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4881e-05 - val_loss: 8.2239e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1339/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step - loss: 5.5303e-05 - val_loss: 8.2741e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1340/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5477e-05 - val_loss: 8.2482e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1341/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step - loss: 5.5613e-05 - val_loss: 8.2246e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1342/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5311e-05 - val_loss: 8.2270e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1343/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - loss: 5.5042e-05 - val_loss: 8.2333e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1344/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 886us/step - loss: 5.5315e-05 - val_loss: 8.2168e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1345/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - loss: 5.4762e-05 - val_loss: 8.2052e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1346/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step - loss: 5.5045e-05 - val_loss: 8.2357e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1347/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4756e-05 - val_loss: 8.2156e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1348/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - loss: 5.4363e-05 - val_loss: 8.2370e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1349/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4779e-05 - val_loss: 8.2276e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1350/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747us/step - loss: 5.5030e-05 - val_loss: 8.2474e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1351/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4822e-05 - val_loss: 8.2277e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1352/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 852us/step - loss: 5.5283e-05 - val_loss: 8.2330e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1353/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step - loss: 5.5152e-05 - val_loss: 8.2313e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1354/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5482e-05 - val_loss: 8.2208e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1355/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step - loss: 5.5174e-05 - val_loss: 8.2245e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1356/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4799e-05 - val_loss: 8.2471e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1357/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 983us/step - loss: 5.5213e-05 - val_loss: 8.2105e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1358/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 769us/step - loss: 5.5266e-05 - val_loss: 8.2407e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1359/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step - loss: 5.4892e-05 - val_loss: 8.2095e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1360/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4593e-05 - val_loss: 8.2153e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1361/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - loss: 5.5528e-05 - val_loss: 8.2248e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1362/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4448e-05 - val_loss: 8.2277e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1363/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - loss: 5.5137e-05 - val_loss: 8.2387e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1364/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4967e-05 - val_loss: 8.2361e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1365/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step - loss: 5.4718e-05 - val_loss: 8.2141e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1366/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5115e-05 - val_loss: 8.2303e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1367/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - loss: 5.5247e-05 - val_loss: 8.2133e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1368/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5160e-05 - val_loss: 8.2060e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1369/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - loss: 5.4578e-05 - val_loss: 8.2273e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1370/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5422e-05 - val_loss: 8.2437e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1371/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - loss: 5.4824e-05 - val_loss: 8.2313e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1372/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4563e-05 - val_loss: 8.2411e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1373/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 791us/step - loss: 5.4895e-05 - val_loss: 8.2390e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1374/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - loss: 5.5302e-05 - val_loss: 8.2241e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1375/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - loss: 5.4938e-05 - val_loss: 8.2072e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1376/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4589e-05 - val_loss: 8.2216e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1377/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - loss: 5.5121e-05 - val_loss: 8.2241e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1378/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4834e-05 - val_loss: 8.2215e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1379/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798us/step - loss: 5.4513e-05 - val_loss: 8.2120e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1380/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 975us/step - loss: 5.5136e-05 - val_loss: 8.2151e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1381/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - loss: 5.5140e-05 - val_loss: 8.2171e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1382/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4781e-05 - val_loss: 8.2179e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1383/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 5.5091e-05 - val_loss: 8.2278e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1384/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5162e-05 - val_loss: 8.2225e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1385/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825us/step - loss: 5.5775e-05 - val_loss: 8.2255e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1386/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5372e-05 - val_loss: 8.2340e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1387/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740us/step - loss: 5.5023e-05 - val_loss: 8.2010e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1388/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5053e-05 - val_loss: 8.2143e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1389/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825us/step - loss: 5.4840e-05 - val_loss: 8.2336e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1390/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4731e-05 - val_loss: 8.1979e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1391/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 822us/step - loss: 5.5178e-05 - val_loss: 8.1934e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1392/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5030e-05 - val_loss: 8.2170e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1393/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820us/step - loss: 5.5105e-05 - val_loss: 8.2149e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1394/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4807e-05 - val_loss: 8.2032e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1395/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 737us/step - loss: 5.5220e-05 - val_loss: 8.2139e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1396/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4934e-05 - val_loss: 8.2003e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1397/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - loss: 5.4760e-05 - val_loss: 8.2002e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1398/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5026e-05 - val_loss: 8.2522e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1399/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step - loss: 5.5045e-05 - val_loss: 8.2292e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1400/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4881e-05 - val_loss: 8.2132e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1401/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - loss: 5.4682e-05 - val_loss: 8.2276e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1402/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4828e-05 - val_loss: 8.1986e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1403/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step - loss: 5.4539e-05 - val_loss: 8.2255e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1404/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4685e-05 - val_loss: 8.1967e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1405/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 739us/step - loss: 5.4500e-05 - val_loss: 8.1984e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1406/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5320e-05 - val_loss: 8.2151e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1407/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 5.4290e-05 - val_loss: 8.1939e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1408/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4749e-05 - val_loss: 8.1910e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1409/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step - loss: 5.4846e-05 - val_loss: 8.2054e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1410/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4506e-05 - val_loss: 8.1956e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1411/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step - loss: 5.4833e-05 - val_loss: 8.1858e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1412/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4899e-05 - val_loss: 8.2026e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1413/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step - loss: 5.4830e-05 - val_loss: 8.2024e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1414/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5546e-05 - val_loss: 8.1920e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1415/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 744us/step - loss: 5.4815e-05 - val_loss: 8.2043e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1416/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4704e-05 - val_loss: 8.1945e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1417/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - loss: 5.4998e-05 - val_loss: 8.2103e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1418/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4895e-05 - val_loss: 8.1954e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1419/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820us/step - loss: 5.4798e-05 - val_loss: 8.1961e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1420/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4619e-05 - val_loss: 8.2462e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1421/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - loss: 5.4845e-05 - val_loss: 8.2006e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1422/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5024e-05 - val_loss: 8.2044e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1423/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 939us/step - loss: 5.5221e-05 - val_loss: 8.1902e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1424/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850us/step - loss: 5.4921e-05 - val_loss: 8.2391e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1425/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step - loss: 5.5029e-05 - val_loss: 8.1971e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1426/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5021e-05 - val_loss: 8.2077e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1427/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - loss: 5.4307e-05 - val_loss: 8.2059e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1428/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4626e-05 - val_loss: 8.2085e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1429/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749us/step - loss: 5.5106e-05 - val_loss: 8.1829e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1430/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4934e-05 - val_loss: 8.2062e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1431/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4342e-05 - val_loss: 8.1803e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1432/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - loss: 5.4744e-05 - val_loss: 8.1994e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1433/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - loss: 5.4894e-05 - val_loss: 8.2078e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1434/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4883e-05 - val_loss: 8.1812e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1435/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833us/step - loss: 5.4464e-05 - val_loss: 8.2083e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1436/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996us/step - loss: 5.4811e-05 - val_loss: 8.1960e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1437/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - loss: 5.5130e-05 - val_loss: 8.1925e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1438/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4572e-05 - val_loss: 8.1705e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1439/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.4876e-05 - val_loss: 8.2138e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1440/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4908e-05 - val_loss: 8.2179e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1441/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4806e-05 - val_loss: 8.1695e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1442/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781us/step - loss: 5.4397e-05 - val_loss: 8.1712e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1443/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5152e-05 - val_loss: 8.1820e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1444/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 5.4851e-05 - val_loss: 8.1665e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1445/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4490e-05 - val_loss: 8.1903e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1446/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - loss: 5.4748e-05 - val_loss: 8.2300e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1447/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4961e-05 - val_loss: 8.2074e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1448/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step - loss: 5.4974e-05 - val_loss: 8.1638e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1449/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4294e-05 - val_loss: 8.1978e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1450/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 741us/step - loss: 5.4994e-05 - val_loss: 8.1863e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1451/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step - loss: 5.4708e-05 - val_loss: 8.1763e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1452/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834us/step - loss: 5.4969e-05 - val_loss: 8.1877e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1453/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4783e-05 - val_loss: 8.1852e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1454/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step - loss: 5.4323e-05 - val_loss: 8.1668e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1455/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4839e-05 - val_loss: 8.2013e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1456/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 799us/step - loss: 5.4612e-05 - val_loss: 8.2009e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1457/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4860e-05 - val_loss: 8.1729e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1458/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 738us/step - loss: 5.4497e-05 - val_loss: 8.1688e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1459/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4792e-05 - val_loss: 8.1821e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1460/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828us/step - loss: 5.4648e-05 - val_loss: 8.1935e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1461/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4395e-05 - val_loss: 8.1686e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1462/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step - loss: 5.4646e-05 - val_loss: 8.1745e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1463/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4400e-05 - val_loss: 8.1786e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1464/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step - loss: 5.4979e-05 - val_loss: 8.1942e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1465/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4519e-05 - val_loss: 8.1817e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1466/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736us/step - loss: 5.4619e-05 - val_loss: 8.1820e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1467/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4154e-05 - val_loss: 8.1630e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1468/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step - loss: 5.4909e-05 - val_loss: 8.1622e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1469/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4438e-05 - val_loss: 8.1867e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1470/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step - loss: 5.4592e-05 - val_loss: 8.1816e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1471/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4598e-05 - val_loss: 8.1677e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1472/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.4632e-05 - val_loss: 8.1801e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1473/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 940us/step - loss: 5.4751e-05 - val_loss: 8.1738e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1474/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829us/step - loss: 5.4178e-05 - val_loss: 8.2016e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1475/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4235e-05 - val_loss: 8.1963e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1476/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4972e-05 - val_loss: 8.1644e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1477/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - loss: 5.4426e-05 - val_loss: 8.1519e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1478/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step - loss: 5.4332e-05 - val_loss: 8.1735e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1479/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4924e-05 - val_loss: 8.1813e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1480/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step - loss: 5.4250e-05 - val_loss: 8.1991e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1481/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4465e-05 - val_loss: 8.1723e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1482/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 733us/step - loss: 5.4043e-05 - val_loss: 8.2091e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1483/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4648e-05 - val_loss: 8.1890e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1484/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4779e-05 - val_loss: 8.1758e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1485/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step - loss: 5.4867e-05 - val_loss: 8.1580e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1486/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4541e-05 - val_loss: 8.1640e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1487/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825us/step - loss: 5.4329e-05 - val_loss: 8.1874e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1488/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4550e-05 - val_loss: 8.1685e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1489/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4735e-05 - val_loss: 8.1773e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1490/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - loss: 5.3966e-05 - val_loss: 8.1820e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1491/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4833e-05 - val_loss: 8.1596e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1492/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step - loss: 5.4528e-05 - val_loss: 8.1700e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1493/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4711e-05 - val_loss: 8.1684e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1494/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 759us/step - loss: 5.4839e-05 - val_loss: 8.1569e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1495/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4439e-05 - val_loss: 8.1638e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1496/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819us/step - loss: 5.4932e-05 - val_loss: 8.1569e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1497/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4051e-05 - val_loss: 8.1575e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1498/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step - loss: 5.4789e-05 - val_loss: 8.1678e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1499/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4991e-05 - val_loss: 8.1713e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1500/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - loss: 5.4823e-05 - val_loss: 8.1537e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1501/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4483e-05 - val_loss: 8.1464e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1502/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step - loss: 5.5045e-05 - val_loss: 8.1905e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1503/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4983e-05 - val_loss: 8.1878e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1504/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 746us/step - loss: 5.4629e-05 - val_loss: 8.1696e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1505/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4376e-05 - val_loss: 8.1681e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1506/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825us/step - loss: 5.5087e-05 - val_loss: 8.1533e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1507/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4635e-05 - val_loss: 8.1724e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1508/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 874us/step - loss: 5.3963e-05 - val_loss: 8.1589e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1509/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4570e-05 - val_loss: 8.1624e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1510/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step - loss: 5.4507e-05 - val_loss: 8.1682e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1511/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4548e-05 - val_loss: 8.1536e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1512/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - loss: 5.4665e-05 - val_loss: 8.1463e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1513/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4471e-05 - val_loss: 8.1455e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1514/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4326e-05 - val_loss: 8.1720e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1515/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - loss: 5.4382e-05 - val_loss: 8.1556e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1516/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4735e-05 - val_loss: 8.1559e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1517/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4510e-05 - val_loss: 8.1509e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1518/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - loss: 5.4551e-05 - val_loss: 8.1335e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1519/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4688e-05 - val_loss: 8.1615e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1520/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - loss: 5.4786e-05 - val_loss: 8.1469e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1521/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4194e-05 - val_loss: 8.1395e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1522/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - loss: 5.4575e-05 - val_loss: 8.1532e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1523/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4505e-05 - val_loss: 8.1588e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1524/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 981us/step - loss: 5.4224e-05 - val_loss: 8.1656e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1525/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - loss: 5.4529e-05 - val_loss: 8.1661e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1526/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step - loss: 5.4868e-05 - val_loss: 8.1491e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1527/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4611e-05 - val_loss: 8.1516e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1528/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - loss: 5.4514e-05 - val_loss: 8.1759e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1529/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4934e-05 - val_loss: 8.1573e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1530/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step - loss: 5.4543e-05 - val_loss: 8.1520e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1531/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4722e-05 - val_loss: 8.1416e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1532/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - loss: 5.4190e-05 - val_loss: 8.1527e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1533/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4161e-05 - val_loss: 8.1272e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1534/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834us/step - loss: 5.4613e-05 - val_loss: 8.1184e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1535/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4340e-05 - val_loss: 8.1384e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1536/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820us/step - loss: 5.4744e-05 - val_loss: 8.1398e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1537/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4468e-05 - val_loss: 8.1617e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1538/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 822us/step - loss: 5.4357e-05 - val_loss: 8.1724e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1539/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4012e-05 - val_loss: 8.1489e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1540/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4267e-05 - val_loss: 8.1340e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1541/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 863us/step - loss: 5.4830e-05 - val_loss: 8.1920e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1542/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4082e-05 - val_loss: 8.1592e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1543/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step - loss: 5.4103e-05 - val_loss: 8.1535e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1544/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4656e-05 - val_loss: 8.1279e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1545/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838us/step - loss: 5.4104e-05 - val_loss: 8.1489e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1546/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4650e-05 - val_loss: 8.1261e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1547/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - loss: 5.4354e-05 - val_loss: 8.1246e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1548/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4106e-05 - val_loss: 8.1332e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1549/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - loss: 5.4402e-05 - val_loss: 8.1616e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1550/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4514e-05 - val_loss: 8.1383e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1551/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4459e-05 - val_loss: 8.1248e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1552/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838us/step - loss: 5.4627e-05 - val_loss: 8.1544e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1553/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4445e-05 - val_loss: 8.1249e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1554/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - loss: 5.4448e-05 - val_loss: 8.1402e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1555/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4346e-05 - val_loss: 8.1303e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1556/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 869us/step - loss: 5.3802e-05 - val_loss: 8.1375e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1557/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3991e-05 - val_loss: 8.1545e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1558/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834us/step - loss: 5.4276e-05 - val_loss: 8.1525e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1559/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4187e-05 - val_loss: 8.1272e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1560/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - loss: 5.4587e-05 - val_loss: 8.1444e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1561/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4589e-05 - val_loss: 8.1262e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1562/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step - loss: 5.4292e-05 - val_loss: 8.1615e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1563/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4277e-05 - val_loss: 8.1282e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1564/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4013e-05 - val_loss: 8.1455e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1565/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 866us/step - loss: 5.4245e-05 - val_loss: 8.1245e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1566/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4336e-05 - val_loss: 8.1413e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1567/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 857us/step - loss: 5.4318e-05 - val_loss: 8.1399e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1568/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4679e-05 - val_loss: 8.1325e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1569/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - loss: 5.4485e-05 - val_loss: 8.1159e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1570/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4393e-05 - val_loss: 8.1354e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1571/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step - loss: 5.4374e-05 - val_loss: 8.1370e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1572/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4458e-05 - val_loss: 8.1312e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1573/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - loss: 5.4744e-05 - val_loss: 8.1480e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1574/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4591e-05 - val_loss: 8.1632e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1575/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825us/step - loss: 5.4362e-05 - val_loss: 8.1629e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1576/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4295e-05 - val_loss: 8.1494e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1577/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - loss: 5.5016e-05 - val_loss: 8.1296e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1578/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4178e-05 - val_loss: 8.1587e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1579/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - loss: 5.3865e-05 - val_loss: 8.1301e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1580/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4338e-05 - val_loss: 8.1508e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1581/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - loss: 5.4295e-05 - val_loss: 8.1265e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1582/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3964e-05 - val_loss: 8.1107e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1583/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819us/step - loss: 5.4134e-05 - val_loss: 8.1148e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1584/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4401e-05 - val_loss: 8.1313e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1585/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 748us/step - loss: 5.4762e-05 - val_loss: 8.1279e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1586/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4688e-05 - val_loss: 8.1167e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1587/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step - loss: 5.4249e-05 - val_loss: 8.1283e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1588/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3997e-05 - val_loss: 8.1290e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1589/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4513e-05 - val_loss: 8.1239e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1590/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850us/step - loss: 5.3760e-05 - val_loss: 8.1249e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1591/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 953us/step - loss: 5.4047e-05 - val_loss: 8.1110e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1592/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4420e-05 - val_loss: 8.1315e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1593/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4037e-05 - val_loss: 8.1337e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1594/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 880us/step - loss: 5.3902e-05 - val_loss: 8.1408e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1595/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 983us/step - loss: 5.4375e-05 - val_loss: 8.1236e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1596/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - loss: 5.4524e-05 - val_loss: 8.1169e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1597/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4046e-05 - val_loss: 8.1255e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1598/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - loss: 5.4319e-05 - val_loss: 8.1364e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1599/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4255e-05 - val_loss: 8.1221e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1600/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - loss: 5.4329e-05 - val_loss: 8.1484e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1601/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.4211e-05 - val_loss: 8.1451e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1602/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.4513e-05 - val_loss: 8.1101e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1603/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4811e-05 - val_loss: 8.1165e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1604/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - loss: 5.4122e-05 - val_loss: 8.1133e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1605/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4565e-05 - val_loss: 8.1061e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1606/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step - loss: 5.4006e-05 - val_loss: 8.1349e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1607/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4391e-05 - val_loss: 8.1324e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1608/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - loss: 5.4826e-05 - val_loss: 8.1122e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1609/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4354e-05 - val_loss: 8.1147e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1610/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4370e-05 - val_loss: 8.1208e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1611/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - loss: 5.3587e-05 - val_loss: 8.1204e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1612/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4528e-05 - val_loss: 8.1290e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1613/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3809e-05 - val_loss: 8.1310e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1614/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step - loss: 5.4513e-05 - val_loss: 8.1396e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1615/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3827e-05 - val_loss: 8.1212e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1616/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829us/step - loss: 5.4367e-05 - val_loss: 8.1077e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1617/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4505e-05 - val_loss: 8.1033e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1618/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - loss: 5.4519e-05 - val_loss: 8.1146e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1619/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4199e-05 - val_loss: 8.1031e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1620/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step - loss: 5.4193e-05 - val_loss: 8.1050e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1621/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3860e-05 - val_loss: 8.1191e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1622/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4703e-05 - val_loss: 8.0999e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1623/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - loss: 5.4299e-05 - val_loss: 8.1317e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1624/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3894e-05 - val_loss: 8.1187e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1625/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - loss: 5.4468e-05 - val_loss: 8.1206e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1626/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4200e-05 - val_loss: 8.1194e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1627/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4567e-05 - val_loss: 8.1120e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1628/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3847e-05 - val_loss: 8.1105e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1629/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4627e-05 - val_loss: 8.1086e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1630/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - loss: 5.4465e-05 - val_loss: 8.1293e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1631/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4241e-05 - val_loss: 8.1083e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1632/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - loss: 5.4206e-05 - val_loss: 8.1229e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1633/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3938e-05 - val_loss: 8.1176e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1634/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.4249e-05 - val_loss: 8.1013e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1635/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3604e-05 - val_loss: 8.0983e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1636/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4090e-05 - val_loss: 8.1117e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1637/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4310e-05 - val_loss: 8.1292e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1638/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step - loss: 5.4034e-05 - val_loss: 8.0860e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1639/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3849e-05 - val_loss: 8.1123e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1640/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - loss: 5.4487e-05 - val_loss: 8.0936e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1641/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4038e-05 - val_loss: 8.1011e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1642/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 863us/step - loss: 5.4503e-05 - val_loss: 8.1309e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1643/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4491e-05 - val_loss: 8.0896e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1644/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749us/step - loss: 5.4003e-05 - val_loss: 8.0856e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1645/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4208e-05 - val_loss: 8.1131e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1646/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3869e-05 - val_loss: 8.1116e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1647/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 866us/step - loss: 5.4196e-05 - val_loss: 8.0801e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1648/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4513e-05 - val_loss: 8.1083e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1649/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - loss: 5.4485e-05 - val_loss: 8.1005e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1650/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4507e-05 - val_loss: 8.0991e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1651/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - loss: 5.4245e-05 - val_loss: 8.1162e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1652/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3800e-05 - val_loss: 8.1047e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1653/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828us/step - loss: 5.4089e-05 - val_loss: 8.1252e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1654/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3760e-05 - val_loss: 8.0965e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1655/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4155e-05 - val_loss: 8.0879e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1656/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - loss: 5.3981e-05 - val_loss: 8.1056e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1657/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4014e-05 - val_loss: 8.0939e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1658/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779us/step - loss: 5.4572e-05 - val_loss: 8.0959e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1659/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4178e-05 - val_loss: 8.1151e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1660/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834us/step - loss: 5.4039e-05 - val_loss: 8.0858e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1661/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4102e-05 - val_loss: 8.0943e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1662/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - loss: 5.3779e-05 - val_loss: 8.1031e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1663/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4393e-05 - val_loss: 8.1031e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1664/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - loss: 5.3944e-05 - val_loss: 8.0851e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1665/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3978e-05 - val_loss: 8.0852e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1666/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838us/step - loss: 5.4082e-05 - val_loss: 8.0991e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1667/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4316e-05 - val_loss: 8.0839e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1668/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 5.4179e-05 - val_loss: 8.0831e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1669/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3991e-05 - val_loss: 8.0970e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1670/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4402e-05 - val_loss: 8.0873e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1671/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - loss: 5.3848e-05 - val_loss: 8.0925e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1672/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4041e-05 - val_loss: 8.0770e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1673/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3850e-05 - val_loss: 8.0836e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1674/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851us/step - loss: 5.4550e-05 - val_loss: 8.0825e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1675/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3949e-05 - val_loss: 8.0717e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1676/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3301e-05 - val_loss: 8.1015e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1677/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868us/step - loss: 5.3613e-05 - val_loss: 8.0789e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1678/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4398e-05 - val_loss: 8.0936e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1679/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875us/step - loss: 5.4074e-05 - val_loss: 8.0882e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1680/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4411e-05 - val_loss: 8.0987e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1681/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 911us/step - loss: 5.4195e-05 - val_loss: 8.0900e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1682/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4251e-05 - val_loss: 8.0691e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1683/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3979e-05 - val_loss: 8.0810e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1684/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - loss: 5.4388e-05 - val_loss: 8.0885e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1685/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3838e-05 - val_loss: 8.1092e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1686/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3921e-05 - val_loss: 8.0683e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1687/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - loss: 5.4123e-05 - val_loss: 8.0920e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1688/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3870e-05 - val_loss: 8.0792e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1689/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 921us/step - loss: 5.4185e-05 - val_loss: 8.0871e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1690/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4074e-05 - val_loss: 8.0894e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1691/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step - loss: 5.3956e-05 - val_loss: 8.0832e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1692/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3946e-05 - val_loss: 8.0763e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1693/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4311e-05 - val_loss: 8.0918e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1694/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 869us/step - loss: 5.4338e-05 - val_loss: 8.0844e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1695/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3727e-05 - val_loss: 8.0982e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1696/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 866us/step - loss: 5.4061e-05 - val_loss: 8.0751e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1697/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4108e-05 - val_loss: 8.1060e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1698/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4232e-05 - val_loss: 8.0496e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1699/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - loss: 5.4317e-05 - val_loss: 8.0793e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1700/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4001e-05 - val_loss: 8.0796e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1701/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - loss: 5.4069e-05 - val_loss: 8.0662e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1702/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3904e-05 - val_loss: 8.1011e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1703/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3787e-05 - val_loss: 8.0690e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1704/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 874us/step - loss: 5.4016e-05 - val_loss: 8.0801e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1705/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 871us/step - loss: 5.4225e-05 - val_loss: 8.1190e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1706/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4020e-05 - val_loss: 8.0705e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1707/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3675e-05 - val_loss: 8.0744e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1708/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 860us/step - loss: 5.3808e-05 - val_loss: 8.0744e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1709/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4073e-05 - val_loss: 8.0889e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1710/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - loss: 5.4227e-05 - val_loss: 8.0720e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1711/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4224e-05 - val_loss: 8.0800e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1712/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - loss: 5.4012e-05 - val_loss: 8.0908e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1713/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4348e-05 - val_loss: 8.0863e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1714/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3726e-05 - val_loss: 8.0654e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1715/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - loss: 5.3915e-05 - val_loss: 8.0532e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1716/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3764e-05 - val_loss: 8.0704e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1717/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 823us/step - loss: 5.4180e-05 - val_loss: 8.1104e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1718/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3960e-05 - val_loss: 8.0648e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1719/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3730e-05 - val_loss: 8.0599e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1720/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834us/step - loss: 5.3653e-05 - val_loss: 8.0571e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1721/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4166e-05 - val_loss: 8.0814e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1722/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4280e-05 - val_loss: 8.0762e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1723/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step - loss: 5.3771e-05 - val_loss: 8.0815e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1724/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4109e-05 - val_loss: 8.0713e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1725/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - loss: 5.4248e-05 - val_loss: 8.0633e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1726/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4006e-05 - val_loss: 8.0827e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1727/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - loss: 5.3847e-05 - val_loss: 8.0667e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1728/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4201e-05 - val_loss: 8.0666e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1729/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - loss: 5.3821e-05 - val_loss: 8.0493e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1730/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793us/step - loss: 5.3608e-05 - val_loss: 8.0679e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1731/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 5.3611e-05 - val_loss: 8.0749e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1732/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3659e-05 - val_loss: 8.0518e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1733/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828us/step - loss: 5.3961e-05 - val_loss: 8.0587e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1734/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3695e-05 - val_loss: 8.0822e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1735/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4024e-05 - val_loss: 8.0685e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1736/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850us/step - loss: 5.3889e-05 - val_loss: 8.0529e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1737/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4089e-05 - val_loss: 8.0570e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1738/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838us/step - loss: 5.3972e-05 - val_loss: 8.0623e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1739/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4045e-05 - val_loss: 8.0698e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1740/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4123e-05 - val_loss: 8.0822e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1741/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - loss: 5.4362e-05 - val_loss: 8.0494e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1742/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3764e-05 - val_loss: 8.0621e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1743/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 5.4098e-05 - val_loss: 8.0617e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1744/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4012e-05 - val_loss: 8.0454e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1745/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3606e-05 - val_loss: 8.1077e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1746/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step - loss: 5.3463e-05 - val_loss: 8.0615e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1747/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3338e-05 - val_loss: 8.0461e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1748/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - loss: 5.3904e-05 - val_loss: 8.0520e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1749/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3670e-05 - val_loss: 8.0515e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1750/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4105e-05 - val_loss: 8.0896e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1751/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 863us/step - loss: 5.3944e-05 - val_loss: 8.0619e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1752/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3617e-05 - val_loss: 8.0720e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1753/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - loss: 5.3717e-05 - val_loss: 8.0690e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1754/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3591e-05 - val_loss: 8.0557e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1755/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833us/step - loss: 5.3889e-05 - val_loss: 8.0488e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1756/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3935e-05 - val_loss: 8.0814e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1757/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step - loss: 5.3367e-05 - val_loss: 8.0334e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1758/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3796e-05 - val_loss: 8.0749e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1759/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3675e-05 - val_loss: 8.0445e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1760/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step - loss: 5.4080e-05 - val_loss: 8.0689e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1761/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3750e-05 - val_loss: 8.0551e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1762/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3751e-05 - val_loss: 8.0407e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1763/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 865us/step - loss: 5.3513e-05 - val_loss: 8.0522e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1764/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3655e-05 - val_loss: 8.0417e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1765/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3643e-05 - val_loss: 8.0510e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1766/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3592e-05 - val_loss: 8.0374e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1767/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - loss: 5.3893e-05 - val_loss: 8.0343e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1768/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3700e-05 - val_loss: 8.0620e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1769/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - loss: 5.4039e-05 - val_loss: 8.0322e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1770/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3535e-05 - val_loss: 8.0670e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1771/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3940e-05 - val_loss: 8.0575e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1772/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 860us/step - loss: 5.3929e-05 - val_loss: 8.0493e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1773/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3643e-05 - val_loss: 8.0553e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1774/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3657e-05 - val_loss: 8.0440e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1775/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 860us/step - loss: 5.3709e-05 - val_loss: 8.0496e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1776/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3807e-05 - val_loss: 8.0374e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1777/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 857us/step - loss: 5.3989e-05 - val_loss: 8.0719e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1778/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3490e-05 - val_loss: 8.0337e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1779/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step - loss: 5.3500e-05 - val_loss: 8.0531e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1780/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3617e-05 - val_loss: 8.0461e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1781/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825us/step - loss: 5.3570e-05 - val_loss: 8.0429e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1782/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4010e-05 - val_loss: 8.0310e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1783/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3193e-05 - val_loss: 8.0399e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1784/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 895us/step - loss: 5.4037e-05 - val_loss: 8.0568e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1785/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3622e-05 - val_loss: 8.0675e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1786/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - loss: 5.4060e-05 - val_loss: 8.0631e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1787/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3764e-05 - val_loss: 8.0586e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1788/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3832e-05 - val_loss: 8.0267e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1789/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3516e-05 - val_loss: 8.0432e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1790/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4011e-05 - val_loss: 8.0370e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1791/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - loss: 5.3806e-05 - val_loss: 8.0559e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1792/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - loss: 5.3823e-05 - val_loss: 8.0427e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1793/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5.3566e-05 - val_loss: 8.0362e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1794/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3949e-05 - val_loss: 8.0450e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1795/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 871us/step - loss: 5.3443e-05 - val_loss: 8.0356e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1796/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3745e-05 - val_loss: 8.0432e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1797/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850us/step - loss: 5.3358e-05 - val_loss: 8.0507e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1798/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3572e-05 - val_loss: 8.0398e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1799/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3585e-05 - val_loss: 8.0259e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1800/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875us/step - loss: 5.3703e-05 - val_loss: 8.0695e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1801/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3128e-05 - val_loss: 8.0385e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1802/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 852us/step - loss: 5.3347e-05 - val_loss: 8.0500e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1803/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3961e-05 - val_loss: 8.0353e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1804/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3945e-05 - val_loss: 8.0341e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1805/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3259e-05 - val_loss: 8.0447e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1806/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 888us/step - loss: 5.3792e-05 - val_loss: 8.0237e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1807/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3385e-05 - val_loss: 8.0302e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1808/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - loss: 5.3570e-05 - val_loss: 8.0409e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1809/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3811e-05 - val_loss: 8.0365e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1810/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3629e-05 - val_loss: 8.0421e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1811/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850us/step - loss: 5.3491e-05 - val_loss: 8.0707e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1812/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3950e-05 - val_loss: 8.0324e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1813/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step - loss: 5.3807e-05 - val_loss: 8.0416e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1814/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3859e-05 - val_loss: 8.0053e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1815/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3622e-05 - val_loss: 8.0437e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1816/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3257e-05 - val_loss: 8.0303e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1817/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 869us/step - loss: 5.3608e-05 - val_loss: 8.0206e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1818/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3749e-05 - val_loss: 8.0298e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1819/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4056e-05 - val_loss: 8.0278e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1820/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - loss: 5.3679e-05 - val_loss: 8.0261e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1821/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4336e-05 - val_loss: 8.0207e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1822/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3716e-05 - val_loss: 8.0194e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1823/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 878us/step - loss: 5.3930e-05 - val_loss: 8.0237e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1824/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3618e-05 - val_loss: 8.0334e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1825/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step - loss: 5.3850e-05 - val_loss: 8.0272e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1826/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3534e-05 - val_loss: 8.0102e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1827/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 5.3375e-05 - val_loss: 8.0334e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1828/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 947us/step - loss: 5.3710e-05 - val_loss: 8.0472e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1829/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3552e-05 - val_loss: 8.0358e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1830/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - loss: 5.3281e-05 - val_loss: 8.0089e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1831/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3615e-05 - val_loss: 8.0311e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1832/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3221e-05 - val_loss: 8.0301e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1833/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - loss: 5.3024e-05 - val_loss: 8.0231e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1834/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3135e-05 - val_loss: 8.0279e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1835/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3336e-05 - val_loss: 8.0104e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1836/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - loss: 5.3664e-05 - val_loss: 8.0230e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1837/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 5.3882e-05 - val_loss: 8.0261e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1838/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3746e-05 - val_loss: 8.0280e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1839/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 888us/step - loss: 5.3225e-05 - val_loss: 8.0406e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1840/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4044e-05 - val_loss: 8.0052e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1841/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 5.3549e-05 - val_loss: 8.0395e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1842/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3739e-05 - val_loss: 8.0144e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1843/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3519e-05 - val_loss: 8.0286e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1844/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - loss: 5.3666e-05 - val_loss: 8.0245e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1845/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3942e-05 - val_loss: 8.0317e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1846/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3216e-05 - val_loss: 8.0410e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1847/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - loss: 5.3699e-05 - val_loss: 8.0151e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1848/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3538e-05 - val_loss: 8.0390e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1849/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3385e-05 - val_loss: 8.0203e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1850/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3817e-05 - val_loss: 8.0179e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1851/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - loss: 5.3628e-05 - val_loss: 8.0112e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1852/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - loss: 5.3596e-05 - val_loss: 8.0348e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1853/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3223e-05 - val_loss: 7.9978e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1854/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868us/step - loss: 5.3471e-05 - val_loss: 8.0171e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1855/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3221e-05 - val_loss: 8.0398e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1856/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3846e-05 - val_loss: 8.0387e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1857/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 871us/step - loss: 5.3772e-05 - val_loss: 8.0474e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1858/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3422e-05 - val_loss: 8.0219e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1859/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - loss: 5.3503e-05 - val_loss: 8.0296e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1860/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step - loss: 5.3315e-05 - val_loss: 8.0428e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1861/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4178e-05 - val_loss: 8.0265e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1862/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858us/step - loss: 5.3560e-05 - val_loss: 8.0118e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1863/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3217e-05 - val_loss: 8.0163e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1864/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3288e-05 - val_loss: 7.9977e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1865/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step - loss: 5.3845e-05 - val_loss: 7.9996e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1866/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3585e-05 - val_loss: 8.0363e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1867/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3210e-05 - val_loss: 8.0038e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1868/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 892us/step - loss: 5.3620e-05 - val_loss: 8.0090e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1869/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3916e-05 - val_loss: 8.0071e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1870/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3687e-05 - val_loss: 8.0114e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1871/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3050e-05 - val_loss: 8.0233e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1872/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3046e-05 - val_loss: 8.0149e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1873/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - loss: 5.3573e-05 - val_loss: 8.0102e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1874/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3659e-05 - val_loss: 7.9995e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1875/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3527e-05 - val_loss: 7.9863e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1876/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - loss: 5.3207e-05 - val_loss: 8.0050e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1877/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3920e-05 - val_loss: 8.0149e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1878/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3664e-05 - val_loss: 8.0131e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1879/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 880us/step - loss: 5.3740e-05 - val_loss: 7.9923e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1880/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3932e-05 - val_loss: 8.0159e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1881/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3275e-05 - val_loss: 7.9838e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1882/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3298e-05 - val_loss: 7.9924e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1883/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3374e-05 - val_loss: 7.9883e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1884/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - loss: 5.3697e-05 - val_loss: 7.9989e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1885/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3384e-05 - val_loss: 7.9991e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1886/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3990e-05 - val_loss: 8.1032e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1887/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 874us/step - loss: 5.3473e-05 - val_loss: 8.0125e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1888/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3510e-05 - val_loss: 8.0271e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1889/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3269e-05 - val_loss: 7.9933e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1890/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - loss: 5.3680e-05 - val_loss: 8.0281e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1891/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3161e-05 - val_loss: 7.9909e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1892/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3786e-05 - val_loss: 8.0004e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1893/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3492e-05 - val_loss: 7.9892e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1894/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3782e-05 - val_loss: 8.0090e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1895/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 924us/step - loss: 5.3503e-05 - val_loss: 8.0189e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1896/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3502e-05 - val_loss: 8.0002e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1897/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3381e-05 - val_loss: 8.0292e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1898/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3398e-05 - val_loss: 7.9911e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1899/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3068e-05 - val_loss: 7.9913e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1900/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3222e-05 - val_loss: 7.9938e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1901/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3553e-05 - val_loss: 8.0147e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1902/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - loss: 5.3666e-05 - val_loss: 8.0130e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1903/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3659e-05 - val_loss: 7.9886e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1904/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3391e-05 - val_loss: 7.9809e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1905/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3524e-05 - val_loss: 7.9778e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1906/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 870us/step - loss: 5.3342e-05 - val_loss: 8.0043e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1907/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3087e-05 - val_loss: 7.9862e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1908/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3589e-05 - val_loss: 7.9938e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1909/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3963e-05 - val_loss: 7.9782e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1910/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - loss: 5.3531e-05 - val_loss: 7.9974e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1911/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3332e-05 - val_loss: 7.9901e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1912/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 976us/step - loss: 5.3692e-05 - val_loss: 8.0018e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1913/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 895us/step - loss: 5.3071e-05 - val_loss: 7.9870e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1914/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.2862e-05 - val_loss: 7.9925e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1915/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3254e-05 - val_loss: 8.0005e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1916/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 981us/step - loss: 5.3963e-05 - val_loss: 7.9851e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1917/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3381e-05 - val_loss: 7.9976e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1918/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3444e-05 - val_loss: 7.9941e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1919/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3263e-05 - val_loss: 8.0216e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1920/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step - loss: 5.3197e-05 - val_loss: 7.9900e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1921/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3291e-05 - val_loss: 7.9946e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1922/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3601e-05 - val_loss: 7.9825e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1923/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step - loss: 5.3418e-05 - val_loss: 8.0092e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1924/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5.3375e-05 - val_loss: 7.9945e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1925/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3092e-05 - val_loss: 7.9944e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1926/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3206e-05 - val_loss: 7.9933e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1927/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3432e-05 - val_loss: 8.0107e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1928/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3474e-05 - val_loss: 7.9689e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1929/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - loss: 5.3468e-05 - val_loss: 7.9951e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1930/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3848e-05 - val_loss: 8.0077e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1931/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3213e-05 - val_loss: 7.9832e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1932/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 874us/step - loss: 5.3520e-05 - val_loss: 7.9882e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1933/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3204e-05 - val_loss: 7.9890e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1934/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3853e-05 - val_loss: 7.9985e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1935/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - loss: 5.3173e-05 - val_loss: 7.9770e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1936/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3522e-05 - val_loss: 7.9651e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1937/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3675e-05 - val_loss: 7.9714e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1938/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3435e-05 - val_loss: 7.9915e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1939/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - loss: 5.3449e-05 - val_loss: 7.9903e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1940/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3550e-05 - val_loss: 7.9724e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1941/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3447e-05 - val_loss: 7.9656e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1942/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3385e-05 - val_loss: 7.9848e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1943/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step - loss: 5.3495e-05 - val_loss: 8.0000e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1944/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3134e-05 - val_loss: 7.9567e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1945/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3165e-05 - val_loss: 7.9849e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1946/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898us/step - loss: 5.3018e-05 - val_loss: 7.9650e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1947/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3530e-05 - val_loss: 7.9592e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1948/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.2963e-05 - val_loss: 7.9711e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1949/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - loss: 5.3151e-05 - val_loss: 7.9873e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1950/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 950us/step - loss: 5.2682e-05 - val_loss: 7.9808e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1951/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3206e-05 - val_loss: 7.9773e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1952/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.2947e-05 - val_loss: 7.9736e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1953/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3916e-05 - val_loss: 7.9826e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1954/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3623e-05 - val_loss: 7.9578e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1955/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3558e-05 - val_loss: 7.9938e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1956/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - loss: 5.3419e-05 - val_loss: 7.9544e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1957/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3026e-05 - val_loss: 7.9759e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1958/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3591e-05 - val_loss: 7.9610e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1959/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - loss: 5.3030e-05 - val_loss: 7.9803e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1960/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3263e-05 - val_loss: 7.9697e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1961/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3667e-05 - val_loss: 7.9822e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1962/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - loss: 5.2862e-05 - val_loss: 7.9814e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1963/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3024e-05 - val_loss: 7.9719e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1964/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3121e-05 - val_loss: 7.9687e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1965/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 893us/step - loss: 5.3065e-05 - val_loss: 7.9573e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1966/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 994us/step - loss: 5.3158e-05 - val_loss: 7.9804e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1967/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.2545e-05 - val_loss: 8.0057e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1968/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3138e-05 - val_loss: 7.9641e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1969/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3363e-05 - val_loss: 7.9818e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1970/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 892us/step - loss: 5.3267e-05 - val_loss: 7.9625e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1971/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3062e-05 - val_loss: 7.9811e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1972/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 865us/step - loss: 5.3855e-05 - val_loss: 7.9956e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1973/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3196e-05 - val_loss: 7.9794e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1974/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3170e-05 - val_loss: 7.9519e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1975/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3341e-05 - val_loss: 7.9574e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1976/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 890us/step - loss: 5.3390e-05 - val_loss: 7.9654e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1977/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.2842e-05 - val_loss: 8.0117e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1978/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3022e-05 - val_loss: 7.9686e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1979/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3300e-05 - val_loss: 7.9603e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1980/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.2946e-05 - val_loss: 7.9629e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1981/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3008e-05 - val_loss: 7.9526e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1982/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3081e-05 - val_loss: 7.9573e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1983/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3231e-05 - val_loss: 7.9695e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1984/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 874us/step - loss: 5.3398e-05 - val_loss: 7.9719e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1985/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3701e-05 - val_loss: 7.9569e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1986/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.2782e-05 - val_loss: 7.9448e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1987/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 949us/step - loss: 5.3022e-05 - val_loss: 7.9747e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1988/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3533e-05 - val_loss: 7.9713e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1989/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3121e-05 - val_loss: 7.9691e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1990/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3153e-05 - val_loss: 7.9564e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1991/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 888us/step - loss: 5.2962e-05 - val_loss: 7.9629e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1992/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 911us/step - loss: 5.3160e-05 - val_loss: 7.9537e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1993/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.2827e-05 - val_loss: 7.9538e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1994/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3139e-05 - val_loss: 7.9671e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1995/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3189e-05 - val_loss: 7.9444e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1996/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3469e-05 - val_loss: 7.9588e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1997/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 884us/step - loss: 5.3203e-05 - val_loss: 7.9493e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1998/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898us/step - loss: 5.3073e-05 - val_loss: 7.9612e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 1999/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3040e-05 - val_loss: 7.9571e-05 - learning_rate: 1.0000e-05\n",
            "Epoch 2000/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - loss: 5.3036e-05 - val_loss: 7.9608e-05 - learning_rate: 1.0000e-05\n"
          ]
        }
      ],
      "source": [
        "Training = True\n",
        "\n",
        "\n",
        "# Define the learning rate scheduler function\n",
        "def scheduler(epoch, lr):\n",
        "    if epoch < 10:\n",
        "        return lr\n",
        "    else:\n",
        "        return max(lr * 0.99, 1e-5)\n",
        "\n",
        "# Initialize the neural network model\n",
        "model_lf = Sequential()\n",
        "\n",
        "\n",
        "l2_reg = 1e-7\n",
        "# Add layers to the model\n",
        "\n",
        "model_lf.add(Dense(128, input_shape=(n_c,), activation='gelu'))#, kernel_regularizer=l2(l2_reg)))\n",
        "model_lf.add(Dense(64, activation='gelu'))\n",
        "model_lf.add(Dense(64, activation='gelu'))\n",
        "model_lf.add(Dense(25, activation='exponential'))#, kernel_regularizer=l2(l2_reg)))\n",
        "\n",
        "\n",
        "if Training:\n",
        "    # Compile the model\n",
        "    initial_learning_rate = 0.001\n",
        "    optimizer = Adam(learning_rate=initial_learning_rate)\n",
        "    model_lf.compile(optimizer=optimizer, loss='mean_squared_error')\n",
        "\n",
        "    # Define the learning rate scheduler callback\n",
        "    lr_scheduler = LearningRateScheduler(scheduler)\n",
        "\n",
        "    # Train the model\n",
        "    history_lf = model_lf.fit(X_train, y_train, \n",
        "                    epochs=2000, \n",
        "                    batch_size=64, \n",
        "                    validation_data=(X_test, y_test),\n",
        "                    callbacks=[lr_scheduler])\n",
        "    \n",
        "    model_lf.save('./models4/model_LF_16000_2.keras')\n",
        "\n",
        "model_lf = load_model('./models4/model_LF_16000_2.keras')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353us/step - loss: 8.0393e-05\n",
            "Test accuracy: 7.96080130385235e-05\n",
            "Test rmse: 0.00892233226452162\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Evaluate the model on the test set\n",
        "test_loss = model_lf.evaluate(x=X_test, y=y_test)\n",
        "\n",
        "# Print the test accuracy\n",
        "print(f\"Test accuracy: {test_loss}\")\n",
        "print(f\"Test rmse: {np.sqrt(test_loss)}\")\n",
        "\n",
        "if Training:\n",
        "    plt.plot(history_lf.history['loss'], label='Loss')\n",
        "    plt.plot(history_lf.history['val_loss'], label='Val loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Learning Rate')\n",
        "    plt.title('Learning Rate over Epochs')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se how it is able to prodict "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x1200 with 18 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Define the sampling points.\n",
        "x_data = y_data = np.array([0.1, 0.3, 0.5, 0.7, 0.9])\n",
        "# Grid to plot the basis \n",
        "X,Y = np.meshgrid(x_data, y_data)\n",
        "\n",
        "samples = [ 1, 10, 100]\n",
        "#Plot POD coefficients: LF vs HF\n",
        "fig = plt.figure(figsize=(12,12))\n",
        "plt.subplots_adjust(hspace=0.5)\n",
        "title = 'True vs Reconstucted signals with NN'\n",
        "fig.suptitle(title, fontsize=14)\n",
        "\n",
        "for mode in range(3):\n",
        "    ax = fig.add_subplot(331 + mode)\n",
        "    pcm = plt.pcolormesh(X, Y, y_test[mode, :].reshape((5, 5)))\n",
        "    ax.title.set_text('True signal sample: ' + str(samples[mode]))\n",
        "    plt.colorbar(pcm, ax=ax)\n",
        "    \n",
        "    ax = fig.add_subplot(331 + mode + 3)\n",
        "    reconstructed_sample = np.array(model_lf(X_test[mode, :].reshape((1, n_c)))).reshape((5, 5))\n",
        "    err = y_test[mode, :].reshape(5, 5) - reconstructed_sample\n",
        "    pcm = plt.pcolormesh(X, Y, reconstructed_sample.reshape((5, 5)))\n",
        "    ax.title.set_text('NN prediction sample: ' + str(samples[mode]))\n",
        "    plt.colorbar(pcm, ax=ax)\n",
        "    \n",
        "    ax = fig.add_subplot(331 + mode + 6)\n",
        "    pcm = plt.pcolormesh(X, Y, err)\n",
        "    ax.title.set_text('Reconst. error sample: ' + str(samples[mode]))\n",
        "    plt.colorbar(pcm, ax=ax)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3 ) Generation of multi-fidelity datset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From now on we will only consider the best low fidelity model = Low fidelity 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "Training = True\n",
        "if Training:\n",
        "    coarse_sol = np.zeros((N, 25))\n",
        "    for i in range(N):\n",
        "        coarse_sol[i,:] = model_lf(X_train[i,:].reshape((1,64)))\n",
        "    \n",
        "    coarse_sol_test = np.zeros((n_t,25))\n",
        "    for i in range(n_t):\n",
        "        coarse_sol_test[i,:] = model_lf(X_test[i,:].reshape((1,64)))\n",
        "    np.savetxt('./data/coarse_sol_training4.csv', coarse_sol, delimiter=',' )\n",
        "    np.savetxt('./data/coarse_sol_test4.csv', coarse_sol_test, delimiter=',' )\n",
        "\n",
        "else: \n",
        "    coarse_sol = np.loadtxt('./data/coarse_sol_training4.csv', delimiter=',')\n",
        "    coarse_sol_test = np.loadtxt('./data/coarse_sol_test4.csv', delimiter=',')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train2 = np.hstack((X_train, coarse_sol))\n",
        "X_test2 = np.hstack((X_test, coarse_sol_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4 ) Training Fine-level NN surrogate "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "89"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n_f = X_train2.shape[1]\n",
        "n_f"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0617 - val_loss: 0.0029 - learning_rate: 0.0010\n",
            "Epoch 2/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0022 - val_loss: 0.0015 - learning_rate: 0.0010\n",
            "Epoch 3/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0012 - val_loss: 0.0010 - learning_rate: 0.0010\n",
            "Epoch 4/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.6581e-04 - val_loss: 7.7822e-04 - learning_rate: 0.0010\n",
            "Epoch 5/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.6309e-04 - val_loss: 6.2914e-04 - learning_rate: 0.0010\n",
            "Epoch 6/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4628e-04 - val_loss: 5.2702e-04 - learning_rate: 0.0010\n",
            "Epoch 7/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.5151e-04 - val_loss: 4.6219e-04 - learning_rate: 0.0010\n",
            "Epoch 8/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.9131e-04 - val_loss: 4.0613e-04 - learning_rate: 0.0010\n",
            "Epoch 9/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.4619e-04 - val_loss: 3.6300e-04 - learning_rate: 0.0010\n",
            "Epoch 10/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.0444e-04 - val_loss: 3.3082e-04 - learning_rate: 0.0010\n",
            "Epoch 11/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.7473e-04 - val_loss: 2.9240e-04 - learning_rate: 0.0010\n",
            "Epoch 12/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.4923e-04 - val_loss: 2.6662e-04 - learning_rate: 0.0010\n",
            "Epoch 13/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.2657e-04 - val_loss: 2.5273e-04 - learning_rate: 0.0010\n",
            "Epoch 14/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.1295e-04 - val_loss: 2.5257e-04 - learning_rate: 0.0010\n",
            "Epoch 15/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.9621e-04 - val_loss: 2.2472e-04 - learning_rate: 0.0010\n",
            "Epoch 16/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.9091e-04 - val_loss: 2.1796e-04 - learning_rate: 0.0010\n",
            "Epoch 17/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7638e-04 - val_loss: 2.0347e-04 - learning_rate: 0.0010\n",
            "Epoch 18/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6417e-04 - val_loss: 1.8687e-04 - learning_rate: 0.0010\n",
            "Epoch 19/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5833e-04 - val_loss: 2.0686e-04 - learning_rate: 0.0010\n",
            "Epoch 20/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4478e-04 - val_loss: 1.9625e-04 - learning_rate: 0.0010\n",
            "Epoch 21/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4115e-04 - val_loss: 1.6710e-04 - learning_rate: 9.9000e-04\n",
            "Epoch 22/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4165e-04 - val_loss: 1.7029e-04 - learning_rate: 9.8010e-04\n",
            "Epoch 23/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.2607e-04 - val_loss: 1.6322e-04 - learning_rate: 9.7030e-04\n",
            "Epoch 24/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.2592e-04 - val_loss: 1.6061e-04 - learning_rate: 9.6060e-04\n",
            "Epoch 25/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.3475e-04 - val_loss: 1.5528e-04 - learning_rate: 9.5099e-04\n",
            "Epoch 26/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.1326e-04 - val_loss: 1.8569e-04 - learning_rate: 9.4148e-04\n",
            "Epoch 27/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.1289e-04 - val_loss: 1.4043e-04 - learning_rate: 9.3207e-04\n",
            "Epoch 28/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.2172e-04 - val_loss: 1.4260e-04 - learning_rate: 9.2274e-04\n",
            "Epoch 29/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0932e-04 - val_loss: 1.4451e-04 - learning_rate: 9.1352e-04\n",
            "Epoch 30/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0526e-04 - val_loss: 1.3648e-04 - learning_rate: 9.0438e-04\n",
            "Epoch 31/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.8433e-05 - val_loss: 1.3587e-04 - learning_rate: 8.9534e-04\n",
            "Epoch 32/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0014e-04 - val_loss: 1.2576e-04 - learning_rate: 8.8638e-04\n",
            "Epoch 33/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0368e-04 - val_loss: 1.2766e-04 - learning_rate: 8.7752e-04\n",
            "Epoch 34/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.7670e-05 - val_loss: 1.2148e-04 - learning_rate: 8.6875e-04\n",
            "Epoch 35/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.8042e-05 - val_loss: 1.1923e-04 - learning_rate: 8.6006e-04\n",
            "Epoch 36/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.8977e-05 - val_loss: 1.1188e-04 - learning_rate: 8.5146e-04\n",
            "Epoch 37/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.6199e-05 - val_loss: 1.1255e-04 - learning_rate: 8.4294e-04\n",
            "Epoch 38/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.6928e-05 - val_loss: 1.1569e-04 - learning_rate: 8.3451e-04\n",
            "Epoch 39/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.3681e-05 - val_loss: 1.0792e-04 - learning_rate: 8.2617e-04\n",
            "Epoch 40/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.1893e-05 - val_loss: 1.2253e-04 - learning_rate: 8.1791e-04\n",
            "Epoch 41/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.9120e-05 - val_loss: 1.0767e-04 - learning_rate: 8.0973e-04\n",
            "Epoch 42/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.8035e-05 - val_loss: 1.0325e-04 - learning_rate: 8.0163e-04\n",
            "Epoch 43/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.5198e-05 - val_loss: 1.1211e-04 - learning_rate: 7.9361e-04\n",
            "Epoch 44/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.6931e-05 - val_loss: 9.8534e-05 - learning_rate: 7.8568e-04\n",
            "Epoch 45/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.5734e-05 - val_loss: 9.9958e-05 - learning_rate: 7.7782e-04\n",
            "Epoch 46/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.1854e-05 - val_loss: 9.7822e-05 - learning_rate: 7.7004e-04\n",
            "Epoch 47/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.3632e-05 - val_loss: 9.8244e-05 - learning_rate: 7.6234e-04\n",
            "Epoch 48/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.0750e-05 - val_loss: 9.8544e-05 - learning_rate: 7.5472e-04\n",
            "Epoch 49/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.8008e-05 - val_loss: 9.0698e-05 - learning_rate: 7.4717e-04\n",
            "Epoch 50/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.6199e-05 - val_loss: 9.5265e-05 - learning_rate: 7.3970e-04\n",
            "Epoch 51/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.8604e-05 - val_loss: 9.1005e-05 - learning_rate: 7.3230e-04\n",
            "Epoch 52/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.5288e-05 - val_loss: 1.0038e-04 - learning_rate: 7.2498e-04\n",
            "Epoch 53/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.4353e-05 - val_loss: 9.2491e-05 - learning_rate: 7.1773e-04\n",
            "Epoch 54/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.4494e-05 - val_loss: 9.2428e-05 - learning_rate: 7.1055e-04\n",
            "Epoch 55/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.0907e-05 - val_loss: 8.6742e-05 - learning_rate: 7.0345e-04\n",
            "Epoch 56/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.3366e-05 - val_loss: 8.6281e-05 - learning_rate: 6.9641e-04\n",
            "Epoch 57/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.1937e-05 - val_loss: 9.2096e-05 - learning_rate: 6.8945e-04\n",
            "Epoch 58/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.0245e-05 - val_loss: 8.7577e-05 - learning_rate: 6.8255e-04\n",
            "Epoch 59/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.0364e-05 - val_loss: 8.2270e-05 - learning_rate: 6.7573e-04\n",
            "Epoch 60/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.7572e-05 - val_loss: 8.3877e-05 - learning_rate: 6.6897e-04\n",
            "Epoch 61/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.7271e-05 - val_loss: 8.6359e-05 - learning_rate: 6.6228e-04\n",
            "Epoch 62/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.0154e-05 - val_loss: 7.8791e-05 - learning_rate: 6.5566e-04\n",
            "Epoch 63/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.6609e-05 - val_loss: 8.1225e-05 - learning_rate: 6.4910e-04\n",
            "Epoch 64/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3983e-05 - val_loss: 8.5999e-05 - learning_rate: 6.4261e-04\n",
            "Epoch 65/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5179e-05 - val_loss: 8.1773e-05 - learning_rate: 6.3619e-04\n",
            "Epoch 66/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4471e-05 - val_loss: 7.7089e-05 - learning_rate: 6.2982e-04\n",
            "Epoch 67/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3530e-05 - val_loss: 7.8271e-05 - learning_rate: 6.2353e-04\n",
            "Epoch 68/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4620e-05 - val_loss: 7.4170e-05 - learning_rate: 6.1729e-04\n",
            "Epoch 69/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3208e-05 - val_loss: 7.6974e-05 - learning_rate: 6.1112e-04\n",
            "Epoch 70/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.2613e-05 - val_loss: 7.6767e-05 - learning_rate: 6.0501e-04\n",
            "Epoch 71/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.1679e-05 - val_loss: 7.9519e-05 - learning_rate: 5.9896e-04\n",
            "Epoch 72/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.1089e-05 - val_loss: 7.2702e-05 - learning_rate: 5.9297e-04\n",
            "Epoch 73/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.0201e-05 - val_loss: 7.7013e-05 - learning_rate: 5.8704e-04\n",
            "Epoch 74/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.0001e-05 - val_loss: 7.5709e-05 - learning_rate: 5.8117e-04\n",
            "Epoch 75/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.8598e-05 - val_loss: 7.2696e-05 - learning_rate: 5.7535e-04\n",
            "Epoch 76/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.6887e-05 - val_loss: 7.4585e-05 - learning_rate: 5.6960e-04\n",
            "Epoch 77/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.8437e-05 - val_loss: 7.2165e-05 - learning_rate: 5.6391e-04\n",
            "Epoch 78/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.6034e-05 - val_loss: 7.0494e-05 - learning_rate: 5.5827e-04\n",
            "Epoch 79/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.6310e-05 - val_loss: 7.5082e-05 - learning_rate: 5.5268e-04\n",
            "Epoch 80/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.5728e-05 - val_loss: 7.0987e-05 - learning_rate: 5.4716e-04\n",
            "Epoch 81/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.7441e-05 - val_loss: 7.3675e-05 - learning_rate: 5.4169e-04\n",
            "Epoch 82/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.6440e-05 - val_loss: 6.8872e-05 - learning_rate: 5.3627e-04\n",
            "Epoch 83/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.7620e-05 - val_loss: 7.5702e-05 - learning_rate: 5.3091e-04\n",
            "Epoch 84/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.5602e-05 - val_loss: 6.9395e-05 - learning_rate: 5.2560e-04\n",
            "Epoch 85/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.4778e-05 - val_loss: 6.7407e-05 - learning_rate: 5.2034e-04\n",
            "Epoch 86/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.2715e-05 - val_loss: 7.2821e-05 - learning_rate: 5.1514e-04\n",
            "Epoch 87/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.4429e-05 - val_loss: 7.2828e-05 - learning_rate: 5.0999e-04\n",
            "Epoch 88/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.2590e-05 - val_loss: 6.5722e-05 - learning_rate: 5.0489e-04\n",
            "Epoch 89/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.1915e-05 - val_loss: 6.6247e-05 - learning_rate: 4.9984e-04\n",
            "Epoch 90/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.3126e-05 - val_loss: 7.0206e-05 - learning_rate: 4.9484e-04\n",
            "Epoch 91/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.2399e-05 - val_loss: 6.3383e-05 - learning_rate: 4.8989e-04\n",
            "Epoch 92/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.1751e-05 - val_loss: 6.6532e-05 - learning_rate: 4.8499e-04\n",
            "Epoch 93/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.0991e-05 - val_loss: 6.6954e-05 - learning_rate: 4.8014e-04\n",
            "Epoch 94/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.0768e-05 - val_loss: 6.5433e-05 - learning_rate: 4.7534e-04\n",
            "Epoch 95/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.0538e-05 - val_loss: 6.4058e-05 - learning_rate: 4.7059e-04\n",
            "Epoch 96/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.9211e-05 - val_loss: 6.8770e-05 - learning_rate: 4.6588e-04\n",
            "Epoch 97/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.0827e-05 - val_loss: 6.1351e-05 - learning_rate: 4.6122e-04\n",
            "Epoch 98/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.8291e-05 - val_loss: 6.3887e-05 - learning_rate: 4.5661e-04\n",
            "Epoch 99/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.9224e-05 - val_loss: 6.6310e-05 - learning_rate: 4.5204e-04\n",
            "Epoch 100/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.9207e-05 - val_loss: 6.5052e-05 - learning_rate: 4.4752e-04\n",
            "Epoch 101/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.7434e-05 - val_loss: 6.3457e-05 - learning_rate: 4.4305e-04\n",
            "Epoch 102/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.8862e-05 - val_loss: 6.4254e-05 - learning_rate: 4.3862e-04\n",
            "Epoch 103/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.9291e-05 - val_loss: 7.4201e-05 - learning_rate: 4.3423e-04\n",
            "Epoch 104/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.9790e-05 - val_loss: 6.0530e-05 - learning_rate: 4.2989e-04\n",
            "Epoch 105/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.6965e-05 - val_loss: 6.1137e-05 - learning_rate: 4.2559e-04\n",
            "Epoch 106/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.6602e-05 - val_loss: 6.3365e-05 - learning_rate: 4.2133e-04\n",
            "Epoch 107/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.7691e-05 - val_loss: 5.9699e-05 - learning_rate: 4.1712e-04\n",
            "Epoch 108/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.6476e-05 - val_loss: 5.9163e-05 - learning_rate: 4.1295e-04\n",
            "Epoch 109/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.5604e-05 - val_loss: 6.0039e-05 - learning_rate: 4.0882e-04\n",
            "Epoch 110/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.5486e-05 - val_loss: 6.1558e-05 - learning_rate: 4.0473e-04\n",
            "Epoch 111/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.5903e-05 - val_loss: 5.7884e-05 - learning_rate: 4.0068e-04\n",
            "Epoch 112/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.5549e-05 - val_loss: 6.4725e-05 - learning_rate: 3.9668e-04\n",
            "Epoch 113/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.5244e-05 - val_loss: 5.7611e-05 - learning_rate: 3.9271e-04\n",
            "Epoch 114/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.4520e-05 - val_loss: 6.5743e-05 - learning_rate: 3.8878e-04\n",
            "Epoch 115/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.5276e-05 - val_loss: 5.8718e-05 - learning_rate: 3.8490e-04\n",
            "Epoch 116/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.4574e-05 - val_loss: 5.7228e-05 - learning_rate: 3.8105e-04\n",
            "Epoch 117/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.4311e-05 - val_loss: 5.8070e-05 - learning_rate: 3.7724e-04\n",
            "Epoch 118/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.4118e-05 - val_loss: 5.8997e-05 - learning_rate: 3.7346e-04\n",
            "Epoch 119/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.4168e-05 - val_loss: 5.8794e-05 - learning_rate: 3.6973e-04\n",
            "Epoch 120/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.3202e-05 - val_loss: 5.8785e-05 - learning_rate: 3.6603e-04\n",
            "Epoch 121/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.3420e-05 - val_loss: 5.7056e-05 - learning_rate: 3.6237e-04\n",
            "Epoch 122/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.3850e-05 - val_loss: 5.7745e-05 - learning_rate: 3.5875e-04\n",
            "Epoch 123/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.4350e-05 - val_loss: 5.9063e-05 - learning_rate: 3.5516e-04\n",
            "Epoch 124/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.3118e-05 - val_loss: 5.5727e-05 - learning_rate: 3.5161e-04\n",
            "Epoch 125/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.3198e-05 - val_loss: 5.6355e-05 - learning_rate: 3.4809e-04\n",
            "Epoch 126/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.1930e-05 - val_loss: 5.4355e-05 - learning_rate: 3.4461e-04\n",
            "Epoch 127/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.2395e-05 - val_loss: 5.4044e-05 - learning_rate: 3.4117e-04\n",
            "Epoch 128/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.2250e-05 - val_loss: 5.6850e-05 - learning_rate: 3.3775e-04\n",
            "Epoch 129/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.2008e-05 - val_loss: 5.6772e-05 - learning_rate: 3.3438e-04\n",
            "Epoch 130/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.1175e-05 - val_loss: 5.5313e-05 - learning_rate: 3.3103e-04\n",
            "Epoch 131/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.2070e-05 - val_loss: 5.7681e-05 - learning_rate: 3.2772e-04\n",
            "Epoch 132/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.1553e-05 - val_loss: 5.5942e-05 - learning_rate: 3.2445e-04\n",
            "Epoch 133/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.1426e-05 - val_loss: 5.4888e-05 - learning_rate: 3.2120e-04\n",
            "Epoch 134/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.0743e-05 - val_loss: 5.4284e-05 - learning_rate: 3.1799e-04\n",
            "Epoch 135/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.0723e-05 - val_loss: 5.4633e-05 - learning_rate: 3.1481e-04\n",
            "Epoch 136/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.1021e-05 - val_loss: 5.4685e-05 - learning_rate: 3.1166e-04\n",
            "Epoch 137/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.0318e-05 - val_loss: 5.4618e-05 - learning_rate: 3.0854e-04\n",
            "Epoch 138/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.0144e-05 - val_loss: 5.2809e-05 - learning_rate: 3.0546e-04\n",
            "Epoch 139/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.0240e-05 - val_loss: 5.2773e-05 - learning_rate: 3.0240e-04\n",
            "Epoch 140/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.9609e-05 - val_loss: 5.4204e-05 - learning_rate: 2.9938e-04\n",
            "Epoch 141/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.9934e-05 - val_loss: 5.3558e-05 - learning_rate: 2.9639e-04\n",
            "Epoch 142/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.9508e-05 - val_loss: 5.4886e-05 - learning_rate: 2.9342e-04\n",
            "Epoch 143/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.9675e-05 - val_loss: 5.4302e-05 - learning_rate: 2.9049e-04\n",
            "Epoch 144/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.9372e-05 - val_loss: 5.2257e-05 - learning_rate: 2.8758e-04\n",
            "Epoch 145/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.8615e-05 - val_loss: 5.2995e-05 - learning_rate: 2.8471e-04\n",
            "Epoch 146/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.9483e-05 - val_loss: 5.2989e-05 - learning_rate: 2.8186e-04\n",
            "Epoch 147/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.8594e-05 - val_loss: 5.2064e-05 - learning_rate: 2.7904e-04\n",
            "Epoch 148/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.8800e-05 - val_loss: 5.1651e-05 - learning_rate: 2.7625e-04\n",
            "Epoch 149/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.8696e-05 - val_loss: 5.4371e-05 - learning_rate: 2.7349e-04\n",
            "Epoch 150/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.8227e-05 - val_loss: 5.1946e-05 - learning_rate: 2.7075e-04\n",
            "Epoch 151/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.7871e-05 - val_loss: 5.1456e-05 - learning_rate: 2.6805e-04\n",
            "Epoch 152/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.8322e-05 - val_loss: 5.1388e-05 - learning_rate: 2.6537e-04\n",
            "Epoch 153/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.7393e-05 - val_loss: 5.0522e-05 - learning_rate: 2.6271e-04\n",
            "Epoch 154/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.7758e-05 - val_loss: 5.0661e-05 - learning_rate: 2.6009e-04\n",
            "Epoch 155/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.7472e-05 - val_loss: 5.2018e-05 - learning_rate: 2.5748e-04\n",
            "Epoch 156/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.7638e-05 - val_loss: 5.4938e-05 - learning_rate: 2.5491e-04\n",
            "Epoch 157/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.7927e-05 - val_loss: 5.0289e-05 - learning_rate: 2.5236e-04\n",
            "Epoch 158/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.7521e-05 - val_loss: 5.4011e-05 - learning_rate: 2.4984e-04\n",
            "Epoch 159/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.7580e-05 - val_loss: 4.9861e-05 - learning_rate: 2.4734e-04\n",
            "Epoch 160/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6971e-05 - val_loss: 5.4415e-05 - learning_rate: 2.4487e-04\n",
            "Epoch 161/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.7232e-05 - val_loss: 4.9460e-05 - learning_rate: 2.4242e-04\n",
            "Epoch 162/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6713e-05 - val_loss: 4.9991e-05 - learning_rate: 2.3999e-04\n",
            "Epoch 163/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6593e-05 - val_loss: 4.9021e-05 - learning_rate: 2.3759e-04\n",
            "Epoch 164/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6683e-05 - val_loss: 4.9101e-05 - learning_rate: 2.3522e-04\n",
            "Epoch 165/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6236e-05 - val_loss: 5.1634e-05 - learning_rate: 2.3286e-04\n",
            "Epoch 166/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6113e-05 - val_loss: 4.8647e-05 - learning_rate: 2.3054e-04\n",
            "Epoch 167/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.5861e-05 - val_loss: 5.0059e-05 - learning_rate: 2.2823e-04\n",
            "Epoch 168/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.5752e-05 - val_loss: 4.9115e-05 - learning_rate: 2.2595e-04\n",
            "Epoch 169/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.5674e-05 - val_loss: 4.8859e-05 - learning_rate: 2.2369e-04\n",
            "Epoch 170/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.5944e-05 - val_loss: 5.2674e-05 - learning_rate: 2.2145e-04\n",
            "Epoch 171/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.5722e-05 - val_loss: 4.8716e-05 - learning_rate: 2.1924e-04\n",
            "Epoch 172/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.5464e-05 - val_loss: 4.8733e-05 - learning_rate: 2.1705e-04\n",
            "Epoch 173/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.5248e-05 - val_loss: 4.8599e-05 - learning_rate: 2.1487e-04\n",
            "Epoch 174/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.5479e-05 - val_loss: 4.9227e-05 - learning_rate: 2.1273e-04\n",
            "Epoch 175/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.5612e-05 - val_loss: 4.8700e-05 - learning_rate: 2.1060e-04\n",
            "Epoch 176/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.5153e-05 - val_loss: 4.9002e-05 - learning_rate: 2.0849e-04\n",
            "Epoch 177/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.5424e-05 - val_loss: 4.8722e-05 - learning_rate: 2.0641e-04\n",
            "Epoch 178/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.5181e-05 - val_loss: 4.7872e-05 - learning_rate: 2.0434e-04\n",
            "Epoch 179/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.5028e-05 - val_loss: 4.8042e-05 - learning_rate: 2.0230e-04\n",
            "Epoch 180/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.4865e-05 - val_loss: 4.7643e-05 - learning_rate: 2.0028e-04\n",
            "Epoch 181/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.4911e-05 - val_loss: 4.7972e-05 - learning_rate: 1.9827e-04\n",
            "Epoch 182/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.4965e-05 - val_loss: 4.7721e-05 - learning_rate: 1.9629e-04\n",
            "Epoch 183/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.4693e-05 - val_loss: 4.8953e-05 - learning_rate: 1.9433e-04\n",
            "Epoch 184/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.4412e-05 - val_loss: 5.1471e-05 - learning_rate: 1.9239e-04\n",
            "Epoch 185/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.5117e-05 - val_loss: 4.8260e-05 - learning_rate: 1.9046e-04\n",
            "Epoch 186/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.4644e-05 - val_loss: 4.7759e-05 - learning_rate: 1.8856e-04\n",
            "Epoch 187/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.4138e-05 - val_loss: 4.7973e-05 - learning_rate: 1.8667e-04\n",
            "Epoch 188/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.4293e-05 - val_loss: 4.6426e-05 - learning_rate: 1.8480e-04\n",
            "Epoch 189/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.4228e-05 - val_loss: 4.7558e-05 - learning_rate: 1.8296e-04\n",
            "Epoch 190/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.3818e-05 - val_loss: 4.8289e-05 - learning_rate: 1.8113e-04\n",
            "Epoch 191/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.4016e-05 - val_loss: 4.7802e-05 - learning_rate: 1.7932e-04\n",
            "Epoch 192/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.3749e-05 - val_loss: 4.6211e-05 - learning_rate: 1.7752e-04\n",
            "Epoch 193/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.3775e-05 - val_loss: 4.5583e-05 - learning_rate: 1.7575e-04\n",
            "Epoch 194/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.3414e-05 - val_loss: 4.8504e-05 - learning_rate: 1.7399e-04\n",
            "Epoch 195/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.3847e-05 - val_loss: 4.6784e-05 - learning_rate: 1.7225e-04\n",
            "Epoch 196/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.3167e-05 - val_loss: 4.7248e-05 - learning_rate: 1.7053e-04\n",
            "Epoch 197/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.3558e-05 - val_loss: 4.6572e-05 - learning_rate: 1.6882e-04\n",
            "Epoch 198/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.3531e-05 - val_loss: 4.6541e-05 - learning_rate: 1.6713e-04\n",
            "Epoch 199/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.3461e-05 - val_loss: 4.9030e-05 - learning_rate: 1.6546e-04\n",
            "Epoch 200/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.3116e-05 - val_loss: 4.6605e-05 - learning_rate: 1.6381e-04\n",
            "Epoch 201/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.3176e-05 - val_loss: 4.6230e-05 - learning_rate: 1.6217e-04\n",
            "Epoch 202/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.2830e-05 - val_loss: 4.5852e-05 - learning_rate: 1.6055e-04\n",
            "Epoch 203/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.3079e-05 - val_loss: 4.5142e-05 - learning_rate: 1.5894e-04\n",
            "Epoch 204/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.2930e-05 - val_loss: 4.6085e-05 - learning_rate: 1.5735e-04\n",
            "Epoch 205/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.2955e-05 - val_loss: 4.5507e-05 - learning_rate: 1.5578e-04\n",
            "Epoch 206/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.2924e-05 - val_loss: 4.5877e-05 - learning_rate: 1.5422e-04\n",
            "Epoch 207/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.2588e-05 - val_loss: 4.6541e-05 - learning_rate: 1.5268e-04\n",
            "Epoch 208/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.2282e-05 - val_loss: 4.5038e-05 - learning_rate: 1.5115e-04\n",
            "Epoch 209/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.2227e-05 - val_loss: 4.5535e-05 - learning_rate: 1.4964e-04\n",
            "Epoch 210/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.2644e-05 - val_loss: 4.5466e-05 - learning_rate: 1.4815e-04\n",
            "Epoch 211/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.2529e-05 - val_loss: 4.6362e-05 - learning_rate: 1.4666e-04\n",
            "Epoch 212/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.2391e-05 - val_loss: 4.5183e-05 - learning_rate: 1.4520e-04\n",
            "Epoch 213/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.2236e-05 - val_loss: 4.5705e-05 - learning_rate: 1.4374e-04\n",
            "Epoch 214/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.2073e-05 - val_loss: 4.7687e-05 - learning_rate: 1.4231e-04\n",
            "Epoch 215/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.2520e-05 - val_loss: 4.4304e-05 - learning_rate: 1.4088e-04\n",
            "Epoch 216/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.2201e-05 - val_loss: 4.4703e-05 - learning_rate: 1.3948e-04\n",
            "Epoch 217/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.1730e-05 - val_loss: 4.4823e-05 - learning_rate: 1.3808e-04\n",
            "Epoch 218/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.1815e-05 - val_loss: 4.5208e-05 - learning_rate: 1.3670e-04\n",
            "Epoch 219/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.1998e-05 - val_loss: 4.4123e-05 - learning_rate: 1.3533e-04\n",
            "Epoch 220/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.1916e-05 - val_loss: 4.4967e-05 - learning_rate: 1.3398e-04\n",
            "Epoch 221/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.1700e-05 - val_loss: 4.4561e-05 - learning_rate: 1.3264e-04\n",
            "Epoch 222/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.1896e-05 - val_loss: 4.4607e-05 - learning_rate: 1.3131e-04\n",
            "Epoch 223/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.1642e-05 - val_loss: 4.4887e-05 - learning_rate: 1.3000e-04\n",
            "Epoch 224/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.1689e-05 - val_loss: 4.4324e-05 - learning_rate: 1.2870e-04\n",
            "Epoch 225/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.1282e-05 - val_loss: 4.3696e-05 - learning_rate: 1.2741e-04\n",
            "Epoch 226/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.1405e-05 - val_loss: 4.4717e-05 - learning_rate: 1.2614e-04\n",
            "Epoch 227/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.1393e-05 - val_loss: 4.4280e-05 - learning_rate: 1.2488e-04\n",
            "Epoch 228/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.1390e-05 - val_loss: 4.3897e-05 - learning_rate: 1.2363e-04\n",
            "Epoch 229/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.1434e-05 - val_loss: 4.4661e-05 - learning_rate: 1.2239e-04\n",
            "Epoch 230/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.1512e-05 - val_loss: 4.4345e-05 - learning_rate: 1.2117e-04\n",
            "Epoch 231/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.1155e-05 - val_loss: 4.3808e-05 - learning_rate: 1.1996e-04\n",
            "Epoch 232/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.1221e-05 - val_loss: 4.3508e-05 - learning_rate: 1.1876e-04\n",
            "Epoch 233/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.0883e-05 - val_loss: 4.3683e-05 - learning_rate: 1.1757e-04\n",
            "Epoch 234/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.1046e-05 - val_loss: 4.4595e-05 - learning_rate: 1.1639e-04\n",
            "Epoch 235/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.1342e-05 - val_loss: 4.4159e-05 - learning_rate: 1.1523e-04\n",
            "Epoch 236/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.0943e-05 - val_loss: 4.3583e-05 - learning_rate: 1.1408e-04\n",
            "Epoch 237/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.0921e-05 - val_loss: 4.3491e-05 - learning_rate: 1.1294e-04\n",
            "Epoch 238/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.0840e-05 - val_loss: 4.3307e-05 - learning_rate: 1.1181e-04\n",
            "Epoch 239/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.1048e-05 - val_loss: 4.4123e-05 - learning_rate: 1.1069e-04\n",
            "Epoch 240/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.0701e-05 - val_loss: 4.4242e-05 - learning_rate: 1.0958e-04\n",
            "Epoch 241/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.0746e-05 - val_loss: 4.4514e-05 - learning_rate: 1.0849e-04\n",
            "Epoch 242/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.0479e-05 - val_loss: 4.3388e-05 - learning_rate: 1.0740e-04\n",
            "Epoch 243/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.0593e-05 - val_loss: 4.2991e-05 - learning_rate: 1.0633e-04\n",
            "Epoch 244/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.0782e-05 - val_loss: 4.3776e-05 - learning_rate: 1.0526e-04\n",
            "Epoch 245/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.0759e-05 - val_loss: 4.3495e-05 - learning_rate: 1.0421e-04\n",
            "Epoch 246/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.0637e-05 - val_loss: 4.3638e-05 - learning_rate: 1.0317e-04\n",
            "Epoch 247/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.0352e-05 - val_loss: 4.3500e-05 - learning_rate: 1.0214e-04\n",
            "Epoch 248/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.0748e-05 - val_loss: 4.3386e-05 - learning_rate: 1.0112e-04\n",
            "Epoch 249/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.0545e-05 - val_loss: 4.3523e-05 - learning_rate: 1.0011e-04\n",
            "Epoch 250/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.0083e-05 - val_loss: 4.2745e-05 - learning_rate: 9.9105e-05\n",
            "Epoch 251/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.0267e-05 - val_loss: 4.2880e-05 - learning_rate: 9.8114e-05\n",
            "Epoch 252/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.0262e-05 - val_loss: 4.3913e-05 - learning_rate: 9.7133e-05\n",
            "Epoch 253/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.0449e-05 - val_loss: 4.2823e-05 - learning_rate: 9.6161e-05\n",
            "Epoch 254/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.9989e-05 - val_loss: 4.2875e-05 - learning_rate: 9.5200e-05\n",
            "Epoch 255/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.0107e-05 - val_loss: 4.2654e-05 - learning_rate: 9.4248e-05\n",
            "Epoch 256/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.0076e-05 - val_loss: 4.2462e-05 - learning_rate: 9.3305e-05\n",
            "Epoch 257/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.0011e-05 - val_loss: 4.2844e-05 - learning_rate: 9.2372e-05\n",
            "Epoch 258/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.9843e-05 - val_loss: 4.2999e-05 - learning_rate: 9.1448e-05\n",
            "Epoch 259/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.9969e-05 - val_loss: 4.2862e-05 - learning_rate: 9.0534e-05\n",
            "Epoch 260/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.9961e-05 - val_loss: 4.2428e-05 - learning_rate: 8.9629e-05\n",
            "Epoch 261/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.0145e-05 - val_loss: 4.3036e-05 - learning_rate: 8.8732e-05\n",
            "Epoch 262/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.9902e-05 - val_loss: 4.2328e-05 - learning_rate: 8.7845e-05\n",
            "Epoch 263/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.9626e-05 - val_loss: 4.2613e-05 - learning_rate: 8.6967e-05\n",
            "Epoch 264/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.9826e-05 - val_loss: 4.2722e-05 - learning_rate: 8.6097e-05\n",
            "Epoch 265/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.9774e-05 - val_loss: 4.1897e-05 - learning_rate: 8.5236e-05\n",
            "Epoch 266/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.9779e-05 - val_loss: 4.2783e-05 - learning_rate: 8.4384e-05\n",
            "Epoch 267/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.9759e-05 - val_loss: 4.2440e-05 - learning_rate: 8.3540e-05\n",
            "Epoch 268/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.9561e-05 - val_loss: 4.3968e-05 - learning_rate: 8.2704e-05\n",
            "Epoch 269/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.9753e-05 - val_loss: 4.2525e-05 - learning_rate: 8.1877e-05\n",
            "Epoch 270/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.9585e-05 - val_loss: 4.2224e-05 - learning_rate: 8.1059e-05\n",
            "Epoch 271/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.9430e-05 - val_loss: 4.2125e-05 - learning_rate: 8.0248e-05\n",
            "Epoch 272/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.9319e-05 - val_loss: 4.2100e-05 - learning_rate: 7.9445e-05\n",
            "Epoch 273/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.9375e-05 - val_loss: 4.1738e-05 - learning_rate: 7.8651e-05\n",
            "Epoch 274/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.9387e-05 - val_loss: 4.2373e-05 - learning_rate: 7.7865e-05\n",
            "Epoch 275/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.9425e-05 - val_loss: 4.2198e-05 - learning_rate: 7.7086e-05\n",
            "Epoch 276/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.9447e-05 - val_loss: 4.1915e-05 - learning_rate: 7.6315e-05\n",
            "Epoch 277/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.9233e-05 - val_loss: 4.2365e-05 - learning_rate: 7.5552e-05\n",
            "Epoch 278/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.9495e-05 - val_loss: 4.1606e-05 - learning_rate: 7.4796e-05\n",
            "Epoch 279/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.9300e-05 - val_loss: 4.2276e-05 - learning_rate: 7.4048e-05\n",
            "Epoch 280/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.9233e-05 - val_loss: 4.2290e-05 - learning_rate: 7.3308e-05\n",
            "Epoch 281/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.9181e-05 - val_loss: 4.1676e-05 - learning_rate: 7.2575e-05\n",
            "Epoch 282/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.9297e-05 - val_loss: 4.1958e-05 - learning_rate: 7.1849e-05\n",
            "Epoch 283/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.9298e-05 - val_loss: 4.2072e-05 - learning_rate: 7.1131e-05\n",
            "Epoch 284/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.9068e-05 - val_loss: 4.1870e-05 - learning_rate: 7.0419e-05\n",
            "Epoch 285/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.9122e-05 - val_loss: 4.1548e-05 - learning_rate: 6.9715e-05\n",
            "Epoch 286/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.9119e-05 - val_loss: 4.1837e-05 - learning_rate: 6.9018e-05\n",
            "Epoch 287/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.9140e-05 - val_loss: 4.1531e-05 - learning_rate: 6.8328e-05\n",
            "Epoch 288/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.9066e-05 - val_loss: 4.1626e-05 - learning_rate: 6.7644e-05\n",
            "Epoch 289/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.9102e-05 - val_loss: 4.1415e-05 - learning_rate: 6.6968e-05\n",
            "Epoch 290/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8873e-05 - val_loss: 4.1283e-05 - learning_rate: 6.6298e-05\n",
            "Epoch 291/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8869e-05 - val_loss: 4.1133e-05 - learning_rate: 6.5635e-05\n",
            "Epoch 292/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8861e-05 - val_loss: 4.1323e-05 - learning_rate: 6.4979e-05\n",
            "Epoch 293/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8857e-05 - val_loss: 4.1285e-05 - learning_rate: 6.4329e-05\n",
            "Epoch 294/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8663e-05 - val_loss: 4.1475e-05 - learning_rate: 6.3686e-05\n",
            "Epoch 295/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8796e-05 - val_loss: 4.1653e-05 - learning_rate: 6.3049e-05\n",
            "Epoch 296/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8578e-05 - val_loss: 4.1429e-05 - learning_rate: 6.2419e-05\n",
            "Epoch 297/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8800e-05 - val_loss: 4.1351e-05 - learning_rate: 6.1794e-05\n",
            "Epoch 298/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8793e-05 - val_loss: 4.1315e-05 - learning_rate: 6.1176e-05\n",
            "Epoch 299/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8507e-05 - val_loss: 4.1970e-05 - learning_rate: 6.0565e-05\n",
            "Epoch 300/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8588e-05 - val_loss: 4.1318e-05 - learning_rate: 5.9959e-05\n",
            "Epoch 301/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8674e-05 - val_loss: 4.1411e-05 - learning_rate: 5.9359e-05\n",
            "Epoch 302/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8641e-05 - val_loss: 4.1033e-05 - learning_rate: 5.8766e-05\n",
            "Epoch 303/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8639e-05 - val_loss: 4.1201e-05 - learning_rate: 5.8178e-05\n",
            "Epoch 304/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8481e-05 - val_loss: 4.0977e-05 - learning_rate: 5.7596e-05\n",
            "Epoch 305/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8575e-05 - val_loss: 4.1068e-05 - learning_rate: 5.7020e-05\n",
            "Epoch 306/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8559e-05 - val_loss: 4.1287e-05 - learning_rate: 5.6450e-05\n",
            "Epoch 307/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8703e-05 - val_loss: 4.1011e-05 - learning_rate: 5.5886e-05\n",
            "Epoch 308/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8389e-05 - val_loss: 4.0854e-05 - learning_rate: 5.5327e-05\n",
            "Epoch 309/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8446e-05 - val_loss: 4.0925e-05 - learning_rate: 5.4774e-05\n",
            "Epoch 310/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8393e-05 - val_loss: 4.0913e-05 - learning_rate: 5.4226e-05\n",
            "Epoch 311/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8452e-05 - val_loss: 4.2085e-05 - learning_rate: 5.3684e-05\n",
            "Epoch 312/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8523e-05 - val_loss: 4.0893e-05 - learning_rate: 5.3147e-05\n",
            "Epoch 313/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8292e-05 - val_loss: 4.1063e-05 - learning_rate: 5.2615e-05\n",
            "Epoch 314/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8393e-05 - val_loss: 4.0401e-05 - learning_rate: 5.2089e-05\n",
            "Epoch 315/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8320e-05 - val_loss: 4.0955e-05 - learning_rate: 5.1568e-05\n",
            "Epoch 316/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8237e-05 - val_loss: 4.0744e-05 - learning_rate: 5.1053e-05\n",
            "Epoch 317/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8345e-05 - val_loss: 4.0728e-05 - learning_rate: 5.0542e-05\n",
            "Epoch 318/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8451e-05 - val_loss: 4.1277e-05 - learning_rate: 5.0037e-05\n",
            "Epoch 319/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8268e-05 - val_loss: 4.0593e-05 - learning_rate: 4.9536e-05\n",
            "Epoch 320/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8078e-05 - val_loss: 4.0997e-05 - learning_rate: 4.9041e-05\n",
            "Epoch 321/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8112e-05 - val_loss: 4.0561e-05 - learning_rate: 4.8550e-05\n",
            "Epoch 322/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8032e-05 - val_loss: 4.0570e-05 - learning_rate: 4.8065e-05\n",
            "Epoch 323/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8087e-05 - val_loss: 4.0928e-05 - learning_rate: 4.7584e-05\n",
            "Epoch 324/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.8224e-05 - val_loss: 4.0736e-05 - learning_rate: 4.7108e-05\n",
            "Epoch 325/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.7923e-05 - val_loss: 4.1035e-05 - learning_rate: 4.6637e-05\n",
            "Epoch 326/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.8086e-05 - val_loss: 4.0491e-05 - learning_rate: 4.6171e-05\n",
            "Epoch 327/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8184e-05 - val_loss: 4.0855e-05 - learning_rate: 4.5709e-05\n",
            "Epoch 328/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8078e-05 - val_loss: 4.0650e-05 - learning_rate: 4.5252e-05\n",
            "Epoch 329/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.7947e-05 - val_loss: 4.0671e-05 - learning_rate: 4.4800e-05\n",
            "Epoch 330/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.7916e-05 - val_loss: 4.0908e-05 - learning_rate: 4.4352e-05\n",
            "Epoch 331/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8050e-05 - val_loss: 4.0824e-05 - learning_rate: 4.3908e-05\n",
            "Epoch 332/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.8020e-05 - val_loss: 4.1198e-05 - learning_rate: 4.3469e-05\n",
            "Epoch 333/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7873e-05 - val_loss: 4.1112e-05 - learning_rate: 4.3034e-05\n",
            "Epoch 334/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7878e-05 - val_loss: 4.0561e-05 - learning_rate: 4.2604e-05\n",
            "Epoch 335/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7989e-05 - val_loss: 4.0625e-05 - learning_rate: 4.2178e-05\n",
            "Epoch 336/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7737e-05 - val_loss: 4.0806e-05 - learning_rate: 4.1756e-05\n",
            "Epoch 337/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7796e-05 - val_loss: 4.0435e-05 - learning_rate: 4.1339e-05\n",
            "Epoch 338/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7870e-05 - val_loss: 4.0732e-05 - learning_rate: 4.0925e-05\n",
            "Epoch 339/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7907e-05 - val_loss: 4.0287e-05 - learning_rate: 4.0516e-05\n",
            "Epoch 340/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7778e-05 - val_loss: 4.1030e-05 - learning_rate: 4.0111e-05\n",
            "Epoch 341/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7780e-05 - val_loss: 4.0583e-05 - learning_rate: 3.9710e-05\n",
            "Epoch 342/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7750e-05 - val_loss: 4.0583e-05 - learning_rate: 3.9313e-05\n",
            "Epoch 343/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7716e-05 - val_loss: 4.0563e-05 - learning_rate: 3.8920e-05\n",
            "Epoch 344/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7770e-05 - val_loss: 4.0502e-05 - learning_rate: 3.8530e-05\n",
            "Epoch 345/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7677e-05 - val_loss: 4.0280e-05 - learning_rate: 3.8145e-05\n",
            "Epoch 346/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7696e-05 - val_loss: 4.0292e-05 - learning_rate: 3.7764e-05\n",
            "Epoch 347/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7624e-05 - val_loss: 4.0035e-05 - learning_rate: 3.7386e-05\n",
            "Epoch 348/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7685e-05 - val_loss: 4.0507e-05 - learning_rate: 3.7012e-05\n",
            "Epoch 349/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7565e-05 - val_loss: 4.0451e-05 - learning_rate: 3.6642e-05\n",
            "Epoch 350/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7698e-05 - val_loss: 4.0322e-05 - learning_rate: 3.6276e-05\n",
            "Epoch 351/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7631e-05 - val_loss: 4.0338e-05 - learning_rate: 3.5913e-05\n",
            "Epoch 352/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7612e-05 - val_loss: 4.0081e-05 - learning_rate: 3.5554e-05\n",
            "Epoch 353/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7575e-05 - val_loss: 4.0234e-05 - learning_rate: 3.5198e-05\n",
            "Epoch 354/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7506e-05 - val_loss: 4.0093e-05 - learning_rate: 3.4846e-05\n",
            "Epoch 355/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7626e-05 - val_loss: 3.9889e-05 - learning_rate: 3.4498e-05\n",
            "Epoch 356/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7737e-05 - val_loss: 3.9925e-05 - learning_rate: 3.4153e-05\n",
            "Epoch 357/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7578e-05 - val_loss: 4.0567e-05 - learning_rate: 3.3811e-05\n",
            "Epoch 358/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7694e-05 - val_loss: 4.0285e-05 - learning_rate: 3.3473e-05\n",
            "Epoch 359/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7594e-05 - val_loss: 4.0098e-05 - learning_rate: 3.3138e-05\n",
            "Epoch 360/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7540e-05 - val_loss: 4.0345e-05 - learning_rate: 3.2807e-05\n",
            "Epoch 361/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7427e-05 - val_loss: 3.9943e-05 - learning_rate: 3.2479e-05\n",
            "Epoch 362/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7557e-05 - val_loss: 4.0303e-05 - learning_rate: 3.2154e-05\n",
            "Epoch 363/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7483e-05 - val_loss: 3.9975e-05 - learning_rate: 3.1833e-05\n",
            "Epoch 364/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7372e-05 - val_loss: 3.9974e-05 - learning_rate: 3.1514e-05\n",
            "Epoch 365/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7353e-05 - val_loss: 4.0509e-05 - learning_rate: 3.1199e-05\n",
            "Epoch 366/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7341e-05 - val_loss: 4.0077e-05 - learning_rate: 3.0887e-05\n",
            "Epoch 367/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7466e-05 - val_loss: 3.9734e-05 - learning_rate: 3.0578e-05\n",
            "Epoch 368/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7402e-05 - val_loss: 3.9824e-05 - learning_rate: 3.0272e-05\n",
            "Epoch 369/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7430e-05 - val_loss: 3.9887e-05 - learning_rate: 2.9970e-05\n",
            "Epoch 370/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7285e-05 - val_loss: 4.0055e-05 - learning_rate: 2.9670e-05\n",
            "Epoch 371/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7305e-05 - val_loss: 4.0008e-05 - learning_rate: 2.9373e-05\n",
            "Epoch 372/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7248e-05 - val_loss: 3.9795e-05 - learning_rate: 2.9080e-05\n",
            "Epoch 373/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7362e-05 - val_loss: 4.0176e-05 - learning_rate: 2.8789e-05\n",
            "Epoch 374/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7473e-05 - val_loss: 3.9897e-05 - learning_rate: 2.8501e-05\n",
            "Epoch 375/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7109e-05 - val_loss: 3.9765e-05 - learning_rate: 2.8216e-05\n",
            "Epoch 376/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7153e-05 - val_loss: 3.9833e-05 - learning_rate: 2.7934e-05\n",
            "Epoch 377/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7229e-05 - val_loss: 3.9774e-05 - learning_rate: 2.7654e-05\n",
            "Epoch 378/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7265e-05 - val_loss: 4.0144e-05 - learning_rate: 2.7378e-05\n",
            "Epoch 379/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7227e-05 - val_loss: 3.9810e-05 - learning_rate: 2.7104e-05\n",
            "Epoch 380/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7258e-05 - val_loss: 3.9571e-05 - learning_rate: 2.6833e-05\n",
            "Epoch 381/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7287e-05 - val_loss: 3.9769e-05 - learning_rate: 2.6565e-05\n",
            "Epoch 382/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7221e-05 - val_loss: 4.0044e-05 - learning_rate: 2.6299e-05\n",
            "Epoch 383/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7405e-05 - val_loss: 3.9662e-05 - learning_rate: 2.6036e-05\n",
            "Epoch 384/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7121e-05 - val_loss: 3.9715e-05 - learning_rate: 2.5776e-05\n",
            "Epoch 385/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7117e-05 - val_loss: 3.9583e-05 - learning_rate: 2.5518e-05\n",
            "Epoch 386/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7161e-05 - val_loss: 3.9696e-05 - learning_rate: 2.5263e-05\n",
            "Epoch 387/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7216e-05 - val_loss: 3.9552e-05 - learning_rate: 2.5010e-05\n",
            "Epoch 388/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7131e-05 - val_loss: 3.9571e-05 - learning_rate: 2.4760e-05\n",
            "Epoch 389/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7022e-05 - val_loss: 3.9886e-05 - learning_rate: 2.4512e-05\n",
            "Epoch 390/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7132e-05 - val_loss: 3.9807e-05 - learning_rate: 2.4267e-05\n",
            "Epoch 391/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7027e-05 - val_loss: 3.9836e-05 - learning_rate: 2.4025e-05\n",
            "Epoch 392/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7094e-05 - val_loss: 3.9535e-05 - learning_rate: 2.3784e-05\n",
            "Epoch 393/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7078e-05 - val_loss: 3.9435e-05 - learning_rate: 2.3547e-05\n",
            "Epoch 394/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7030e-05 - val_loss: 3.9732e-05 - learning_rate: 2.3311e-05\n",
            "Epoch 395/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6897e-05 - val_loss: 3.9676e-05 - learning_rate: 2.3078e-05\n",
            "Epoch 396/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7112e-05 - val_loss: 4.0009e-05 - learning_rate: 2.2847e-05\n",
            "Epoch 397/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7140e-05 - val_loss: 3.9622e-05 - learning_rate: 2.2619e-05\n",
            "Epoch 398/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6964e-05 - val_loss: 3.9751e-05 - learning_rate: 2.2393e-05\n",
            "Epoch 399/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6968e-05 - val_loss: 3.9660e-05 - learning_rate: 2.2169e-05\n",
            "Epoch 400/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6908e-05 - val_loss: 3.9614e-05 - learning_rate: 2.1947e-05\n",
            "Epoch 401/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6983e-05 - val_loss: 3.9755e-05 - learning_rate: 2.1727e-05\n",
            "Epoch 402/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6994e-05 - val_loss: 3.9330e-05 - learning_rate: 2.1510e-05\n",
            "Epoch 403/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6948e-05 - val_loss: 3.9572e-05 - learning_rate: 2.1295e-05\n",
            "Epoch 404/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7028e-05 - val_loss: 3.9356e-05 - learning_rate: 2.1082e-05\n",
            "Epoch 405/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6943e-05 - val_loss: 3.9360e-05 - learning_rate: 2.0871e-05\n",
            "Epoch 406/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6948e-05 - val_loss: 3.9540e-05 - learning_rate: 2.0663e-05\n",
            "Epoch 407/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6954e-05 - val_loss: 3.9386e-05 - learning_rate: 2.0456e-05\n",
            "Epoch 408/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6806e-05 - val_loss: 3.9579e-05 - learning_rate: 2.0251e-05\n",
            "Epoch 409/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6825e-05 - val_loss: 3.9288e-05 - learning_rate: 2.0049e-05\n",
            "Epoch 410/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7034e-05 - val_loss: 3.9339e-05 - learning_rate: 1.9848e-05\n",
            "Epoch 411/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6857e-05 - val_loss: 3.9283e-05 - learning_rate: 1.9650e-05\n",
            "Epoch 412/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6925e-05 - val_loss: 3.9694e-05 - learning_rate: 1.9453e-05\n",
            "Epoch 413/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6894e-05 - val_loss: 3.9388e-05 - learning_rate: 1.9259e-05\n",
            "Epoch 414/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6770e-05 - val_loss: 3.9545e-05 - learning_rate: 1.9066e-05\n",
            "Epoch 415/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6853e-05 - val_loss: 3.9655e-05 - learning_rate: 1.8876e-05\n",
            "Epoch 416/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6881e-05 - val_loss: 3.9511e-05 - learning_rate: 1.8687e-05\n",
            "Epoch 417/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6979e-05 - val_loss: 3.9311e-05 - learning_rate: 1.8500e-05\n",
            "Epoch 418/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6838e-05 - val_loss: 3.9479e-05 - learning_rate: 1.8315e-05\n",
            "Epoch 419/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6855e-05 - val_loss: 3.9372e-05 - learning_rate: 1.8132e-05\n",
            "Epoch 420/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6772e-05 - val_loss: 3.9305e-05 - learning_rate: 1.7951e-05\n",
            "Epoch 421/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6825e-05 - val_loss: 3.9448e-05 - learning_rate: 1.7771e-05\n",
            "Epoch 422/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6845e-05 - val_loss: 3.9295e-05 - learning_rate: 1.7593e-05\n",
            "Epoch 423/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6783e-05 - val_loss: 3.9612e-05 - learning_rate: 1.7417e-05\n",
            "Epoch 424/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6839e-05 - val_loss: 3.9338e-05 - learning_rate: 1.7243e-05\n",
            "Epoch 425/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6846e-05 - val_loss: 3.9602e-05 - learning_rate: 1.7071e-05\n",
            "Epoch 426/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6729e-05 - val_loss: 3.9362e-05 - learning_rate: 1.6900e-05\n",
            "Epoch 427/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6844e-05 - val_loss: 3.9450e-05 - learning_rate: 1.6731e-05\n",
            "Epoch 428/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6734e-05 - val_loss: 3.9350e-05 - learning_rate: 1.6564e-05\n",
            "Epoch 429/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6701e-05 - val_loss: 3.9151e-05 - learning_rate: 1.6398e-05\n",
            "Epoch 430/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6809e-05 - val_loss: 3.9268e-05 - learning_rate: 1.6234e-05\n",
            "Epoch 431/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6832e-05 - val_loss: 3.9203e-05 - learning_rate: 1.6072e-05\n",
            "Epoch 432/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6634e-05 - val_loss: 3.9341e-05 - learning_rate: 1.5911e-05\n",
            "Epoch 433/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6771e-05 - val_loss: 3.9458e-05 - learning_rate: 1.5752e-05\n",
            "Epoch 434/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6786e-05 - val_loss: 3.9238e-05 - learning_rate: 1.5594e-05\n",
            "Epoch 435/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6679e-05 - val_loss: 3.9259e-05 - learning_rate: 1.5439e-05\n",
            "Epoch 436/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6776e-05 - val_loss: 3.9355e-05 - learning_rate: 1.5284e-05\n",
            "Epoch 437/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6680e-05 - val_loss: 3.9212e-05 - learning_rate: 1.5131e-05\n",
            "Epoch 438/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6635e-05 - val_loss: 3.9172e-05 - learning_rate: 1.4980e-05\n",
            "Epoch 439/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6633e-05 - val_loss: 3.9252e-05 - learning_rate: 1.4830e-05\n",
            "Epoch 440/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6596e-05 - val_loss: 3.9256e-05 - learning_rate: 1.4682e-05\n",
            "Epoch 441/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6693e-05 - val_loss: 3.9404e-05 - learning_rate: 1.4535e-05\n",
            "Epoch 442/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6744e-05 - val_loss: 3.9244e-05 - learning_rate: 1.4390e-05\n",
            "Epoch 443/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6719e-05 - val_loss: 3.9196e-05 - learning_rate: 1.4246e-05\n",
            "Epoch 444/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6671e-05 - val_loss: 3.9137e-05 - learning_rate: 1.4103e-05\n",
            "Epoch 445/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6634e-05 - val_loss: 3.9125e-05 - learning_rate: 1.3962e-05\n",
            "Epoch 446/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6694e-05 - val_loss: 3.9218e-05 - learning_rate: 1.3823e-05\n",
            "Epoch 447/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6670e-05 - val_loss: 3.9366e-05 - learning_rate: 1.3684e-05\n",
            "Epoch 448/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6641e-05 - val_loss: 3.9158e-05 - learning_rate: 1.3548e-05\n",
            "Epoch 449/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.6539e-05 - val_loss: 3.9043e-05 - learning_rate: 1.3412e-05\n",
            "Epoch 450/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6564e-05 - val_loss: 3.9143e-05 - learning_rate: 1.3278e-05\n",
            "Epoch 451/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6554e-05 - val_loss: 3.9296e-05 - learning_rate: 1.3145e-05\n",
            "Epoch 452/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6635e-05 - val_loss: 3.9157e-05 - learning_rate: 1.3014e-05\n",
            "Epoch 453/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6523e-05 - val_loss: 3.9393e-05 - learning_rate: 1.2884e-05\n",
            "Epoch 454/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6691e-05 - val_loss: 3.9022e-05 - learning_rate: 1.2755e-05\n",
            "Epoch 455/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6489e-05 - val_loss: 3.9094e-05 - learning_rate: 1.2627e-05\n",
            "Epoch 456/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6522e-05 - val_loss: 3.8964e-05 - learning_rate: 1.2501e-05\n",
            "Epoch 457/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6699e-05 - val_loss: 3.9164e-05 - learning_rate: 1.2376e-05\n",
            "Epoch 458/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6545e-05 - val_loss: 3.9186e-05 - learning_rate: 1.2252e-05\n",
            "Epoch 459/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6620e-05 - val_loss: 3.9224e-05 - learning_rate: 1.2130e-05\n",
            "Epoch 460/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6464e-05 - val_loss: 3.9140e-05 - learning_rate: 1.2008e-05\n",
            "Epoch 461/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6553e-05 - val_loss: 3.9037e-05 - learning_rate: 1.1888e-05\n",
            "Epoch 462/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6644e-05 - val_loss: 3.9254e-05 - learning_rate: 1.1769e-05\n",
            "Epoch 463/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6524e-05 - val_loss: 3.9031e-05 - learning_rate: 1.1652e-05\n",
            "Epoch 464/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6518e-05 - val_loss: 3.9068e-05 - learning_rate: 1.1535e-05\n",
            "Epoch 465/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6516e-05 - val_loss: 3.9084e-05 - learning_rate: 1.1420e-05\n",
            "Epoch 466/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6572e-05 - val_loss: 3.9073e-05 - learning_rate: 1.1306e-05\n",
            "Epoch 467/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6476e-05 - val_loss: 3.9083e-05 - learning_rate: 1.1193e-05\n",
            "Epoch 468/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6626e-05 - val_loss: 3.8955e-05 - learning_rate: 1.1081e-05\n",
            "Epoch 469/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6560e-05 - val_loss: 3.9056e-05 - learning_rate: 1.0970e-05\n",
            "Epoch 470/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6524e-05 - val_loss: 3.8982e-05 - learning_rate: 1.0860e-05\n",
            "Epoch 471/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6541e-05 - val_loss: 3.9002e-05 - learning_rate: 1.0752e-05\n",
            "Epoch 472/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6572e-05 - val_loss: 3.9025e-05 - learning_rate: 1.0644e-05\n",
            "Epoch 473/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6603e-05 - val_loss: 3.8991e-05 - learning_rate: 1.0538e-05\n",
            "Epoch 474/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6460e-05 - val_loss: 3.9012e-05 - learning_rate: 1.0432e-05\n",
            "Epoch 475/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6370e-05 - val_loss: 3.9055e-05 - learning_rate: 1.0328e-05\n",
            "Epoch 476/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6522e-05 - val_loss: 3.9120e-05 - learning_rate: 1.0225e-05\n",
            "Epoch 477/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6408e-05 - val_loss: 3.9035e-05 - learning_rate: 1.0122e-05\n",
            "Epoch 478/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6506e-05 - val_loss: 3.9016e-05 - learning_rate: 1.0021e-05\n",
            "Epoch 479/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6418e-05 - val_loss: 3.9253e-05 - learning_rate: 9.9210e-06\n",
            "Epoch 480/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6608e-05 - val_loss: 3.9007e-05 - learning_rate: 9.8218e-06\n",
            "Epoch 481/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6511e-05 - val_loss: 3.8955e-05 - learning_rate: 9.7235e-06\n",
            "Epoch 482/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6450e-05 - val_loss: 3.8943e-05 - learning_rate: 9.6263e-06\n",
            "Epoch 483/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6491e-05 - val_loss: 3.9088e-05 - learning_rate: 9.5300e-06\n",
            "Epoch 484/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6554e-05 - val_loss: 3.8885e-05 - learning_rate: 9.4347e-06\n",
            "Epoch 485/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6417e-05 - val_loss: 3.8952e-05 - learning_rate: 9.3404e-06\n",
            "Epoch 486/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6358e-05 - val_loss: 3.8889e-05 - learning_rate: 9.2470e-06\n",
            "Epoch 487/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6405e-05 - val_loss: 3.8986e-05 - learning_rate: 9.1545e-06\n",
            "Epoch 488/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6462e-05 - val_loss: 3.9037e-05 - learning_rate: 9.0630e-06\n",
            "Epoch 489/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6426e-05 - val_loss: 3.8922e-05 - learning_rate: 8.9724e-06\n",
            "Epoch 490/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6427e-05 - val_loss: 3.8951e-05 - learning_rate: 8.8826e-06\n",
            "Epoch 491/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6447e-05 - val_loss: 3.8914e-05 - learning_rate: 8.7938e-06\n",
            "Epoch 492/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6411e-05 - val_loss: 3.8951e-05 - learning_rate: 8.7059e-06\n",
            "Epoch 493/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6363e-05 - val_loss: 3.8997e-05 - learning_rate: 8.6188e-06\n",
            "Epoch 494/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6459e-05 - val_loss: 3.8903e-05 - learning_rate: 8.5326e-06\n",
            "Epoch 495/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6389e-05 - val_loss: 3.8846e-05 - learning_rate: 8.4473e-06\n",
            "Epoch 496/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6364e-05 - val_loss: 3.8884e-05 - learning_rate: 8.3628e-06\n",
            "Epoch 497/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6313e-05 - val_loss: 3.8807e-05 - learning_rate: 8.2792e-06\n",
            "Epoch 498/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6235e-05 - val_loss: 3.8942e-05 - learning_rate: 8.1964e-06\n",
            "Epoch 499/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6222e-05 - val_loss: 3.9016e-05 - learning_rate: 8.1144e-06\n",
            "Epoch 500/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6397e-05 - val_loss: 3.8976e-05 - learning_rate: 8.0333e-06\n",
            "Epoch 501/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6356e-05 - val_loss: 3.8910e-05 - learning_rate: 7.9530e-06\n",
            "Epoch 502/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6500e-05 - val_loss: 3.8983e-05 - learning_rate: 7.8734e-06\n",
            "Epoch 503/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6459e-05 - val_loss: 3.8762e-05 - learning_rate: 7.7947e-06\n",
            "Epoch 504/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6414e-05 - val_loss: 3.8903e-05 - learning_rate: 7.7167e-06\n",
            "Epoch 505/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6492e-05 - val_loss: 3.8979e-05 - learning_rate: 7.6396e-06\n",
            "Epoch 506/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6330e-05 - val_loss: 3.8806e-05 - learning_rate: 7.5632e-06\n",
            "Epoch 507/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6367e-05 - val_loss: 3.8890e-05 - learning_rate: 7.4875e-06\n",
            "Epoch 508/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6324e-05 - val_loss: 3.8965e-05 - learning_rate: 7.4127e-06\n",
            "Epoch 509/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6369e-05 - val_loss: 3.8916e-05 - learning_rate: 7.3385e-06\n",
            "Epoch 510/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6290e-05 - val_loss: 3.8825e-05 - learning_rate: 7.2652e-06\n",
            "Epoch 511/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6276e-05 - val_loss: 3.8934e-05 - learning_rate: 7.1925e-06\n",
            "Epoch 512/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6358e-05 - val_loss: 3.8913e-05 - learning_rate: 7.1206e-06\n",
            "Epoch 513/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6477e-05 - val_loss: 3.8893e-05 - learning_rate: 7.0494e-06\n",
            "Epoch 514/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6267e-05 - val_loss: 3.9053e-05 - learning_rate: 6.9789e-06\n",
            "Epoch 515/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6277e-05 - val_loss: 3.8862e-05 - learning_rate: 6.9091e-06\n",
            "Epoch 516/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6401e-05 - val_loss: 3.8916e-05 - learning_rate: 6.8400e-06\n",
            "Epoch 517/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6219e-05 - val_loss: 3.8788e-05 - learning_rate: 6.7716e-06\n",
            "Epoch 518/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6440e-05 - val_loss: 3.8743e-05 - learning_rate: 6.7039e-06\n",
            "Epoch 519/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6313e-05 - val_loss: 3.8829e-05 - learning_rate: 6.6369e-06\n",
            "Epoch 520/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6144e-05 - val_loss: 3.8796e-05 - learning_rate: 6.5705e-06\n",
            "Epoch 521/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6269e-05 - val_loss: 3.8837e-05 - learning_rate: 6.5048e-06\n",
            "Epoch 522/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6233e-05 - val_loss: 3.8869e-05 - learning_rate: 6.4397e-06\n",
            "Epoch 523/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6256e-05 - val_loss: 3.8764e-05 - learning_rate: 6.3753e-06\n",
            "Epoch 524/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6317e-05 - val_loss: 3.8845e-05 - learning_rate: 6.3116e-06\n",
            "Epoch 525/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6301e-05 - val_loss: 3.8812e-05 - learning_rate: 6.2485e-06\n",
            "Epoch 526/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6402e-05 - val_loss: 3.8844e-05 - learning_rate: 6.1860e-06\n",
            "Epoch 527/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6355e-05 - val_loss: 3.8822e-05 - learning_rate: 6.1241e-06\n",
            "Epoch 528/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6316e-05 - val_loss: 3.8740e-05 - learning_rate: 6.0629e-06\n",
            "Epoch 529/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6361e-05 - val_loss: 3.8798e-05 - learning_rate: 6.0022e-06\n",
            "Epoch 530/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6171e-05 - val_loss: 3.8877e-05 - learning_rate: 5.9422e-06\n",
            "Epoch 531/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6309e-05 - val_loss: 3.8804e-05 - learning_rate: 5.8828e-06\n",
            "Epoch 532/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6273e-05 - val_loss: 3.8838e-05 - learning_rate: 5.8240e-06\n",
            "Epoch 533/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6150e-05 - val_loss: 3.8794e-05 - learning_rate: 5.7657e-06\n",
            "Epoch 534/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6244e-05 - val_loss: 3.8770e-05 - learning_rate: 5.7081e-06\n",
            "Epoch 535/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6224e-05 - val_loss: 3.8788e-05 - learning_rate: 5.6510e-06\n",
            "Epoch 536/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6232e-05 - val_loss: 3.8994e-05 - learning_rate: 5.5945e-06\n",
            "Epoch 537/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6207e-05 - val_loss: 3.8864e-05 - learning_rate: 5.5385e-06\n",
            "Epoch 538/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6176e-05 - val_loss: 3.8777e-05 - learning_rate: 5.4832e-06\n",
            "Epoch 539/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6239e-05 - val_loss: 3.8700e-05 - learning_rate: 5.4283e-06\n",
            "Epoch 540/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6356e-05 - val_loss: 3.8711e-05 - learning_rate: 5.3740e-06\n",
            "Epoch 541/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6240e-05 - val_loss: 3.8752e-05 - learning_rate: 5.3203e-06\n",
            "Epoch 542/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6260e-05 - val_loss: 3.8818e-05 - learning_rate: 5.2671e-06\n",
            "Epoch 543/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6289e-05 - val_loss: 3.8819e-05 - learning_rate: 5.2144e-06\n",
            "Epoch 544/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6258e-05 - val_loss: 3.8760e-05 - learning_rate: 5.1623e-06\n",
            "Epoch 545/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6235e-05 - val_loss: 3.8835e-05 - learning_rate: 5.1107e-06\n",
            "Epoch 546/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6224e-05 - val_loss: 3.8744e-05 - learning_rate: 5.0596e-06\n",
            "Epoch 547/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6308e-05 - val_loss: 3.8742e-05 - learning_rate: 5.0090e-06\n",
            "Epoch 548/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6272e-05 - val_loss: 3.8771e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 549/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6292e-05 - val_loss: 3.8814e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 550/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6237e-05 - val_loss: 3.8804e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 551/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6242e-05 - val_loss: 3.8753e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 552/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6182e-05 - val_loss: 3.8740e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 553/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6192e-05 - val_loss: 3.8752e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 554/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6204e-05 - val_loss: 3.8825e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 555/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6140e-05 - val_loss: 3.8899e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 556/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6350e-05 - val_loss: 3.8755e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 557/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6255e-05 - val_loss: 3.8734e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 558/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6237e-05 - val_loss: 3.8732e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 559/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6114e-05 - val_loss: 3.8747e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 560/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6219e-05 - val_loss: 3.8777e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 561/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6206e-05 - val_loss: 3.8762e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 562/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6313e-05 - val_loss: 3.8720e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 563/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6272e-05 - val_loss: 3.8748e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 564/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6322e-05 - val_loss: 3.8771e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 565/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6153e-05 - val_loss: 3.8771e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 566/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6236e-05 - val_loss: 3.8641e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 567/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6052e-05 - val_loss: 3.8794e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 568/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6364e-05 - val_loss: 3.8792e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 569/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6230e-05 - val_loss: 3.8742e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 570/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6259e-05 - val_loss: 3.8696e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 571/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6146e-05 - val_loss: 3.8747e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 572/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6262e-05 - val_loss: 3.8656e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 573/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6208e-05 - val_loss: 3.8695e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 574/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6148e-05 - val_loss: 3.8737e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 575/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6250e-05 - val_loss: 3.8713e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 576/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6263e-05 - val_loss: 3.8740e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 577/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6253e-05 - val_loss: 3.8743e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 578/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6282e-05 - val_loss: 3.8683e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 579/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6178e-05 - val_loss: 3.8732e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 580/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6158e-05 - val_loss: 3.8772e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 581/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6133e-05 - val_loss: 3.8740e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 582/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6198e-05 - val_loss: 3.8671e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 583/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6154e-05 - val_loss: 3.8721e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 584/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6201e-05 - val_loss: 3.8692e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 585/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6179e-05 - val_loss: 3.8767e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 586/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6124e-05 - val_loss: 3.8680e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 587/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6156e-05 - val_loss: 3.8732e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 588/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6302e-05 - val_loss: 3.8753e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 589/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6203e-05 - val_loss: 3.8670e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 590/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6123e-05 - val_loss: 3.8709e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 591/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6200e-05 - val_loss: 3.8746e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 592/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6180e-05 - val_loss: 3.8742e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 593/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6131e-05 - val_loss: 3.8703e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 594/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6239e-05 - val_loss: 3.8832e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 595/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6122e-05 - val_loss: 3.8698e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 596/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6138e-05 - val_loss: 3.8716e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 597/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6249e-05 - val_loss: 3.8726e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 598/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6186e-05 - val_loss: 3.8649e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 599/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6178e-05 - val_loss: 3.8712e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 600/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6322e-05 - val_loss: 3.8685e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 601/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6140e-05 - val_loss: 3.8694e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 602/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6293e-05 - val_loss: 3.8676e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 603/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6209e-05 - val_loss: 3.8693e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 604/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6277e-05 - val_loss: 3.8684e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 605/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6141e-05 - val_loss: 3.8708e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 606/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6237e-05 - val_loss: 3.8768e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 607/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6064e-05 - val_loss: 3.8811e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 608/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6160e-05 - val_loss: 3.8702e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 609/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6219e-05 - val_loss: 3.8696e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 610/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6101e-05 - val_loss: 3.8639e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 611/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6156e-05 - val_loss: 3.8697e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 612/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6087e-05 - val_loss: 3.8654e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 613/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6208e-05 - val_loss: 3.8643e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 614/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6033e-05 - val_loss: 3.8724e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 615/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.6135e-05 - val_loss: 3.8658e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 616/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6175e-05 - val_loss: 3.8676e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 617/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6173e-05 - val_loss: 3.8667e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 618/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6251e-05 - val_loss: 3.8744e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 619/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6244e-05 - val_loss: 3.8646e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 620/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6226e-05 - val_loss: 3.8633e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 621/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6056e-05 - val_loss: 3.8662e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 622/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6080e-05 - val_loss: 3.8733e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 623/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6150e-05 - val_loss: 3.8624e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 624/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6196e-05 - val_loss: 3.8649e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 625/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6054e-05 - val_loss: 3.8586e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 626/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6246e-05 - val_loss: 3.8629e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 627/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6213e-05 - val_loss: 3.8617e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 628/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6167e-05 - val_loss: 3.8658e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 629/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6230e-05 - val_loss: 3.8680e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 630/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6104e-05 - val_loss: 3.8643e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 631/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6176e-05 - val_loss: 3.8707e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 632/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6119e-05 - val_loss: 3.8671e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 633/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6097e-05 - val_loss: 3.8696e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 634/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6156e-05 - val_loss: 3.8627e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 635/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6215e-05 - val_loss: 3.8701e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 636/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6179e-05 - val_loss: 3.8644e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 637/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6140e-05 - val_loss: 3.8605e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 638/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6303e-05 - val_loss: 3.8617e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 639/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6150e-05 - val_loss: 3.8637e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 640/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6078e-05 - val_loss: 3.8624e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 641/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6233e-05 - val_loss: 3.8601e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 642/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6199e-05 - val_loss: 3.8645e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 643/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6141e-05 - val_loss: 3.8652e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 644/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6175e-05 - val_loss: 3.8602e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 645/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6133e-05 - val_loss: 3.8590e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 646/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6200e-05 - val_loss: 3.8545e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 647/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6046e-05 - val_loss: 3.8704e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 648/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6131e-05 - val_loss: 3.8620e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 649/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6101e-05 - val_loss: 3.8759e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 650/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6162e-05 - val_loss: 3.8671e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 651/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6075e-05 - val_loss: 3.8620e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 652/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6021e-05 - val_loss: 3.8722e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 653/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6077e-05 - val_loss: 3.8674e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 654/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6175e-05 - val_loss: 3.8723e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 655/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6082e-05 - val_loss: 3.8637e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 656/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6155e-05 - val_loss: 3.8631e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 657/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5998e-05 - val_loss: 3.8554e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 658/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6130e-05 - val_loss: 3.8539e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 659/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6231e-05 - val_loss: 3.8615e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 660/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6210e-05 - val_loss: 3.8545e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 661/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6098e-05 - val_loss: 3.8538e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 662/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6113e-05 - val_loss: 3.8607e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 663/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6193e-05 - val_loss: 3.8595e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 664/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6038e-05 - val_loss: 3.8559e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 665/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6244e-05 - val_loss: 3.8678e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 666/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6223e-05 - val_loss: 3.8561e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 667/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6205e-05 - val_loss: 3.8669e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 668/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6167e-05 - val_loss: 3.8597e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 669/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6007e-05 - val_loss: 3.8712e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 670/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6081e-05 - val_loss: 3.8580e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 671/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6068e-05 - val_loss: 3.8566e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 672/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6204e-05 - val_loss: 3.8575e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 673/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6017e-05 - val_loss: 3.8604e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 674/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6185e-05 - val_loss: 3.8598e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 675/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6107e-05 - val_loss: 3.8544e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 676/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6100e-05 - val_loss: 3.8617e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 677/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6194e-05 - val_loss: 3.8635e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 678/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6126e-05 - val_loss: 3.8598e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 679/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6090e-05 - val_loss: 3.8640e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 680/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6011e-05 - val_loss: 3.8645e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 681/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6144e-05 - val_loss: 3.8560e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 682/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6044e-05 - val_loss: 3.8526e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 683/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6228e-05 - val_loss: 3.8561e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 684/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6005e-05 - val_loss: 3.8544e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 685/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6155e-05 - val_loss: 3.8632e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 686/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6129e-05 - val_loss: 3.8566e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 687/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5987e-05 - val_loss: 3.8550e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 688/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6100e-05 - val_loss: 3.8585e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 689/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6042e-05 - val_loss: 3.8638e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 690/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5947e-05 - val_loss: 3.8520e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 691/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6113e-05 - val_loss: 3.8535e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 692/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6294e-05 - val_loss: 3.8566e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 693/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6040e-05 - val_loss: 3.8508e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 694/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6082e-05 - val_loss: 3.8568e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 695/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6060e-05 - val_loss: 3.8589e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 696/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6137e-05 - val_loss: 3.8504e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 697/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6066e-05 - val_loss: 3.8519e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 698/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6090e-05 - val_loss: 3.8529e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 699/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6148e-05 - val_loss: 3.8516e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 700/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6062e-05 - val_loss: 3.8557e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 701/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6065e-05 - val_loss: 3.8636e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 702/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6093e-05 - val_loss: 3.8506e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 703/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6160e-05 - val_loss: 3.8542e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 704/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6082e-05 - val_loss: 3.8506e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 705/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6225e-05 - val_loss: 3.8523e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 706/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6107e-05 - val_loss: 3.8632e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 707/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6132e-05 - val_loss: 3.8508e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 708/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5970e-05 - val_loss: 3.8538e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 709/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6136e-05 - val_loss: 3.8608e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 710/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6012e-05 - val_loss: 3.8481e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 711/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6108e-05 - val_loss: 3.8470e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 712/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6096e-05 - val_loss: 3.8556e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 713/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6119e-05 - val_loss: 3.8582e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 714/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6042e-05 - val_loss: 3.8515e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 715/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6039e-05 - val_loss: 3.8587e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 716/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6177e-05 - val_loss: 3.8656e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 717/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6028e-05 - val_loss: 3.8519e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 718/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5966e-05 - val_loss: 3.8477e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 719/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5959e-05 - val_loss: 3.8452e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 720/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6184e-05 - val_loss: 3.8531e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 721/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6036e-05 - val_loss: 3.8608e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 722/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6157e-05 - val_loss: 3.8507e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 723/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6116e-05 - val_loss: 3.8528e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 724/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6047e-05 - val_loss: 3.8458e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 725/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6119e-05 - val_loss: 3.8505e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 726/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6050e-05 - val_loss: 3.8551e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 727/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6011e-05 - val_loss: 3.8532e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 728/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6066e-05 - val_loss: 3.8547e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 729/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6081e-05 - val_loss: 3.8453e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 730/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6046e-05 - val_loss: 3.8531e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 731/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6214e-05 - val_loss: 3.8478e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 732/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5937e-05 - val_loss: 3.8460e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 733/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6110e-05 - val_loss: 3.8411e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 734/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5905e-05 - val_loss: 3.8467e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 735/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5843e-05 - val_loss: 3.8476e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 736/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6142e-05 - val_loss: 3.8487e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 737/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6005e-05 - val_loss: 3.8434e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 738/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6066e-05 - val_loss: 3.8526e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 739/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6023e-05 - val_loss: 3.8556e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 740/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6064e-05 - val_loss: 3.8461e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 741/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5972e-05 - val_loss: 3.8451e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 742/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6013e-05 - val_loss: 3.8514e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 743/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5934e-05 - val_loss: 3.8511e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 744/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5974e-05 - val_loss: 3.8463e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 745/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6063e-05 - val_loss: 3.8439e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 746/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6041e-05 - val_loss: 3.8446e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 747/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6036e-05 - val_loss: 3.8461e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 748/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5964e-05 - val_loss: 3.8557e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 749/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5972e-05 - val_loss: 3.8480e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 750/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6019e-05 - val_loss: 3.8426e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 751/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5989e-05 - val_loss: 3.8461e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 752/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6132e-05 - val_loss: 3.8469e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 753/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6081e-05 - val_loss: 3.8447e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 754/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6129e-05 - val_loss: 3.8464e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 755/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6000e-05 - val_loss: 3.8466e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 756/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6143e-05 - val_loss: 3.8496e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 757/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6028e-05 - val_loss: 3.8432e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 758/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5992e-05 - val_loss: 3.8474e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 759/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6037e-05 - val_loss: 3.8409e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 760/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6073e-05 - val_loss: 3.8468e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 761/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6014e-05 - val_loss: 3.8507e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 762/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6040e-05 - val_loss: 3.8537e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 763/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6059e-05 - val_loss: 3.8445e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 764/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6031e-05 - val_loss: 3.8417e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 765/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6006e-05 - val_loss: 3.8468e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 766/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6081e-05 - val_loss: 3.8444e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 767/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6008e-05 - val_loss: 3.8444e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 768/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6037e-05 - val_loss: 3.8357e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 769/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6004e-05 - val_loss: 3.8512e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 770/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5926e-05 - val_loss: 3.8484e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 771/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6012e-05 - val_loss: 3.8442e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 772/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6032e-05 - val_loss: 3.8435e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 773/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6014e-05 - val_loss: 3.8447e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 774/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5953e-05 - val_loss: 3.8430e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 775/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5953e-05 - val_loss: 3.8416e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 776/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6017e-05 - val_loss: 3.8453e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 777/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6012e-05 - val_loss: 3.8400e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 778/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5918e-05 - val_loss: 3.8486e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 779/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6031e-05 - val_loss: 3.8450e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 780/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5975e-05 - val_loss: 3.8428e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 781/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6105e-05 - val_loss: 3.8424e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 782/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5937e-05 - val_loss: 3.8421e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 783/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6018e-05 - val_loss: 3.8478e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 784/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6092e-05 - val_loss: 3.8427e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 785/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5873e-05 - val_loss: 3.8471e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 786/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6013e-05 - val_loss: 3.8430e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 787/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6094e-05 - val_loss: 3.8475e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 788/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6047e-05 - val_loss: 3.8399e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 789/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5931e-05 - val_loss: 3.8383e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 790/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5948e-05 - val_loss: 3.8501e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 791/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6077e-05 - val_loss: 3.8396e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 792/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5937e-05 - val_loss: 3.8440e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 793/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6028e-05 - val_loss: 3.8372e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 794/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6047e-05 - val_loss: 3.8459e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 795/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6004e-05 - val_loss: 3.8408e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 796/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5867e-05 - val_loss: 3.8405e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 797/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5926e-05 - val_loss: 3.8403e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 798/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5915e-05 - val_loss: 3.8440e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 799/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5800e-05 - val_loss: 3.8485e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 800/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6034e-05 - val_loss: 3.8343e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 801/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6081e-05 - val_loss: 3.8462e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 802/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5885e-05 - val_loss: 3.8419e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 803/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6024e-05 - val_loss: 3.8429e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 804/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5920e-05 - val_loss: 3.8378e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 805/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6059e-05 - val_loss: 3.8344e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 806/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5982e-05 - val_loss: 3.8304e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 807/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5887e-05 - val_loss: 3.8332e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 808/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6077e-05 - val_loss: 3.8364e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 809/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5996e-05 - val_loss: 3.8391e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 810/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5984e-05 - val_loss: 3.8567e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 811/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5922e-05 - val_loss: 3.8400e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 812/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5969e-05 - val_loss: 3.8355e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 813/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6011e-05 - val_loss: 3.8449e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 814/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6011e-05 - val_loss: 3.8396e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 815/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5937e-05 - val_loss: 3.8428e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 816/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5865e-05 - val_loss: 3.8473e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 817/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6050e-05 - val_loss: 3.8331e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 818/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5965e-05 - val_loss: 3.8428e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 819/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5909e-05 - val_loss: 3.8396e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 820/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5922e-05 - val_loss: 3.8408e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 821/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5880e-05 - val_loss: 3.8324e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 822/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5983e-05 - val_loss: 3.8388e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 823/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6049e-05 - val_loss: 3.8429e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 824/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5917e-05 - val_loss: 3.8350e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 825/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6086e-05 - val_loss: 3.8403e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 826/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5963e-05 - val_loss: 3.8386e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 827/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5983e-05 - val_loss: 3.8304e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 828/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5812e-05 - val_loss: 3.8375e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 829/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6092e-05 - val_loss: 3.8424e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 830/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5921e-05 - val_loss: 3.8312e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 831/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6040e-05 - val_loss: 3.8363e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 832/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5910e-05 - val_loss: 3.8340e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 833/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5851e-05 - val_loss: 3.8345e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 834/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5964e-05 - val_loss: 3.8353e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 835/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5925e-05 - val_loss: 3.8406e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 836/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6025e-05 - val_loss: 3.8340e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 837/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5919e-05 - val_loss: 3.8417e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 838/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6045e-05 - val_loss: 3.8367e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 839/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6056e-05 - val_loss: 3.8348e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 840/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5911e-05 - val_loss: 3.8340e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 841/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5872e-05 - val_loss: 3.8331e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 842/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5879e-05 - val_loss: 3.8397e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 843/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5914e-05 - val_loss: 3.8356e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 844/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6035e-05 - val_loss: 3.8367e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 845/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5811e-05 - val_loss: 3.8335e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 846/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5983e-05 - val_loss: 3.8329e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 847/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5843e-05 - val_loss: 3.8294e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 848/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5867e-05 - val_loss: 3.8345e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 849/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5892e-05 - val_loss: 3.8370e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 850/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5983e-05 - val_loss: 3.8328e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 851/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5921e-05 - val_loss: 3.8308e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 852/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6005e-05 - val_loss: 3.8351e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 853/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5884e-05 - val_loss: 3.8288e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 854/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5888e-05 - val_loss: 3.8339e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 855/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6015e-05 - val_loss: 3.8381e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 856/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5944e-05 - val_loss: 3.8282e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 857/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5936e-05 - val_loss: 3.8381e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 858/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6017e-05 - val_loss: 3.8404e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 859/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5825e-05 - val_loss: 3.8306e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 860/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6021e-05 - val_loss: 3.8311e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 861/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5935e-05 - val_loss: 3.8278e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 862/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5992e-05 - val_loss: 3.8303e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 863/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5810e-05 - val_loss: 3.8307e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 864/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6028e-05 - val_loss: 3.8376e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 865/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5990e-05 - val_loss: 3.8279e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 866/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6052e-05 - val_loss: 3.8272e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 867/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5914e-05 - val_loss: 3.8299e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 868/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5903e-05 - val_loss: 3.8386e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 869/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5924e-05 - val_loss: 3.8299e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 870/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5946e-05 - val_loss: 3.8305e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 871/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5856e-05 - val_loss: 3.8347e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 872/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5956e-05 - val_loss: 3.8297e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 873/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5894e-05 - val_loss: 3.8341e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 874/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5846e-05 - val_loss: 3.8274e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 875/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5943e-05 - val_loss: 3.8291e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 876/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5860e-05 - val_loss: 3.8288e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 877/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5757e-05 - val_loss: 3.8355e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 878/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5880e-05 - val_loss: 3.8289e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 879/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5882e-05 - val_loss: 3.8376e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 880/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6019e-05 - val_loss: 3.8384e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 881/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5847e-05 - val_loss: 3.8260e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 882/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5901e-05 - val_loss: 3.8267e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 883/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5853e-05 - val_loss: 3.8311e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 884/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5859e-05 - val_loss: 3.8289e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 885/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5840e-05 - val_loss: 3.8268e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 886/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5950e-05 - val_loss: 3.8219e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 887/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5851e-05 - val_loss: 3.8321e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 888/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5835e-05 - val_loss: 3.8316e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 889/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5881e-05 - val_loss: 3.8260e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 890/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5754e-05 - val_loss: 3.8254e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 891/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5740e-05 - val_loss: 3.8286e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 892/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5932e-05 - val_loss: 3.8281e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 893/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5939e-05 - val_loss: 3.8317e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 894/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5972e-05 - val_loss: 3.8348e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 895/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5975e-05 - val_loss: 3.8343e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 896/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5916e-05 - val_loss: 3.8271e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 897/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5990e-05 - val_loss: 3.8278e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 898/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5889e-05 - val_loss: 3.8375e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 899/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5866e-05 - val_loss: 3.8309e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 900/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5952e-05 - val_loss: 3.8317e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 901/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5823e-05 - val_loss: 3.8244e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 902/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5874e-05 - val_loss: 3.8265e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 903/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5957e-05 - val_loss: 3.8237e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 904/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5883e-05 - val_loss: 3.8259e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 905/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5883e-05 - val_loss: 3.8281e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 906/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5935e-05 - val_loss: 3.8279e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 907/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5890e-05 - val_loss: 3.8253e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 908/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5919e-05 - val_loss: 3.8218e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 909/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5831e-05 - val_loss: 3.8255e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 910/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5968e-05 - val_loss: 3.8380e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 911/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5784e-05 - val_loss: 3.8222e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 912/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5844e-05 - val_loss: 3.8258e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 913/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5973e-05 - val_loss: 3.8207e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 914/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5883e-05 - val_loss: 3.8210e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 915/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5798e-05 - val_loss: 3.8239e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 916/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5793e-05 - val_loss: 3.8241e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 917/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5798e-05 - val_loss: 3.8222e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 918/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5913e-05 - val_loss: 3.8250e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 919/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5969e-05 - val_loss: 3.8222e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 920/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5991e-05 - val_loss: 3.8256e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 921/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5755e-05 - val_loss: 3.8299e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 922/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5803e-05 - val_loss: 3.8164e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 923/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5900e-05 - val_loss: 3.8174e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 924/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5822e-05 - val_loss: 3.8183e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 925/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5949e-05 - val_loss: 3.8217e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 926/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5830e-05 - val_loss: 3.8140e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 927/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5883e-05 - val_loss: 3.8178e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 928/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5891e-05 - val_loss: 3.8242e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 929/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5910e-05 - val_loss: 3.8169e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 930/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5894e-05 - val_loss: 3.8361e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 931/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5827e-05 - val_loss: 3.8186e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 932/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5828e-05 - val_loss: 3.8245e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 933/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5929e-05 - val_loss: 3.8177e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 934/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5708e-05 - val_loss: 3.8155e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 935/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5899e-05 - val_loss: 3.8232e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 936/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5943e-05 - val_loss: 3.8232e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 937/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5710e-05 - val_loss: 3.8188e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 938/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5919e-05 - val_loss: 3.8189e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 939/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5840e-05 - val_loss: 3.8217e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 940/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5824e-05 - val_loss: 3.8207e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 941/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5960e-05 - val_loss: 3.8202e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 942/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5861e-05 - val_loss: 3.8184e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 943/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5824e-05 - val_loss: 3.8139e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 944/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5799e-05 - val_loss: 3.8171e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 945/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5856e-05 - val_loss: 3.8153e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 946/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5860e-05 - val_loss: 3.8149e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 947/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5988e-05 - val_loss: 3.8186e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 948/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5890e-05 - val_loss: 3.8114e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 949/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5909e-05 - val_loss: 3.8195e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 950/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5797e-05 - val_loss: 3.8249e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 951/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5928e-05 - val_loss: 3.8152e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 952/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5817e-05 - val_loss: 3.8149e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 953/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5850e-05 - val_loss: 3.8208e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 954/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5892e-05 - val_loss: 3.8247e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 955/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5856e-05 - val_loss: 3.8252e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 956/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5914e-05 - val_loss: 3.8192e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 957/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5834e-05 - val_loss: 3.8179e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 958/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5828e-05 - val_loss: 3.8237e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 959/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5806e-05 - val_loss: 3.8144e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 960/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5844e-05 - val_loss: 3.8198e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 961/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5814e-05 - val_loss: 3.8111e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 962/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5880e-05 - val_loss: 3.8228e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 963/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5913e-05 - val_loss: 3.8234e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 964/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5838e-05 - val_loss: 3.8166e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 965/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5873e-05 - val_loss: 3.8182e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 966/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5803e-05 - val_loss: 3.8202e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 967/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5759e-05 - val_loss: 3.8176e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 968/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5923e-05 - val_loss: 3.8217e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 969/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5970e-05 - val_loss: 3.8168e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 970/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5755e-05 - val_loss: 3.8128e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 971/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5778e-05 - val_loss: 3.8203e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 972/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5945e-05 - val_loss: 3.8104e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 973/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5733e-05 - val_loss: 3.8245e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 974/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5903e-05 - val_loss: 3.8144e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 975/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5789e-05 - val_loss: 3.8139e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 976/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5827e-05 - val_loss: 3.8246e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 977/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5796e-05 - val_loss: 3.8239e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 978/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.5865e-05 - val_loss: 3.8133e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 979/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5791e-05 - val_loss: 3.8298e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 980/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5818e-05 - val_loss: 3.8133e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 981/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5897e-05 - val_loss: 3.8198e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 982/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5847e-05 - val_loss: 3.8155e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 983/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5786e-05 - val_loss: 3.8195e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 984/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5786e-05 - val_loss: 3.8313e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 985/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5841e-05 - val_loss: 3.8122e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 986/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5834e-05 - val_loss: 3.8105e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 987/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5743e-05 - val_loss: 3.8155e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 988/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5791e-05 - val_loss: 3.8131e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 989/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5808e-05 - val_loss: 3.8106e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 990/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5856e-05 - val_loss: 3.8149e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 991/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5776e-05 - val_loss: 3.8117e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 992/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5749e-05 - val_loss: 3.8129e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 993/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5726e-05 - val_loss: 3.8117e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 994/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5777e-05 - val_loss: 3.8162e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 995/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5838e-05 - val_loss: 3.8127e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 996/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5739e-05 - val_loss: 3.8156e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 997/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5745e-05 - val_loss: 3.8085e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 998/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5812e-05 - val_loss: 3.8072e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 999/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5758e-05 - val_loss: 3.8083e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1000/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5727e-05 - val_loss: 3.8214e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1001/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5803e-05 - val_loss: 3.8182e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1002/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5796e-05 - val_loss: 3.8179e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1003/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5691e-05 - val_loss: 3.8165e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1004/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5733e-05 - val_loss: 3.8106e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1005/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5862e-05 - val_loss: 3.8087e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1006/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5883e-05 - val_loss: 3.8140e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1007/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5700e-05 - val_loss: 3.8126e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1008/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5778e-05 - val_loss: 3.8119e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1009/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5766e-05 - val_loss: 3.8126e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1010/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5723e-05 - val_loss: 3.8103e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1011/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5772e-05 - val_loss: 3.8104e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1012/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5811e-05 - val_loss: 3.8111e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1013/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5943e-05 - val_loss: 3.8077e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1014/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5745e-05 - val_loss: 3.8111e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1015/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5781e-05 - val_loss: 3.8113e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1016/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5781e-05 - val_loss: 3.8083e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1017/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5665e-05 - val_loss: 3.8046e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1018/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5796e-05 - val_loss: 3.8054e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1019/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5809e-05 - val_loss: 3.8197e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1020/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5893e-05 - val_loss: 3.8062e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1021/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5771e-05 - val_loss: 3.8153e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1022/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5760e-05 - val_loss: 3.8043e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1023/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5704e-05 - val_loss: 3.8067e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1024/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5741e-05 - val_loss: 3.8069e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1025/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5765e-05 - val_loss: 3.8131e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1026/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5839e-05 - val_loss: 3.8085e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1027/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5721e-05 - val_loss: 3.8078e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1028/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5843e-05 - val_loss: 3.8070e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1029/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5740e-05 - val_loss: 3.8088e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1030/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5744e-05 - val_loss: 3.8091e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1031/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5646e-05 - val_loss: 3.8079e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1032/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5686e-05 - val_loss: 3.8067e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1033/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5780e-05 - val_loss: 3.8026e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1034/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5729e-05 - val_loss: 3.8101e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1035/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5727e-05 - val_loss: 3.8060e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1036/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5790e-05 - val_loss: 3.8091e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1037/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5759e-05 - val_loss: 3.8063e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1038/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5860e-05 - val_loss: 3.8093e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1039/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5786e-05 - val_loss: 3.8047e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1040/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5848e-05 - val_loss: 3.8127e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1041/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5784e-05 - val_loss: 3.8060e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1042/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5751e-05 - val_loss: 3.8067e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1043/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5852e-05 - val_loss: 3.8016e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1044/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5714e-05 - val_loss: 3.8014e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1045/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5704e-05 - val_loss: 3.8069e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1046/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5744e-05 - val_loss: 3.8081e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1047/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5790e-05 - val_loss: 3.8037e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1048/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5787e-05 - val_loss: 3.7998e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1049/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5731e-05 - val_loss: 3.8023e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1050/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5743e-05 - val_loss: 3.7986e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1051/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5655e-05 - val_loss: 3.8004e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1052/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5672e-05 - val_loss: 3.8061e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1053/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5842e-05 - val_loss: 3.8044e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1054/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5671e-05 - val_loss: 3.8047e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1055/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5733e-05 - val_loss: 3.8103e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1056/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5755e-05 - val_loss: 3.8079e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1057/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5820e-05 - val_loss: 3.8036e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1058/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5722e-05 - val_loss: 3.8081e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1059/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5777e-05 - val_loss: 3.8054e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1060/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5761e-05 - val_loss: 3.8039e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1061/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5708e-05 - val_loss: 3.8088e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1062/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5805e-05 - val_loss: 3.8062e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1063/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5729e-05 - val_loss: 3.8062e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1064/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5701e-05 - val_loss: 3.8018e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1065/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5663e-05 - val_loss: 3.8012e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1066/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5833e-05 - val_loss: 3.8012e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1067/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5685e-05 - val_loss: 3.8025e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1068/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5688e-05 - val_loss: 3.8052e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1069/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5724e-05 - val_loss: 3.8053e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1070/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5712e-05 - val_loss: 3.8043e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1071/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5582e-05 - val_loss: 3.8125e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1072/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5783e-05 - val_loss: 3.8052e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1073/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5774e-05 - val_loss: 3.8084e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1074/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5802e-05 - val_loss: 3.8141e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1075/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5632e-05 - val_loss: 3.8076e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1076/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5772e-05 - val_loss: 3.8056e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1077/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5769e-05 - val_loss: 3.8043e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1078/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5748e-05 - val_loss: 3.8080e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1079/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5769e-05 - val_loss: 3.8001e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1080/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5668e-05 - val_loss: 3.8104e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1081/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5613e-05 - val_loss: 3.8038e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1082/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5845e-05 - val_loss: 3.7938e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1083/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5805e-05 - val_loss: 3.8031e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1084/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5787e-05 - val_loss: 3.8033e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1085/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5786e-05 - val_loss: 3.7982e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1086/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5753e-05 - val_loss: 3.8023e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1087/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5744e-05 - val_loss: 3.8041e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1088/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5740e-05 - val_loss: 3.7972e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1089/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5665e-05 - val_loss: 3.8013e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1090/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5701e-05 - val_loss: 3.7924e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1091/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5530e-05 - val_loss: 3.8026e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1092/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5743e-05 - val_loss: 3.7946e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1093/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5660e-05 - val_loss: 3.8043e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1094/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5828e-05 - val_loss: 3.7993e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1095/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5815e-05 - val_loss: 3.7983e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1096/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5619e-05 - val_loss: 3.7961e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1097/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5679e-05 - val_loss: 3.7958e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1098/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5680e-05 - val_loss: 3.8065e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1099/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5654e-05 - val_loss: 3.8005e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1100/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5755e-05 - val_loss: 3.7995e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1101/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5710e-05 - val_loss: 3.7964e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1102/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5682e-05 - val_loss: 3.8021e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1103/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5558e-05 - val_loss: 3.8092e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1104/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5610e-05 - val_loss: 3.8023e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1105/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5683e-05 - val_loss: 3.7975e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1106/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5675e-05 - val_loss: 3.8177e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1107/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5710e-05 - val_loss: 3.7999e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1108/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5795e-05 - val_loss: 3.7972e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1109/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5719e-05 - val_loss: 3.8029e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1110/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5597e-05 - val_loss: 3.8076e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1111/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5547e-05 - val_loss: 3.8017e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1112/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5612e-05 - val_loss: 3.8038e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1113/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5719e-05 - val_loss: 3.8103e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1114/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5624e-05 - val_loss: 3.7980e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1115/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5632e-05 - val_loss: 3.7980e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1116/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5704e-05 - val_loss: 3.7974e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1117/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5712e-05 - val_loss: 3.7964e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1118/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5681e-05 - val_loss: 3.7958e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1119/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5706e-05 - val_loss: 3.7966e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1120/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5740e-05 - val_loss: 3.8033e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1121/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5679e-05 - val_loss: 3.7926e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1122/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5740e-05 - val_loss: 3.7991e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1123/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5708e-05 - val_loss: 3.7970e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1124/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5736e-05 - val_loss: 3.7977e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1125/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5566e-05 - val_loss: 3.7884e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1126/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5601e-05 - val_loss: 3.7969e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1127/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5597e-05 - val_loss: 3.8017e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1128/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5697e-05 - val_loss: 3.7920e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1129/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5784e-05 - val_loss: 3.7997e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1130/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5710e-05 - val_loss: 3.7936e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1131/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5656e-05 - val_loss: 3.7942e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1132/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5666e-05 - val_loss: 3.7911e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1133/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5595e-05 - val_loss: 3.8024e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1134/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5563e-05 - val_loss: 3.7912e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1135/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5667e-05 - val_loss: 3.8070e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1136/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5691e-05 - val_loss: 3.7995e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1137/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5667e-05 - val_loss: 3.7901e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1138/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5585e-05 - val_loss: 3.7923e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1139/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5701e-05 - val_loss: 3.7921e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1140/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5808e-05 - val_loss: 3.7988e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1141/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5774e-05 - val_loss: 3.8021e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1142/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5744e-05 - val_loss: 3.7962e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1143/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5704e-05 - val_loss: 3.8051e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1144/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5752e-05 - val_loss: 3.7842e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1145/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5692e-05 - val_loss: 3.7890e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1146/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5682e-05 - val_loss: 3.7932e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1147/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5701e-05 - val_loss: 3.7909e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1148/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5612e-05 - val_loss: 3.7884e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1149/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5579e-05 - val_loss: 3.7946e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1150/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5603e-05 - val_loss: 3.7894e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1151/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5713e-05 - val_loss: 3.7962e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1152/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5830e-05 - val_loss: 3.7924e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1153/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5605e-05 - val_loss: 3.7916e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1154/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5661e-05 - val_loss: 3.7980e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1155/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5586e-05 - val_loss: 3.7926e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1156/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5604e-05 - val_loss: 3.7943e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1157/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5569e-05 - val_loss: 3.7922e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1158/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5734e-05 - val_loss: 3.7955e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1159/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5595e-05 - val_loss: 3.7952e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1160/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5679e-05 - val_loss: 3.7869e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1161/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5587e-05 - val_loss: 3.7934e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1162/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5734e-05 - val_loss: 3.7923e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1163/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5577e-05 - val_loss: 3.7973e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1164/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5668e-05 - val_loss: 3.7901e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1165/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5587e-05 - val_loss: 3.7866e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1166/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5556e-05 - val_loss: 3.7944e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1167/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5769e-05 - val_loss: 3.7918e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1168/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5677e-05 - val_loss: 3.7866e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1169/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5642e-05 - val_loss: 3.7937e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1170/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5532e-05 - val_loss: 3.7909e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1171/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5664e-05 - val_loss: 3.7938e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1172/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5685e-05 - val_loss: 3.7937e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1173/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5647e-05 - val_loss: 3.7885e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1174/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5739e-05 - val_loss: 3.8035e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1175/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5601e-05 - val_loss: 3.7846e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1176/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5620e-05 - val_loss: 3.7885e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1177/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5690e-05 - val_loss: 3.7942e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1178/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5500e-05 - val_loss: 3.7884e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1179/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5586e-05 - val_loss: 3.7901e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1180/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5690e-05 - val_loss: 3.7846e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1181/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5660e-05 - val_loss: 3.7864e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1182/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5568e-05 - val_loss: 3.7828e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1183/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5662e-05 - val_loss: 3.7834e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1184/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5545e-05 - val_loss: 3.7850e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1185/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5606e-05 - val_loss: 3.7862e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1186/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5658e-05 - val_loss: 3.7842e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1187/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5543e-05 - val_loss: 3.7840e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1188/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5587e-05 - val_loss: 3.7803e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1189/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5529e-05 - val_loss: 3.7799e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1190/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5659e-05 - val_loss: 3.7969e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1191/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5681e-05 - val_loss: 3.7880e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1192/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5607e-05 - val_loss: 3.7862e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1193/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5488e-05 - val_loss: 3.7923e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1194/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5676e-05 - val_loss: 3.7855e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1195/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5734e-05 - val_loss: 3.7886e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1196/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5619e-05 - val_loss: 3.7870e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1197/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5609e-05 - val_loss: 3.7868e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1198/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5646e-05 - val_loss: 3.7912e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1199/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5636e-05 - val_loss: 3.7800e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1200/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5570e-05 - val_loss: 3.7821e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1201/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5594e-05 - val_loss: 3.7832e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1202/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5652e-05 - val_loss: 3.7889e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1203/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5609e-05 - val_loss: 3.7784e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1204/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5563e-05 - val_loss: 3.7911e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1205/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5487e-05 - val_loss: 3.7842e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1206/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5611e-05 - val_loss: 3.7819e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1207/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5657e-05 - val_loss: 3.7882e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1208/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5589e-05 - val_loss: 3.7877e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1209/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5603e-05 - val_loss: 3.7782e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1210/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5527e-05 - val_loss: 3.7816e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1211/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5551e-05 - val_loss: 3.7881e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1212/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5640e-05 - val_loss: 3.7912e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1213/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5619e-05 - val_loss: 3.7782e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1214/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5478e-05 - val_loss: 3.7858e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1215/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5557e-05 - val_loss: 3.7792e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1216/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5534e-05 - val_loss: 3.7808e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1217/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5612e-05 - val_loss: 3.7845e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1218/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5566e-05 - val_loss: 3.7813e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1219/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5616e-05 - val_loss: 3.7821e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1220/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5735e-05 - val_loss: 3.7866e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1221/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5538e-05 - val_loss: 3.7842e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1222/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5579e-05 - val_loss: 3.7828e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1223/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5560e-05 - val_loss: 3.7892e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1224/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5578e-05 - val_loss: 3.7914e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1225/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5712e-05 - val_loss: 3.7898e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1226/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5522e-05 - val_loss: 3.7815e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1227/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5662e-05 - val_loss: 3.7803e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1228/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5665e-05 - val_loss: 3.7875e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1229/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5575e-05 - val_loss: 3.7788e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1230/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5617e-05 - val_loss: 3.7781e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1231/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5556e-05 - val_loss: 3.7800e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1232/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5663e-05 - val_loss: 3.7833e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1233/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5639e-05 - val_loss: 3.7776e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1234/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5561e-05 - val_loss: 3.7826e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1235/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5590e-05 - val_loss: 3.7842e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1236/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5495e-05 - val_loss: 3.7806e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1237/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5549e-05 - val_loss: 3.7857e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1238/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5602e-05 - val_loss: 3.7845e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1239/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5599e-05 - val_loss: 3.7774e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1240/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5675e-05 - val_loss: 3.7748e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1241/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5505e-05 - val_loss: 3.7883e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1242/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5518e-05 - val_loss: 3.7835e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1243/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5517e-05 - val_loss: 3.7823e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1244/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5626e-05 - val_loss: 3.7809e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1245/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5567e-05 - val_loss: 3.7857e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1246/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5702e-05 - val_loss: 3.7757e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1247/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5621e-05 - val_loss: 3.7832e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1248/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5517e-05 - val_loss: 3.7870e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1249/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5532e-05 - val_loss: 3.7880e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1250/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5456e-05 - val_loss: 3.7838e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1251/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5625e-05 - val_loss: 3.7748e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1252/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5559e-05 - val_loss: 3.7742e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1253/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5585e-05 - val_loss: 3.7781e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1254/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5613e-05 - val_loss: 3.7763e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1255/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5538e-05 - val_loss: 3.7783e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1256/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5551e-05 - val_loss: 3.7791e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1257/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5541e-05 - val_loss: 3.7812e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1258/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5514e-05 - val_loss: 3.7822e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1259/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5425e-05 - val_loss: 3.7768e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1260/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5478e-05 - val_loss: 3.7785e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1261/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5575e-05 - val_loss: 3.7751e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1262/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5625e-05 - val_loss: 3.7804e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1263/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5576e-05 - val_loss: 3.7766e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1264/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5619e-05 - val_loss: 3.7909e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1265/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5479e-05 - val_loss: 3.7781e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1266/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5497e-05 - val_loss: 3.7696e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1267/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5536e-05 - val_loss: 3.7797e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1268/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5471e-05 - val_loss: 3.7794e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1269/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5535e-05 - val_loss: 3.7816e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1270/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5455e-05 - val_loss: 3.7768e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1271/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5580e-05 - val_loss: 3.7764e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1272/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5520e-05 - val_loss: 3.7831e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1273/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5566e-05 - val_loss: 3.7783e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1274/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5525e-05 - val_loss: 3.7742e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1275/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5527e-05 - val_loss: 3.7722e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1276/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5684e-05 - val_loss: 3.7693e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1277/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5501e-05 - val_loss: 3.7756e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1278/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5484e-05 - val_loss: 3.7835e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1279/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5460e-05 - val_loss: 3.7732e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1280/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5390e-05 - val_loss: 3.7738e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1281/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5497e-05 - val_loss: 3.7758e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1282/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5558e-05 - val_loss: 3.7747e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1283/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5595e-05 - val_loss: 3.7736e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1284/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5526e-05 - val_loss: 3.7707e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1285/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5548e-05 - val_loss: 3.7774e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1286/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5612e-05 - val_loss: 3.7689e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1287/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5528e-05 - val_loss: 3.7743e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1288/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5487e-05 - val_loss: 3.7697e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1289/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5366e-05 - val_loss: 3.7869e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1290/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5463e-05 - val_loss: 3.7762e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1291/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5516e-05 - val_loss: 3.7714e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1292/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5541e-05 - val_loss: 3.7789e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1293/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5544e-05 - val_loss: 3.7724e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1294/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5501e-05 - val_loss: 3.7740e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1295/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5592e-05 - val_loss: 3.7828e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1296/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5545e-05 - val_loss: 3.7802e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1297/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5488e-05 - val_loss: 3.7741e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1298/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5463e-05 - val_loss: 3.7869e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1299/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5418e-05 - val_loss: 3.7804e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1300/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5532e-05 - val_loss: 3.7638e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1301/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5450e-05 - val_loss: 3.7707e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1302/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5573e-05 - val_loss: 3.7716e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1303/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5455e-05 - val_loss: 3.7782e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1304/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5492e-05 - val_loss: 3.7716e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1305/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5448e-05 - val_loss: 3.7676e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1306/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5590e-05 - val_loss: 3.7685e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1307/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5498e-05 - val_loss: 3.7705e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1308/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5379e-05 - val_loss: 3.7693e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1309/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5417e-05 - val_loss: 3.7669e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1310/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5546e-05 - val_loss: 3.7673e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1311/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5465e-05 - val_loss: 3.7667e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1312/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5522e-05 - val_loss: 3.7689e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1313/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5516e-05 - val_loss: 3.7720e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1314/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5434e-05 - val_loss: 3.7748e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1315/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5551e-05 - val_loss: 3.7692e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1316/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5538e-05 - val_loss: 3.7800e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1317/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5440e-05 - val_loss: 3.7675e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1318/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5410e-05 - val_loss: 3.7814e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1319/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5580e-05 - val_loss: 3.7771e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1320/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5405e-05 - val_loss: 3.7873e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1321/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5510e-05 - val_loss: 3.7669e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1322/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5528e-05 - val_loss: 3.7670e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1323/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5491e-05 - val_loss: 3.7835e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1324/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5604e-05 - val_loss: 3.7722e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1325/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5606e-05 - val_loss: 3.7631e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1326/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5561e-05 - val_loss: 3.7760e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1327/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5395e-05 - val_loss: 3.7682e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1328/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5615e-05 - val_loss: 3.7776e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1329/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5568e-05 - val_loss: 3.7726e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1330/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5507e-05 - val_loss: 3.7685e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1331/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5485e-05 - val_loss: 3.7683e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1332/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5552e-05 - val_loss: 3.7682e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1333/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5532e-05 - val_loss: 3.7711e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1334/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5458e-05 - val_loss: 3.7720e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1335/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5520e-05 - val_loss: 3.7708e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1336/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5526e-05 - val_loss: 3.7743e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1337/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5372e-05 - val_loss: 3.7684e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1338/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5543e-05 - val_loss: 3.7753e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1339/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5486e-05 - val_loss: 3.7758e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1340/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5464e-05 - val_loss: 3.7694e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1341/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5556e-05 - val_loss: 3.7631e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1342/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5488e-05 - val_loss: 3.7682e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1343/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5401e-05 - val_loss: 3.7684e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1344/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5466e-05 - val_loss: 3.7705e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1345/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5432e-05 - val_loss: 3.7596e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1346/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5367e-05 - val_loss: 3.7702e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1347/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5451e-05 - val_loss: 3.7666e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1348/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5387e-05 - val_loss: 3.7640e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1349/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5496e-05 - val_loss: 3.7665e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1350/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5385e-05 - val_loss: 3.7637e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1351/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5463e-05 - val_loss: 3.7701e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1352/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5410e-05 - val_loss: 3.7662e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1353/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5520e-05 - val_loss: 3.7622e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1354/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5442e-05 - val_loss: 3.7683e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1355/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5423e-05 - val_loss: 3.7651e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1356/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5503e-05 - val_loss: 3.7668e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1357/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5446e-05 - val_loss: 3.7702e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1358/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5496e-05 - val_loss: 3.7676e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1359/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5482e-05 - val_loss: 3.7662e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1360/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5405e-05 - val_loss: 3.7627e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1361/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5511e-05 - val_loss: 3.7691e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1362/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5441e-05 - val_loss: 3.7692e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1363/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5352e-05 - val_loss: 3.7607e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1364/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5442e-05 - val_loss: 3.7763e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1365/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5480e-05 - val_loss: 3.7682e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1366/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5368e-05 - val_loss: 3.7627e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1367/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5529e-05 - val_loss: 3.7598e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1368/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5439e-05 - val_loss: 3.7667e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1369/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5374e-05 - val_loss: 3.7631e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1370/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5410e-05 - val_loss: 3.7641e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1371/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5481e-05 - val_loss: 3.7689e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1372/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5464e-05 - val_loss: 3.7641e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1373/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5409e-05 - val_loss: 3.7662e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1374/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5435e-05 - val_loss: 3.7745e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1375/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5383e-05 - val_loss: 3.7772e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1376/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5436e-05 - val_loss: 3.7625e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1377/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5350e-05 - val_loss: 3.7610e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1378/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5469e-05 - val_loss: 3.7685e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1379/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5379e-05 - val_loss: 3.7654e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1380/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5453e-05 - val_loss: 3.7635e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1381/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5553e-05 - val_loss: 3.7619e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1382/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5382e-05 - val_loss: 3.7632e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1383/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5449e-05 - val_loss: 3.7594e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1384/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5463e-05 - val_loss: 3.7618e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1385/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5550e-05 - val_loss: 3.7652e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1386/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5355e-05 - val_loss: 3.7637e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1387/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5441e-05 - val_loss: 3.7571e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1388/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5342e-05 - val_loss: 3.7572e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1389/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5460e-05 - val_loss: 3.7575e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1390/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5340e-05 - val_loss: 3.7595e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1391/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5443e-05 - val_loss: 3.7687e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1392/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5369e-05 - val_loss: 3.7590e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1393/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5392e-05 - val_loss: 3.7721e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1394/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5349e-05 - val_loss: 3.7703e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1395/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5421e-05 - val_loss: 3.7583e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1396/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5461e-05 - val_loss: 3.7596e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1397/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5432e-05 - val_loss: 3.7665e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1398/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5415e-05 - val_loss: 3.7633e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1399/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5346e-05 - val_loss: 3.7622e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1400/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5393e-05 - val_loss: 3.7635e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1401/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5375e-05 - val_loss: 3.7651e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1402/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5508e-05 - val_loss: 3.7625e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1403/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5522e-05 - val_loss: 3.7617e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1404/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5423e-05 - val_loss: 3.7556e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1405/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5384e-05 - val_loss: 3.7643e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1406/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5468e-05 - val_loss: 3.7565e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1407/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5419e-05 - val_loss: 3.7674e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1408/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5376e-05 - val_loss: 3.7645e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1409/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5416e-05 - val_loss: 3.7716e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1410/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5486e-05 - val_loss: 3.7561e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1411/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5352e-05 - val_loss: 3.7633e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1412/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5409e-05 - val_loss: 3.7618e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1413/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5335e-05 - val_loss: 3.7710e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1414/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5428e-05 - val_loss: 3.7522e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1415/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5353e-05 - val_loss: 3.7556e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1416/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5522e-05 - val_loss: 3.7649e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1417/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5516e-05 - val_loss: 3.7529e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1418/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5457e-05 - val_loss: 3.7519e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1419/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5401e-05 - val_loss: 3.7603e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1420/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5404e-05 - val_loss: 3.7540e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1421/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5528e-05 - val_loss: 3.7645e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1422/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5309e-05 - val_loss: 3.7560e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1423/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5491e-05 - val_loss: 3.7566e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1424/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5408e-05 - val_loss: 3.7515e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1425/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5476e-05 - val_loss: 3.7558e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1426/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5396e-05 - val_loss: 3.7586e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1427/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5362e-05 - val_loss: 3.7552e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1428/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5372e-05 - val_loss: 3.7487e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1429/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5344e-05 - val_loss: 3.7532e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1430/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5475e-05 - val_loss: 3.7598e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1431/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5331e-05 - val_loss: 3.7635e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1432/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5439e-05 - val_loss: 3.7575e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1433/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5365e-05 - val_loss: 3.7586e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1434/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5348e-05 - val_loss: 3.7542e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1435/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5439e-05 - val_loss: 3.7504e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1436/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5343e-05 - val_loss: 3.7632e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1437/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5438e-05 - val_loss: 3.7557e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1438/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5378e-05 - val_loss: 3.7552e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1439/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5414e-05 - val_loss: 3.7535e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1440/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5367e-05 - val_loss: 3.7622e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1441/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5354e-05 - val_loss: 3.7542e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1442/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5321e-05 - val_loss: 3.7517e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1443/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5428e-05 - val_loss: 3.7535e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1444/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5381e-05 - val_loss: 3.7608e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1445/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5400e-05 - val_loss: 3.7571e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1446/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5388e-05 - val_loss: 3.7575e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1447/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5330e-05 - val_loss: 3.7586e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1448/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5408e-05 - val_loss: 3.7530e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1449/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5326e-05 - val_loss: 3.7565e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1450/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5323e-05 - val_loss: 3.7502e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1451/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5303e-05 - val_loss: 3.7544e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1452/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5371e-05 - val_loss: 3.7530e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1453/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5369e-05 - val_loss: 3.7520e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1454/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5354e-05 - val_loss: 3.7539e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1455/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5327e-05 - val_loss: 3.7520e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1456/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5252e-05 - val_loss: 3.7546e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1457/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5356e-05 - val_loss: 3.7500e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1458/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5349e-05 - val_loss: 3.7473e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1459/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5430e-05 - val_loss: 3.7523e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1460/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5373e-05 - val_loss: 3.7498e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1461/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5372e-05 - val_loss: 3.7598e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1462/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5318e-05 - val_loss: 3.7634e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1463/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5462e-05 - val_loss: 3.7580e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1464/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5390e-05 - val_loss: 3.7583e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1465/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5391e-05 - val_loss: 3.7469e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1466/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5518e-05 - val_loss: 3.7448e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1467/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5358e-05 - val_loss: 3.7566e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1468/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5433e-05 - val_loss: 3.7609e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1469/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5372e-05 - val_loss: 3.7590e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1470/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5448e-05 - val_loss: 3.7518e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1471/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5360e-05 - val_loss: 3.7493e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1472/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5418e-05 - val_loss: 3.7567e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1473/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5308e-05 - val_loss: 3.7542e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1474/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5372e-05 - val_loss: 3.7524e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1475/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5476e-05 - val_loss: 3.7513e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1476/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5541e-05 - val_loss: 3.7506e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1477/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5387e-05 - val_loss: 3.7514e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1478/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5449e-05 - val_loss: 3.7513e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1479/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5435e-05 - val_loss: 3.7547e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1480/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5273e-05 - val_loss: 3.7537e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1481/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5368e-05 - val_loss: 3.7453e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1482/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5298e-05 - val_loss: 3.7481e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1483/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5426e-05 - val_loss: 3.7552e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1484/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5322e-05 - val_loss: 3.7575e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1485/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5367e-05 - val_loss: 3.7591e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1486/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5399e-05 - val_loss: 3.7509e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1487/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5387e-05 - val_loss: 3.7563e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1488/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5485e-05 - val_loss: 3.7444e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1489/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5381e-05 - val_loss: 3.7505e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1490/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5313e-05 - val_loss: 3.7550e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1491/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5305e-05 - val_loss: 3.7510e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1492/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5407e-05 - val_loss: 3.7486e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1493/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5281e-05 - val_loss: 3.7427e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1494/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5460e-05 - val_loss: 3.7459e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1495/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5266e-05 - val_loss: 3.7509e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1496/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5376e-05 - val_loss: 3.7488e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1497/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5264e-05 - val_loss: 3.7522e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1498/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5324e-05 - val_loss: 3.7533e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1499/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5293e-05 - val_loss: 3.7509e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1500/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5379e-05 - val_loss: 3.7413e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1501/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5356e-05 - val_loss: 3.7506e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1502/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5387e-05 - val_loss: 3.7479e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1503/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5259e-05 - val_loss: 3.7504e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1504/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5399e-05 - val_loss: 3.7537e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1505/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5392e-05 - val_loss: 3.7472e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1506/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5282e-05 - val_loss: 3.7494e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1507/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5372e-05 - val_loss: 3.7447e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1508/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5295e-05 - val_loss: 3.7419e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1509/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5411e-05 - val_loss: 3.7512e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1510/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5394e-05 - val_loss: 3.7473e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1511/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5292e-05 - val_loss: 3.7538e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1512/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5181e-05 - val_loss: 3.7507e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1513/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5293e-05 - val_loss: 3.7485e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1514/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5355e-05 - val_loss: 3.7468e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1515/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5440e-05 - val_loss: 3.7513e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1516/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5399e-05 - val_loss: 3.7512e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1517/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5319e-05 - val_loss: 3.7643e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1518/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5327e-05 - val_loss: 3.7469e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1519/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5365e-05 - val_loss: 3.7489e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1520/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5473e-05 - val_loss: 3.7436e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1521/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5357e-05 - val_loss: 3.7467e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1522/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5374e-05 - val_loss: 3.7450e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1523/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5282e-05 - val_loss: 3.7455e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1524/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5262e-05 - val_loss: 3.7381e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1525/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5341e-05 - val_loss: 3.7457e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1526/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5252e-05 - val_loss: 3.7515e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1527/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5304e-05 - val_loss: 3.7429e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1528/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5238e-05 - val_loss: 3.7518e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1529/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5398e-05 - val_loss: 3.7444e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1530/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5242e-05 - val_loss: 3.7472e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1531/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5207e-05 - val_loss: 3.7420e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1532/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5310e-05 - val_loss: 3.7588e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1533/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5354e-05 - val_loss: 3.7516e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1534/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5362e-05 - val_loss: 3.7421e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1535/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5319e-05 - val_loss: 3.7445e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1536/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5268e-05 - val_loss: 3.7403e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1537/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5319e-05 - val_loss: 3.7426e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1538/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5354e-05 - val_loss: 3.7493e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1539/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5446e-05 - val_loss: 3.7501e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1540/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5391e-05 - val_loss: 3.7404e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1541/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5307e-05 - val_loss: 3.7523e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1542/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5327e-05 - val_loss: 3.7421e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1543/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5400e-05 - val_loss: 3.7511e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1544/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5374e-05 - val_loss: 3.7427e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1545/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5252e-05 - val_loss: 3.7372e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1546/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5228e-05 - val_loss: 3.7454e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1547/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5283e-05 - val_loss: 3.7392e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1548/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5288e-05 - val_loss: 3.7428e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1549/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5341e-05 - val_loss: 3.7466e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1550/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5318e-05 - val_loss: 3.7486e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1551/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5300e-05 - val_loss: 3.7394e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1552/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5337e-05 - val_loss: 3.7438e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1553/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5268e-05 - val_loss: 3.7345e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1554/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5127e-05 - val_loss: 3.7446e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1555/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5351e-05 - val_loss: 3.7371e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1556/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5362e-05 - val_loss: 3.7449e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1557/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5316e-05 - val_loss: 3.7348e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1558/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5316e-05 - val_loss: 3.7435e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1559/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5296e-05 - val_loss: 3.7373e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1560/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5278e-05 - val_loss: 3.7489e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1561/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5270e-05 - val_loss: 3.7363e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1562/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5260e-05 - val_loss: 3.7387e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1563/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5294e-05 - val_loss: 3.7386e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1564/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5285e-05 - val_loss: 3.7536e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1565/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5181e-05 - val_loss: 3.7510e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1566/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5391e-05 - val_loss: 3.7447e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1567/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5306e-05 - val_loss: 3.7471e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1568/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5344e-05 - val_loss: 3.7495e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1569/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5286e-05 - val_loss: 3.7341e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1570/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5253e-05 - val_loss: 3.7373e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1571/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5310e-05 - val_loss: 3.7382e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1572/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5244e-05 - val_loss: 3.7371e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1573/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5311e-05 - val_loss: 3.7375e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1574/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5406e-05 - val_loss: 3.7427e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1575/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5225e-05 - val_loss: 3.7468e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1576/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5375e-05 - val_loss: 3.7416e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1577/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5271e-05 - val_loss: 3.7430e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1578/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5290e-05 - val_loss: 3.7366e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1579/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5278e-05 - val_loss: 3.7337e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1580/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5240e-05 - val_loss: 3.7413e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1581/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5261e-05 - val_loss: 3.7430e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1582/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5381e-05 - val_loss: 3.7426e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1583/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5273e-05 - val_loss: 3.7437e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1584/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5213e-05 - val_loss: 3.7385e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1585/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5299e-05 - val_loss: 3.7424e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1586/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5179e-05 - val_loss: 3.7386e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1587/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.5296e-05 - val_loss: 3.7337e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1588/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5288e-05 - val_loss: 3.7390e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1589/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5273e-05 - val_loss: 3.7397e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1590/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5261e-05 - val_loss: 3.7384e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1591/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5231e-05 - val_loss: 3.7367e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1592/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5277e-05 - val_loss: 3.7341e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1593/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5373e-05 - val_loss: 3.7396e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1594/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5283e-05 - val_loss: 3.7513e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1595/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5350e-05 - val_loss: 3.7326e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1596/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5165e-05 - val_loss: 3.7363e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1597/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5372e-05 - val_loss: 3.7405e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1598/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5220e-05 - val_loss: 3.7341e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1599/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5238e-05 - val_loss: 3.7369e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1600/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5199e-05 - val_loss: 3.7457e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1601/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5126e-05 - val_loss: 3.7317e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1602/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5118e-05 - val_loss: 3.7316e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1603/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5222e-05 - val_loss: 3.7412e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1604/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5273e-05 - val_loss: 3.7378e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1605/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5400e-05 - val_loss: 3.7321e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1606/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5243e-05 - val_loss: 3.7465e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1607/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5390e-05 - val_loss: 3.7318e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1608/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5321e-05 - val_loss: 3.7477e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1609/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5347e-05 - val_loss: 3.7306e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1610/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5270e-05 - val_loss: 3.7381e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1611/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5189e-05 - val_loss: 3.7312e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1612/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5220e-05 - val_loss: 3.7340e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1613/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5198e-05 - val_loss: 3.7350e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1614/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5350e-05 - val_loss: 3.7312e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1615/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5162e-05 - val_loss: 3.7314e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1616/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5300e-05 - val_loss: 3.7285e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1617/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5133e-05 - val_loss: 3.7323e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1618/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5158e-05 - val_loss: 3.7341e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1619/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5159e-05 - val_loss: 3.7312e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1620/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5283e-05 - val_loss: 3.7286e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1621/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5169e-05 - val_loss: 3.7326e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1622/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5298e-05 - val_loss: 3.7385e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1623/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5299e-05 - val_loss: 3.7267e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1624/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5162e-05 - val_loss: 3.7303e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1625/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5136e-05 - val_loss: 3.7286e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1626/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5211e-05 - val_loss: 3.7367e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1627/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5338e-05 - val_loss: 3.7252e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1628/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5263e-05 - val_loss: 3.7397e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1629/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5191e-05 - val_loss: 3.7288e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1630/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5382e-05 - val_loss: 3.7296e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1631/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5216e-05 - val_loss: 3.7298e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1632/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5314e-05 - val_loss: 3.7307e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1633/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5302e-05 - val_loss: 3.7338e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1634/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5197e-05 - val_loss: 3.7337e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1635/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5231e-05 - val_loss: 3.7350e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1636/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5129e-05 - val_loss: 3.7281e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1637/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5188e-05 - val_loss: 3.7262e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1638/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5300e-05 - val_loss: 3.7321e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1639/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5351e-05 - val_loss: 3.7484e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1640/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5345e-05 - val_loss: 3.7303e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1641/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5207e-05 - val_loss: 3.7253e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1642/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5161e-05 - val_loss: 3.7303e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1643/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5252e-05 - val_loss: 3.7281e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1644/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5223e-05 - val_loss: 3.7371e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1645/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5269e-05 - val_loss: 3.7282e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1646/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5238e-05 - val_loss: 3.7268e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1647/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5169e-05 - val_loss: 3.7307e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1648/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5279e-05 - val_loss: 3.7263e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1649/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5291e-05 - val_loss: 3.7288e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1650/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5158e-05 - val_loss: 3.7288e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1651/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5212e-05 - val_loss: 3.7282e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1652/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5184e-05 - val_loss: 3.7455e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1653/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5173e-05 - val_loss: 3.7243e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1654/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5248e-05 - val_loss: 3.7267e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1655/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5230e-05 - val_loss: 3.7345e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1656/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5149e-05 - val_loss: 3.7336e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1657/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5308e-05 - val_loss: 3.7312e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1658/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5228e-05 - val_loss: 3.7257e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1659/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5235e-05 - val_loss: 3.7299e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1660/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5166e-05 - val_loss: 3.7304e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1661/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5125e-05 - val_loss: 3.7325e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1662/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5233e-05 - val_loss: 3.7198e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1663/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5253e-05 - val_loss: 3.7325e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1664/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5224e-05 - val_loss: 3.7350e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1665/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5203e-05 - val_loss: 3.7275e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1666/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5146e-05 - val_loss: 3.7239e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1667/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5273e-05 - val_loss: 3.7357e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1668/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5212e-05 - val_loss: 3.7322e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1669/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5236e-05 - val_loss: 3.7317e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1670/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5157e-05 - val_loss: 3.7358e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1671/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5234e-05 - val_loss: 3.7234e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1672/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5169e-05 - val_loss: 3.7301e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1673/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5121e-05 - val_loss: 3.7310e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1674/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5253e-05 - val_loss: 3.7366e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1675/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5304e-05 - val_loss: 3.7321e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1676/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5140e-05 - val_loss: 3.7366e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1677/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5164e-05 - val_loss: 3.7259e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1678/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5111e-05 - val_loss: 3.7298e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1679/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5192e-05 - val_loss: 3.7269e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1680/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5255e-05 - val_loss: 3.7222e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1681/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5189e-05 - val_loss: 3.7260e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1682/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5145e-05 - val_loss: 3.7246e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1683/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5201e-05 - val_loss: 3.7243e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1684/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5245e-05 - val_loss: 3.7297e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1685/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5062e-05 - val_loss: 3.7249e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1686/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5198e-05 - val_loss: 3.7312e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1687/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5139e-05 - val_loss: 3.7491e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1688/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5195e-05 - val_loss: 3.7259e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1689/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5200e-05 - val_loss: 3.7233e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1690/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5219e-05 - val_loss: 3.7323e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1691/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5173e-05 - val_loss: 3.7251e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1692/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5223e-05 - val_loss: 3.7358e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1693/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5225e-05 - val_loss: 3.7236e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1694/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5237e-05 - val_loss: 3.7294e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1695/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5203e-05 - val_loss: 3.7228e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1696/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5221e-05 - val_loss: 3.7272e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1697/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5236e-05 - val_loss: 3.7245e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1698/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5180e-05 - val_loss: 3.7279e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1699/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5083e-05 - val_loss: 3.7217e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1700/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5184e-05 - val_loss: 3.7284e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1701/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5130e-05 - val_loss: 3.7227e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1702/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5296e-05 - val_loss: 3.7248e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1703/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5210e-05 - val_loss: 3.7241e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1704/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5220e-05 - val_loss: 3.7192e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1705/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5142e-05 - val_loss: 3.7275e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1706/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5216e-05 - val_loss: 3.7200e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1707/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5258e-05 - val_loss: 3.7244e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1708/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5169e-05 - val_loss: 3.7268e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1709/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5184e-05 - val_loss: 3.7273e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1710/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5180e-05 - val_loss: 3.7248e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1711/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5141e-05 - val_loss: 3.7265e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1712/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5202e-05 - val_loss: 3.7280e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1713/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.5115e-05 - val_loss: 3.7338e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1714/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5165e-05 - val_loss: 3.7352e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1715/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5214e-05 - val_loss: 3.7236e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1716/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5236e-05 - val_loss: 3.7183e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1717/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5126e-05 - val_loss: 3.7320e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1718/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5200e-05 - val_loss: 3.7224e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1719/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5150e-05 - val_loss: 3.7157e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1720/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5142e-05 - val_loss: 3.7256e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1721/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5179e-05 - val_loss: 3.7239e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1722/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5160e-05 - val_loss: 3.7183e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1723/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5276e-05 - val_loss: 3.7381e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1724/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5141e-05 - val_loss: 3.7200e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1725/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5217e-05 - val_loss: 3.7219e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1726/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5166e-05 - val_loss: 3.7203e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1727/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5137e-05 - val_loss: 3.7284e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1728/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5119e-05 - val_loss: 3.7150e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1729/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5176e-05 - val_loss: 3.7180e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1730/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5084e-05 - val_loss: 3.7233e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1731/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5135e-05 - val_loss: 3.7260e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1732/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5158e-05 - val_loss: 3.7189e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1733/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5298e-05 - val_loss: 3.7168e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1734/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5102e-05 - val_loss: 3.7292e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1735/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5127e-05 - val_loss: 3.7338e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1736/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5070e-05 - val_loss: 3.7200e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1737/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5132e-05 - val_loss: 3.7120e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1738/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5014e-05 - val_loss: 3.7266e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1739/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5188e-05 - val_loss: 3.7193e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1740/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5118e-05 - val_loss: 3.7149e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1741/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5178e-05 - val_loss: 3.7150e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1742/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5015e-05 - val_loss: 3.7275e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1743/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5168e-05 - val_loss: 3.7245e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1744/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5118e-05 - val_loss: 3.7155e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1745/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5170e-05 - val_loss: 3.7125e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1746/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5078e-05 - val_loss: 3.7195e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1747/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5143e-05 - val_loss: 3.7170e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1748/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5104e-05 - val_loss: 3.7304e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1749/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5056e-05 - val_loss: 3.7142e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1750/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5137e-05 - val_loss: 3.7210e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1751/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5245e-05 - val_loss: 3.7122e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1752/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5204e-05 - val_loss: 3.7208e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1753/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5080e-05 - val_loss: 3.7137e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1754/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5170e-05 - val_loss: 3.7138e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1755/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5068e-05 - val_loss: 3.7228e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1756/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5170e-05 - val_loss: 3.7223e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1757/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5158e-05 - val_loss: 3.7172e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1758/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5130e-05 - val_loss: 3.7114e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1759/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5128e-05 - val_loss: 3.7220e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1760/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5137e-05 - val_loss: 3.7205e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1761/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5039e-05 - val_loss: 3.7158e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1762/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5149e-05 - val_loss: 3.7176e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1763/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5098e-05 - val_loss: 3.7226e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1764/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5173e-05 - val_loss: 3.7109e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1765/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4953e-05 - val_loss: 3.7198e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1766/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5185e-05 - val_loss: 3.7214e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1767/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5079e-05 - val_loss: 3.7215e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1768/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5188e-05 - val_loss: 3.7243e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1769/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5061e-05 - val_loss: 3.7169e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1770/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5100e-05 - val_loss: 3.7277e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1771/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5128e-05 - val_loss: 3.7131e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1772/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5081e-05 - val_loss: 3.7224e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1773/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5167e-05 - val_loss: 3.7136e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1774/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5088e-05 - val_loss: 3.7126e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1775/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5123e-05 - val_loss: 3.7230e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1776/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5023e-05 - val_loss: 3.7122e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1777/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5086e-05 - val_loss: 3.7133e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1778/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5144e-05 - val_loss: 3.7162e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1779/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5104e-05 - val_loss: 3.7114e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1780/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5149e-05 - val_loss: 3.7150e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1781/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5102e-05 - val_loss: 3.7095e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1782/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5080e-05 - val_loss: 3.7178e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1783/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5103e-05 - val_loss: 3.7183e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1784/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5066e-05 - val_loss: 3.7112e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1785/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5184e-05 - val_loss: 3.7124e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1786/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5193e-05 - val_loss: 3.7110e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1787/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5112e-05 - val_loss: 3.7203e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1788/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5125e-05 - val_loss: 3.7147e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1789/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5143e-05 - val_loss: 3.7112e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1790/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5190e-05 - val_loss: 3.7211e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1791/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5057e-05 - val_loss: 3.7202e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1792/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5048e-05 - val_loss: 3.7074e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1793/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5016e-05 - val_loss: 3.7088e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1794/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5089e-05 - val_loss: 3.7148e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1795/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5047e-05 - val_loss: 3.7175e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1796/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5131e-05 - val_loss: 3.7146e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1797/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5024e-05 - val_loss: 3.7108e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1798/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5156e-05 - val_loss: 3.7162e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1799/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4931e-05 - val_loss: 3.7120e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1800/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5125e-05 - val_loss: 3.7156e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1801/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5050e-05 - val_loss: 3.7115e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1802/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5029e-05 - val_loss: 3.7219e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1803/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5091e-05 - val_loss: 3.7138e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1804/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5127e-05 - val_loss: 3.7139e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1805/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5048e-05 - val_loss: 3.7096e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1806/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5105e-05 - val_loss: 3.7099e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1807/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5182e-05 - val_loss: 3.7116e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1808/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5122e-05 - val_loss: 3.7119e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1809/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5051e-05 - val_loss: 3.7183e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1810/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5155e-05 - val_loss: 3.7163e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1811/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5120e-05 - val_loss: 3.7225e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1812/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5090e-05 - val_loss: 3.7092e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1813/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5162e-05 - val_loss: 3.7056e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1814/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5161e-05 - val_loss: 3.7090e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1815/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5100e-05 - val_loss: 3.7206e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1816/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.5076e-05 - val_loss: 3.7111e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1817/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5121e-05 - val_loss: 3.7100e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1818/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4986e-05 - val_loss: 3.7048e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1819/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4975e-05 - val_loss: 3.7147e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1820/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5038e-05 - val_loss: 3.7108e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1821/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5063e-05 - val_loss: 3.7117e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1822/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5020e-05 - val_loss: 3.7119e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1823/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5176e-05 - val_loss: 3.7178e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1824/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5020e-05 - val_loss: 3.7102e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1825/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5150e-05 - val_loss: 3.7056e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1826/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5144e-05 - val_loss: 3.7043e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1827/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5101e-05 - val_loss: 3.7090e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1828/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5139e-05 - val_loss: 3.7127e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1829/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5122e-05 - val_loss: 3.7091e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1830/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5007e-05 - val_loss: 3.7198e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1831/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5058e-05 - val_loss: 3.7137e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1832/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5115e-05 - val_loss: 3.7055e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1833/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5151e-05 - val_loss: 3.7083e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1834/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5077e-05 - val_loss: 3.7057e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1835/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5150e-05 - val_loss: 3.7096e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1836/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5070e-05 - val_loss: 3.7117e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1837/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5066e-05 - val_loss: 3.7117e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1838/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5140e-05 - val_loss: 3.7049e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1839/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5036e-05 - val_loss: 3.7084e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1840/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5043e-05 - val_loss: 3.7070e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1841/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5060e-05 - val_loss: 3.7207e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1842/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5137e-05 - val_loss: 3.7095e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1843/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5064e-05 - val_loss: 3.7080e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1844/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5052e-05 - val_loss: 3.7171e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1845/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5163e-05 - val_loss: 3.7028e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1846/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5071e-05 - val_loss: 3.7088e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1847/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5005e-05 - val_loss: 3.7036e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1848/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5161e-05 - val_loss: 3.7028e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1849/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5066e-05 - val_loss: 3.7165e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1850/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5071e-05 - val_loss: 3.7142e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1851/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5025e-05 - val_loss: 3.7089e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1852/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5008e-05 - val_loss: 3.7097e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1853/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5079e-05 - val_loss: 3.7045e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1854/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5036e-05 - val_loss: 3.7082e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1855/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5036e-05 - val_loss: 3.7070e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1856/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5027e-05 - val_loss: 3.7039e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1857/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5119e-05 - val_loss: 3.7034e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1858/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4916e-05 - val_loss: 3.7056e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1859/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5034e-05 - val_loss: 3.7004e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1860/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4989e-05 - val_loss: 3.7035e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1861/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5055e-05 - val_loss: 3.7066e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1862/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5073e-05 - val_loss: 3.7033e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1863/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5132e-05 - val_loss: 3.7104e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1864/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5043e-05 - val_loss: 3.7036e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1865/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5042e-05 - val_loss: 3.7020e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1866/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4943e-05 - val_loss: 3.7069e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1867/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5127e-05 - val_loss: 3.7030e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1868/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4958e-05 - val_loss: 3.7023e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1869/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5076e-05 - val_loss: 3.7053e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1870/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4991e-05 - val_loss: 3.7031e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1871/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4996e-05 - val_loss: 3.6980e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1872/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4872e-05 - val_loss: 3.7035e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1873/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4948e-05 - val_loss: 3.7012e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1874/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5022e-05 - val_loss: 3.7052e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1875/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5093e-05 - val_loss: 3.6998e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1876/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4965e-05 - val_loss: 3.7070e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1877/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5086e-05 - val_loss: 3.7033e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1878/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4981e-05 - val_loss: 3.7120e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1879/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5106e-05 - val_loss: 3.7049e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1880/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5032e-05 - val_loss: 3.7100e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1881/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5093e-05 - val_loss: 3.6986e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1882/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4975e-05 - val_loss: 3.7025e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1883/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5017e-05 - val_loss: 3.7041e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1884/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5014e-05 - val_loss: 3.7047e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1885/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5080e-05 - val_loss: 3.7035e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1886/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5026e-05 - val_loss: 3.7038e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1887/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5037e-05 - val_loss: 3.7025e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1888/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5047e-05 - val_loss: 3.7004e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1889/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4930e-05 - val_loss: 3.6984e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1890/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4950e-05 - val_loss: 3.6993e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1891/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5033e-05 - val_loss: 3.6997e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1892/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5102e-05 - val_loss: 3.7011e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1893/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5050e-05 - val_loss: 3.7098e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1894/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5027e-05 - val_loss: 3.6988e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1895/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5091e-05 - val_loss: 3.6974e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1896/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5021e-05 - val_loss: 3.7035e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1897/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4932e-05 - val_loss: 3.7164e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1898/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5136e-05 - val_loss: 3.7013e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1899/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5076e-05 - val_loss: 3.7011e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1900/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5047e-05 - val_loss: 3.7018e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1901/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4986e-05 - val_loss: 3.7077e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1902/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5134e-05 - val_loss: 3.6957e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1903/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4904e-05 - val_loss: 3.6996e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1904/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5084e-05 - val_loss: 3.6968e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1905/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4878e-05 - val_loss: 3.7041e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1906/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4938e-05 - val_loss: 3.7099e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1907/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5070e-05 - val_loss: 3.7004e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1908/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4962e-05 - val_loss: 3.6981e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1909/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5083e-05 - val_loss: 3.6968e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1910/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.5065e-05 - val_loss: 3.6960e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1911/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5078e-05 - val_loss: 3.7024e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1912/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5039e-05 - val_loss: 3.6970e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1913/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5006e-05 - val_loss: 3.6980e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1914/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5024e-05 - val_loss: 3.6965e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1915/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4918e-05 - val_loss: 3.6910e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1916/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5033e-05 - val_loss: 3.7038e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1917/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5023e-05 - val_loss: 3.6981e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1918/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4959e-05 - val_loss: 3.6993e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1919/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4959e-05 - val_loss: 3.6980e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1920/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4961e-05 - val_loss: 3.7082e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1921/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5030e-05 - val_loss: 3.6976e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1922/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4972e-05 - val_loss: 3.6977e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1923/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5079e-05 - val_loss: 3.6891e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1924/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 118ms/step - loss: 1.5033e-05 - val_loss: 3.6952e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1925/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4981e-05 - val_loss: 3.7003e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1926/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4994e-05 - val_loss: 3.6986e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1927/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4918e-05 - val_loss: 3.7011e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1928/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4999e-05 - val_loss: 3.6985e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1929/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5016e-05 - val_loss: 3.6968e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1930/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4905e-05 - val_loss: 3.6927e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1931/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4888e-05 - val_loss: 3.6967e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1932/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4987e-05 - val_loss: 3.6976e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1933/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5040e-05 - val_loss: 3.6998e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1934/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4943e-05 - val_loss: 3.6974e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1935/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4909e-05 - val_loss: 3.6961e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1936/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4993e-05 - val_loss: 3.6959e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1937/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5078e-05 - val_loss: 3.7098e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1938/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5067e-05 - val_loss: 3.6977e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1939/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4933e-05 - val_loss: 3.6999e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1940/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4980e-05 - val_loss: 3.7079e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1941/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4985e-05 - val_loss: 3.7041e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1942/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4998e-05 - val_loss: 3.6950e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1943/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4997e-05 - val_loss: 3.6958e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1944/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4974e-05 - val_loss: 3.7002e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1945/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4964e-05 - val_loss: 3.6960e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1946/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5005e-05 - val_loss: 3.6876e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1947/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4934e-05 - val_loss: 3.6938e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1948/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5067e-05 - val_loss: 3.6944e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1949/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4933e-05 - val_loss: 3.6937e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1950/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5076e-05 - val_loss: 3.6957e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1951/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5011e-05 - val_loss: 3.6921e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1952/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4933e-05 - val_loss: 3.6952e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1953/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4992e-05 - val_loss: 3.6955e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1954/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4996e-05 - val_loss: 3.6895e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1955/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4855e-05 - val_loss: 3.6989e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1956/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4866e-05 - val_loss: 3.6905e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1957/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5065e-05 - val_loss: 3.6903e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1958/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4989e-05 - val_loss: 3.6887e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1959/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4925e-05 - val_loss: 3.6980e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1960/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4988e-05 - val_loss: 3.6892e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1961/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4973e-05 - val_loss: 3.6921e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1962/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4932e-05 - val_loss: 3.7070e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1963/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4934e-05 - val_loss: 3.6952e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1964/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5203e-05 - val_loss: 3.6883e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1965/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4894e-05 - val_loss: 3.6953e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1966/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4964e-05 - val_loss: 3.6941e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1967/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4868e-05 - val_loss: 3.6920e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1968/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5044e-05 - val_loss: 3.6878e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1969/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4950e-05 - val_loss: 3.7012e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1970/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5021e-05 - val_loss: 3.6993e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1971/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4981e-05 - val_loss: 3.6879e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1972/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4906e-05 - val_loss: 3.6987e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1973/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5021e-05 - val_loss: 3.6929e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1974/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4883e-05 - val_loss: 3.6904e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1975/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5050e-05 - val_loss: 3.6934e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1976/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5018e-05 - val_loss: 3.6913e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1977/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4936e-05 - val_loss: 3.6916e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1978/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4981e-05 - val_loss: 3.7044e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1979/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4830e-05 - val_loss: 3.6873e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1980/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4980e-05 - val_loss: 3.6892e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1981/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4920e-05 - val_loss: 3.6921e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1982/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4945e-05 - val_loss: 3.6916e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1983/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5038e-05 - val_loss: 3.6926e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1984/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4956e-05 - val_loss: 3.6953e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1985/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4904e-05 - val_loss: 3.6939e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1986/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4794e-05 - val_loss: 3.6869e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1987/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4952e-05 - val_loss: 3.6898e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1988/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4960e-05 - val_loss: 3.6938e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1989/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4859e-05 - val_loss: 3.6937e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1990/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4949e-05 - val_loss: 3.6966e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1991/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4972e-05 - val_loss: 3.6937e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1992/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4934e-05 - val_loss: 3.6845e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1993/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4891e-05 - val_loss: 3.6931e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1994/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4998e-05 - val_loss: 3.6900e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1995/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5044e-05 - val_loss: 3.6881e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1996/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4857e-05 - val_loss: 3.6938e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1997/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4894e-05 - val_loss: 3.6903e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1998/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5001e-05 - val_loss: 3.6888e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 1999/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4963e-05 - val_loss: 3.6866e-05 - learning_rate: 5.0000e-06\n",
            "Epoch 2000/2000\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4908e-05 - val_loss: 3.6988e-05 - learning_rate: 5.0000e-06\n"
          ]
        }
      ],
      "source": [
        "Training = True\n",
        "\n",
        "\n",
        "# Define the learning rate scheduler function\n",
        "def scheduler(epoch, lr):\n",
        "    if epoch < 20:\n",
        "        return lr\n",
        "    else:\n",
        "        return max(lr * 0.99, 5e-6)\n",
        "\n",
        "# Initialize the neural network model\n",
        "model_hf = Sequential()\n",
        "\n",
        "\n",
        "l2_reg = 0#1e-8\n",
        "# Add layers to the model\n",
        "\n",
        "model_hf.add(Dense(256, input_shape=(n_f,), activation='gelu'))\n",
        "model_hf.add(Dense(128, activation='gelu'))\n",
        "model_hf.add(Dense(64, activation='gelu'))\n",
        "#model_hf.add(Dense(128, activation='gelu'))\n",
        "model_hf.add(Dense(25, activation='gelu'))\n",
        "\n",
        "\n",
        "if Training:\n",
        "    # Compile the model\n",
        "    initial_learning_rate = 0.001\n",
        "    optimizer = Adam(learning_rate=initial_learning_rate)\n",
        "    model_hf.compile(optimizer=optimizer, loss='mean_squared_error')\n",
        "\n",
        "    # Define the learning rate scheduler callback\n",
        "    lr_scheduler = LearningRateScheduler(scheduler)\n",
        "\n",
        "    # Train the model\n",
        "    history_hf = model_hf.fit(X_train2, y_train, \n",
        "                    epochs=2000, \n",
        "                    batch_size=64, \n",
        "                    validation_data=(X_test2, y_test),\n",
        "                    callbacks=[lr_scheduler])\n",
        "    \n",
        "    model_hf.save('./models3/model_HF_16000_1.keras')\n",
        "\n",
        "model_hf = load_model('./models3/model_HF_16000_1.keras')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425us/step - loss: 3.6410e-05\n",
            "Test accuracy: 3.6988094507250935e-05\n",
            "Test rmse: 0.006081783826086795\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Evaluate the model on the test set\n",
        "test_loss = model_hf.evaluate(x=X_test2, y=y_test)\n",
        "\n",
        "# Print the test accuracy\n",
        "print(f\"Test accuracy: {test_loss}\")\n",
        "print(f\"Test rmse: {np.sqrt(test_loss)}\")\n",
        "\n",
        "if Training:\n",
        "    plt.plot(history_hf.history['loss'], label='Loss')\n",
        "    plt.plot(history_hf.history['val_loss'], label='Val loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Learning Rate')\n",
        "    plt.title('Learning Rate over Epochs')\n",
        "    plt.legend()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5 ) Evaluation of different models "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### LOW FIDELITY MODELS "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "MODEL LF 1 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/lucacaroselli/miniconda3/envs/myenv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "model_lf = Sequential()\n",
        "\n",
        "# Add layers to the model\n",
        "model_lf.add(Dense(64, input_shape=(n_c,), activation='gelu'))\n",
        "model_lf.add(Dense(64, activation='gelu'))\n",
        "model_lf.add(Dense(64, activation='gelu'))\n",
        "model_lf.add(Dense(32, activation='gelu'))\n",
        "model_lf.add(Dense(25, activation='exponential'))\n",
        "\n",
        "model_lf = load_model('./models1/model_LF_16000_1.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288us/step - loss: 1.1679e-04\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5034e-04 \n",
            "Training accuracy: 0.00011638842261163518\n",
            "Test accuracy: 0.00014689793169964105\n",
            "Test rmse: 0.012120145696304194\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on the test set\n",
        "training_loss = model_lf.evaluate(x=X_train, y=y_train)\n",
        "test_loss = model_lf.evaluate(x=X_test, y=y_test)\n",
        "\n",
        "# Print the test accuracy\n",
        "print(f\"Training accuracy: {training_loss}\")\n",
        "print(f\"Test accuracy: {test_loss}\")\n",
        "print(f\"Test rmse: {np.sqrt(test_loss)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "MODEL LF 2 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_lf = Sequential()\n",
        "\n",
        "# Add layers to the model\n",
        "model_lf.add(Dense(128, input_shape=(n_c,), activation='gelu'))\n",
        "model_lf.add(Dense(32, activation='gelu'))\n",
        "model_lf.add(Dense(25, activation='exponential'))\n",
        "\n",
        "model_lf = load_model('./models1/model_LF_16000_2.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368us/step - loss: 1.1175e-04\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.2112e-04 \n",
            "Training accuracy: 0.00011180200817761943\n",
            "Test accuracy: 0.00011737531167455018\n",
            "Test rmse: 0.010833988724128808\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on the test set\n",
        "training_loss = model_lf.evaluate(x=X_train, y=y_train)\n",
        "test_loss = model_lf.evaluate(x=X_test, y=y_test)\n",
        "\n",
        "# Print the test accuracy\n",
        "print(f\"Training accuracy: {training_loss}\")\n",
        "print(f\"Test accuracy: {test_loss}\")\n",
        "print(f\"Test rmse: {np.sqrt(test_loss)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "MODEL LF 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_lf = Sequential()\n",
        "\n",
        "# Add layers to the model\n",
        "model_lf.add(Dense(64, input_shape=(n_c,), activation='gelu'))\n",
        "model_lf.add(Dense(64, activation='gelu'))\n",
        "model_lf.add(Dense(64, activation='sigmoid'))\n",
        "model_lf.add(Dense(32, activation='sigmoid'))\n",
        "model_lf.add(Dense(25, activation='exponential'))\n",
        "\n",
        "model_lf = load_model('./models1/model_LF_16000_3.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352us/step - loss: 1.3880e-04\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7144e-04 \n",
            "Training accuracy: 0.0001386828371323645\n",
            "Test accuracy: 0.00016588458674959838\n",
            "Test rmse: 0.012879619045204651\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on the test set\n",
        "training_loss = model_lf.evaluate(x=X_train, y=y_train)\n",
        "test_loss = model_lf.evaluate(x=X_test, y=y_test)\n",
        "\n",
        "# Print the test accuracy\n",
        "print(f\"Training accuracy: {training_loss}\")\n",
        "print(f\"Test accuracy: {test_loss}\")\n",
        "print(f\"Test rmse: {np.sqrt(test_loss)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "MODEL LF 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_lf = Sequential()\n",
        "\n",
        "# Add layers to the model\n",
        "model_lf.add(Dense(128, input_shape=(n_c,), activation='sigmoid'))\n",
        "model_lf.add(Dense(32, activation='sigmoid'))\n",
        "model_lf.add(Dense(25, activation='exponential'))\n",
        "\n",
        "model_lf = load_model('./models1/model_LF_16000_4.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412us/step - loss: 1.6804e-04\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 921us/step - loss: 2.1964e-04\n",
            "Training accuracy: 0.00016872900596354157\n",
            "Test accuracy: 0.0002119092969223857\n",
            "Test rmse: 0.014557104688858485\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on the test set\n",
        "training_loss = model_lf.evaluate(x=X_train, y=y_train)\n",
        "test_loss = model_lf.evaluate(x=X_test, y=y_test)\n",
        "\n",
        "# Print the test accuracy\n",
        "print(f\"Training accuracy: {training_loss}\")\n",
        "print(f\"Test accuracy: {test_loss}\")\n",
        "print(f\"Test rmse: {np.sqrt(test_loss)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "MODEL LF 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_lf = Sequential()\n",
        "\n",
        "# Add layers to the model\n",
        "model_lf.add(Dense(64, input_shape=(n_c,), activation='tanh'))\n",
        "model_lf.add(Dense(64, activation='tanh'))\n",
        "model_lf.add(Dense(64, activation='tanh'))\n",
        "model_lf.add(Dense(32, activation='tanh'))\n",
        "model_lf.add(Dense(25, activation='exponential'))\n",
        "\n",
        "model_lf = load_model('./models1/model_LF_16000_5.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328us/step - loss: 1.4515e-04\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8559e-04 \n",
            "Training accuracy: 0.00014478772936854511\n",
            "Test accuracy: 0.0001777773431967944\n",
            "Test rmse: 0.013333317036536497\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on the test set\n",
        "training_loss = model_lf.evaluate(x=X_train, y=y_train)\n",
        "test_loss = model_lf.evaluate(x=X_test, y=y_test)\n",
        "\n",
        "# Print the test accuracy\n",
        "print(f\"Training accuracy: {training_loss}\")\n",
        "print(f\"Test accuracy: {test_loss}\")\n",
        "print(f\"Test rmse: {np.sqrt(test_loss)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "MODEL LF 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_lf = Sequential()\n",
        "\n",
        "# Add layers to the model\n",
        "model_lf.add(Dense(128, input_shape=(n_c,), activation='tanh'))\n",
        "model_lf.add(Dense(32, activation='tanh'))\n",
        "model_lf.add(Dense(25, activation='exponential'))\n",
        "\n",
        "model_lf = load_model('./models1/model_LF_16000_6.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310us/step - loss: 1.0220e-04\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3540e-04\n",
            "Training accuracy: 0.000102774596598465\n",
            "Test accuracy: 0.00013271876377984881\n",
            "Test rmse: 0.011520363005558844\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on the test set\n",
        "training_loss = model_lf.evaluate(x=X_train, y=y_train)\n",
        "test_loss = model_lf.evaluate(x=X_test, y=y_test)\n",
        "\n",
        "# Print the test accuracy\n",
        "print(f\"Training accuracy: {training_loss}\")\n",
        "print(f\"Test accuracy: {test_loss}\")\n",
        "print(f\"Test rmse: {np.sqrt(test_loss)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### HIGH-FIDELITY MODELS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "HF MODEL 1 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_hf = Sequential()\n",
        "\n",
        "model_hf.add(Dense(256, input_shape=(n_f,), activation='gelu'))\n",
        "model_hf.add(Dense(128, activation='gelu'))\n",
        "model_hf.add(Dense(64, activation='gelu'))\n",
        "model_hf.add(Dense(25, activation='exponential'))\n",
        "\n",
        "model_hf = load_model('./models1/model_HF_16000_1.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611us/step - loss: 3.2770e-05\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568us/step - loss: 3.5348e-05\n",
            "Training accuracy: 3.305211430415511e-05\n",
            "Test accuracy: 3.5236069379607216e-05\n",
            "Test rmse: 0.005935997757715817\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on the test set\n",
        "training_loss = model_hf.evaluate(x=X_train2, y=y_train)\n",
        "test_loss = model_hf.evaluate(x=X_test2, y=y_test)\n",
        "\n",
        "# Print the test accuracy\n",
        "print(f\"Training accuracy: {training_loss}\")\n",
        "print(f\"Test accuracy: {test_loss}\")\n",
        "print(f\"Test rmse: {np.sqrt(test_loss)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "HF MODEL 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/lucacaroselli/miniconda3/envs/myenv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "model_hf = Sequential()\n",
        "\n",
        "model_hf.add(Dense(128, input_shape=(n_f,), activation='gelu'))\n",
        "model_hf.add(Dense(128, activation='gelu'))\n",
        "model_hf.add(Dense(128, activation='gelu'))\n",
        "model_hf.add(Dense(128, activation='gelu'))\n",
        "model_hf.add(Dense(25, activation='exponential'))\n",
        "\n",
        "model_hf = load_model('./models1/model_HF_16000_2.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378us/step - loss: 2.6195e-05\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.1128e-05 \n",
            "Training accuracy: 2.640677848830819e-05\n",
            "Test accuracy: 4.889052070211619e-05\n",
            "Test rmse: 0.006992175677292168\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on the test set\n",
        "training_loss = model_hf.evaluate(x=X_train2, y=y_train)\n",
        "test_loss = model_hf.evaluate(x=X_test2, y=y_test)\n",
        "\n",
        "# Print the test accuracy\n",
        "print(f\"Training accuracy: {training_loss}\")\n",
        "print(f\"Test accuracy: {test_loss}\")\n",
        "print(f\"Test rmse: {np.sqrt(test_loss)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "MODEL HF 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_hf = Sequential()\n",
        "\n",
        "model_hf.add(Dense(256, input_shape=(n_f,), activation='sigmoid'))\n",
        "model_hf.add(Dense(128, activation='sigmoid'))\n",
        "model_hf.add(Dense(64, activation='sigmoid'))\n",
        "model_hf.add(Dense(25, activation='exponential'))\n",
        "\n",
        "model_hf = load_model('./models1/model_HF_16000_3.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - loss: 5.4758e-05\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.3519e-05 \n",
            "Training accuracy: 5.470459655043669e-05\n",
            "Test accuracy: 9.166927338810638e-05\n",
            "Test rmse: 0.009574407208182988\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on the test set\n",
        "training_loss = model_hf.evaluate(x=X_train2, y=y_train)\n",
        "test_loss = model_hf.evaluate(x=X_test2, y=y_test)\n",
        "\n",
        "# Print the test accuracy\n",
        "print(f\"Training accuracy: {training_loss}\")\n",
        "print(f\"Test accuracy: {test_loss}\")\n",
        "print(f\"Test rmse: {np.sqrt(test_loss)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "MODEL HF 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_hf = Sequential()\n",
        "\n",
        "model_hf.add(Dense(128, input_shape=(n_f,), activation='gelu'))\n",
        "model_hf.add(Dense(128, activation='gelu'))\n",
        "model_hf.add(Dense(128, activation='sigmoid'))\n",
        "model_hf.add(Dense(128, activation='sigmoid'))\n",
        "model_hf.add(Dense(25, activation='exponential'))\n",
        "\n",
        "model_hf = load_model('./models1/model_HF_16000_4.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 521us/step - loss: 3.0853e-05\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.6304e-05 \n",
            "Training accuracy: 3.0951185181038454e-05\n",
            "Test accuracy: 5.645782221108675e-05\n",
            "Test rmse: 0.007513842040599919\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on the test set\n",
        "training_loss = model_hf.evaluate(x=X_train2, y=y_train)\n",
        "test_loss = model_hf.evaluate(x=X_test2, y=y_test)\n",
        "\n",
        "# Print the test accuracy\n",
        "print(f\"Training accuracy: {training_loss}\")\n",
        "print(f\"Test accuracy: {test_loss}\")\n",
        "print(f\"Test rmse: {np.sqrt(test_loss)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "MODEL HF 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_hf = Sequential()\n",
        "\n",
        "model_hf.add(Dense(256, input_shape=(n_f,), activation='tanh'))\n",
        "model_hf.add(Dense(128, activation='tanh'))\n",
        "model_hf.add(Dense(64, activation='tanh'))\n",
        "model_hf.add(Dense(25, activation='exponential'))\n",
        "\n",
        "model_hf = load_model('./models1/model_HF_16000_5.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - loss: 3.4404e-05\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.1807e-05 \n",
            "Training accuracy: 3.446887421887368e-05\n",
            "Test accuracy: 7.171485049184412e-05\n",
            "Test rmse: 0.008468462109016259\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on the test set\n",
        "training_loss = model_hf.evaluate(x=X_train2, y=y_train)\n",
        "test_loss = model_hf.evaluate(x=X_test2, y=y_test)\n",
        "\n",
        "# Print the test accuracy\n",
        "print(f\"Training accuracy: {training_loss}\")\n",
        "print(f\"Test accuracy: {test_loss}\")\n",
        "print(f\"Test rmse: {np.sqrt(test_loss)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "MODEL HF 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_hf = Sequential()\n",
        "\n",
        "model_hf.add(Dense(128, input_shape=(n_f,), activation='tanh'))\n",
        "model_hf.add(Dense(128, activation='tanh'))\n",
        "model_hf.add(Dense(128, activation='tanh'))\n",
        "model_hf.add(Dense(128, activation='tanh'))\n",
        "model_hf.add(Dense(25, activation='exponential'))\n",
        "\n",
        "model_hf = load_model('./models1/model_HF_16000_6.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 605us/step - loss: 4.0609e-05\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.4543e-05 \n",
            "Training accuracy: 4.058445483678952e-05\n",
            "Test accuracy: 7.237195677589625e-05\n",
            "Test rmse: 0.00850717090317905\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on the test set\n",
        "training_loss = model_hf.evaluate(x=X_train2, y=y_train)\n",
        "test_loss = model_hf.evaluate(x=X_test2, y=y_test)\n",
        "\n",
        "# Print the test accuracy\n",
        "print(f\"Training accuracy: {training_loss}\")\n",
        "print(f\"Test accuracy: {test_loss}\")\n",
        "print(f\"Test rmse: {np.sqrt(test_loss)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# BONUS (to do)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This model would be too big to be used as a low fidelity model yet was calculataed to set a benchmark for the performane of larger Networks. \n",
        "\n",
        "To be more specific this model will help highlight the contribution that the knowledge on the coarse solution gives to the same Neural Network (model_HF_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "\n",
        "# Add layers to the model\n",
        "model.add(Dense(128, input_shape=(n_c,), activation='gelu'))\n",
        "model.add(Dense(128, activation='gelu'))\n",
        "model.add(Dense(128, activation='gelu'))\n",
        "model.add(Dense(128, activation='gelu'))\n",
        "model.add(Dense(25, activation='exponential'))\n",
        "\n",
        "model = load_model('./models/model_LF_64000_4.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1800/1800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 732us/step - loss: 1.3567e-05\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 908us/step - loss: 1.3916e-05\n",
            "Training accuracy: 1.3542909982788842e-05\n",
            "Test accuracy: 1.3684657460544258e-05\n",
            "Test rmse: 0.0036992779647580225\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on the test set\n",
        "training_loss = model.evaluate(x=X_train, y=y_train)\n",
        "test_loss = model.evaluate(x=X_test, y=y_test)\n",
        "\n",
        "# Print the test accuracy\n",
        "print(f\"Training accuracy: {training_loss}\")\n",
        "print(f\"Test accuracy: {test_loss}\")\n",
        "print(f\"Test rmse: {np.sqrt(test_loss)}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOLKvMRTaykHpCaydJMPm9E",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
